{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\statsforecast\\core.py:26: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsforecast.models import MSTL\n",
    "from sklearn.metrics import mean_pinball_loss\n",
    "\n",
    "os.chdir(\"C:/2023_11-PTSFC\")\n",
    "import model_train as model_train\n",
    "import data_prepro as data_prepro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"1\"  # Replace \"4\" with the desired number of cores\n",
    "\n",
    "quantiles = [0.025, 0.25, 0.5, 0.75, 0.975]\n",
    "fcast_hor = [36, 40, 44, 60, 64, 68] # in hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 80136 entries, 2014-12-31 23:00:00+00:00 to 2024-02-21 22:00:00+00:00\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype              \n",
      "---  ------         --------------  -----              \n",
      " 0   timestamp_CET  80136 non-null  datetime64[ns, CET]\n",
      " 1   gesamt         80136 non-null  float64            \n",
      "dtypes: datetime64[ns, CET](1), float64(1)\n",
      "memory usage: 1.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# = = = = = = = = = = = = = \n",
    "# get data\n",
    "# df_energy = data_prepro.get_energy_data_today(to_date=t_wednesday.strftime('%Y%m%d'))\n",
    "\n",
    "# Read data from file with specified data types\n",
    "df_energy = pd.read_csv(\"data/2015-01-01_2024-02-21_energy.csv\", index_col=0, parse_dates=[0])\n",
    "df_energy['timestamp_CET'] = pd.to_datetime(df_energy['timestamp_CET'], utc=True).dt.tz_convert('CET')\n",
    "print(df_energy.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df_energy, start_date):\n",
    "    \n",
    "    df_energy_small = df_energy.loc[(df_energy['timestamp_CET'] > start_date)].copy()\n",
    "    \n",
    "    df_energy_dummy = data_prepro.create_dummy_df(df_energy_small, hour_method='simple', holiday_method='separate')\n",
    "    df_energy_fturs = data_prepro.create_features_df(df_energy_small, holiday_method='separate')\n",
    "\n",
    "    X_train_fturs = df_energy_fturs.drop(['gesamt', 'timestamp_CET'], axis=1)\n",
    "    y_train_fturs = df_energy_fturs['gesamt']\n",
    "\n",
    "    X_train_dummy = df_energy_dummy.drop(['gesamt', 'timestamp_CET'], axis=1)\n",
    "    y_train_dummy = df_energy_dummy['gesamt']\n",
    "    \n",
    "    return X_train_dummy, y_train_dummy, X_train_fturs, y_train_fturs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator DummyRegressor from version 1.3.0 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.3.0 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator GradientBoostingRegressor from version 1.3.0 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "# import trained models\n",
    "path = \"custom_models\"\n",
    "\n",
    "def load_pickled_object(path, filename):\n",
    "    with open(f\"{path}/{filename}\", \"rb\") as handle:\n",
    "        return pickle.load(handle)\n",
    "    \n",
    "quant_reg_models = {}\n",
    "quant_reg_models['quant_reg_2015_sk'] = load_pickled_object(path, \"20150101_20231031_quant_reg_sk.pickle\")\n",
    "quant_reg_models['quant_reg_2018_sk'] = load_pickled_object(path, \"20180101_20231031_quant_reg_sk.pickle\")\n",
    "quant_reg_models['quant_reg_2015_sm'] = load_pickled_object(path, \"20150101_20231031_quant_reg_sm.pickle\")\n",
    "quant_reg_models['quant_reg_2018_sm'] = load_pickled_object(path, \"20180101_20231031_quant_reg_sm.pickle\")\n",
    "\n",
    "grad_boost_models = {}\n",
    "grad_boost_models['grad_boost_2015_fturs'] = load_pickled_object(path, \"20150101_20231031_grad_boost_fturs.pickle\")\n",
    "grad_boost_models['grad_boost_2018_fturs'] = load_pickled_object(path, \"20180101_20231031_grad_boost_fturs.pickle\")\n",
    "grad_boost_models['grad_boost_2015_dummy'] = load_pickled_object(path, \"20150101_20231031_grad_boost_dummy.pickle\")\n",
    "grad_boost_models['grad_boost_2018_dummy'] = load_pickled_object(path, \"20180101_20231031_grad_boost_dummy.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2023-11-15 ...\n",
      "Submission timestamps = 2023-11-17 12:00:00+01:00 to 2023-11-18 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "method = bench_pm_2weeks\n",
      "method = bench_same_month\n",
      "method = bench_pm_1month\n",
      "method = mstl_1\n",
      "method = mstl_0.5\n",
      "method = quant_reg_2015_sk\n",
      "method = quant_reg_2018_sk\n",
      "method = quant_reg_2015_sm\n",
      "method = quant_reg_2018_sm\n",
      "method = grad_boost_2015_fturs\n",
      "method = grad_boost_2018_fturs\n",
      "method = grad_boost_2015_dummy\n",
      "method = grad_boost_2018_dummy\n",
      "method = lightgbm_dummy_2019\n",
      "method = lightgbm_dummy_2020\n",
      "method = lightgbm_dummy_2021\n",
      "method = xgboost_dummy_2019\n",
      "> time taken: 22.50 seconds\n",
      "method = xgboost_dummy_2020\n",
      "> time taken: 18.40 seconds\n",
      "method = xgboost_dummy_2021\n",
      "> time taken: 13.63 seconds\n",
      "- - - - - - - - - - - - - - - \n",
      "scores:\n",
      "lightgbm_dummy_2021      0.240762\n",
      "lightgbm_dummy_2020      0.283331\n",
      "lightgbm_dummy_2019      0.404046\n",
      "xgboost_dummy_2021       0.463602\n",
      "xgboost_dummy_2020       0.496376\n",
      "xgboost_dummy_2019       0.558907\n",
      "grad_boost_2018_fturs    0.573452\n",
      "grad_boost_2018_dummy    0.594057\n",
      "bench_pm_1month          0.615163\n",
      "mstl_0.5                 0.660708\n",
      "mstl_1                   0.702681\n",
      "bench_same_month         0.779177\n",
      "quant_reg_2018_sk        0.782333\n",
      "bench_pm_2weeks          0.789655\n",
      "grad_boost_2015_dummy    0.880643\n",
      "grad_boost_2015_fturs    0.895345\n",
      "quant_reg_2015_sk        0.993727\n",
      "quant_reg_2018_sm        1.020705\n",
      "quant_reg_2015_sm         1.24246\n",
      "dtype: object\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2023-11-22 ...\n",
      "Submission timestamps = 2023-11-24 12:00:00+01:00 to 2023-11-25 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "method = bench_pm_2weeks\n",
      "method = bench_same_month\n",
      "method = bench_pm_1month\n",
      "method = mstl_1\n",
      "method = mstl_0.5\n",
      "method = quant_reg_2015_sk\n",
      "method = quant_reg_2018_sk\n",
      "method = quant_reg_2015_sm\n",
      "method = quant_reg_2018_sm\n",
      "method = grad_boost_2015_fturs\n",
      "method = grad_boost_2018_fturs\n",
      "method = grad_boost_2015_dummy\n",
      "method = grad_boost_2018_dummy\n",
      "method = lightgbm_dummy_2019\n",
      "method = lightgbm_dummy_2020\n",
      "method = lightgbm_dummy_2021\n",
      "method = xgboost_dummy_2019\n",
      "> time taken: 23.76 seconds\n",
      "method = xgboost_dummy_2020\n",
      "> time taken: 18.61 seconds\n",
      "method = xgboost_dummy_2021\n",
      "> time taken: 13.13 seconds\n",
      "- - - - - - - - - - - - - - - \n",
      "scores:\n",
      "grad_boost_2018_dummy    0.372723\n",
      "grad_boost_2018_fturs    0.394035\n",
      "lightgbm_dummy_2019      0.394223\n",
      "grad_boost_2015_fturs    0.429604\n",
      "grad_boost_2015_dummy    0.432374\n",
      "xgboost_dummy_2019       0.462547\n",
      "quant_reg_2018_sk         0.49737\n",
      "xgboost_dummy_2020        0.50524\n",
      "lightgbm_dummy_2020        0.5503\n",
      "quant_reg_2015_sk        0.572595\n",
      "bench_same_month         0.578205\n",
      "xgboost_dummy_2021       0.579054\n",
      "mstl_0.5                 0.630093\n",
      "bench_pm_2weeks          0.664756\n",
      "quant_reg_2018_sm        0.688156\n",
      "lightgbm_dummy_2021      0.719044\n",
      "bench_pm_1month          0.732704\n",
      "mstl_1                   0.736854\n",
      "quant_reg_2015_sm        0.801323\n",
      "dtype: object\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2023-11-29 ...\n",
      "Submission timestamps = 2023-12-01 12:00:00+01:00 to 2023-12-02 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "method = bench_pm_2weeks\n",
      "method = bench_same_month\n",
      "method = bench_pm_1month\n",
      "method = mstl_1\n",
      "method = mstl_0.5\n",
      "method = quant_reg_2015_sk\n",
      "method = quant_reg_2018_sk\n",
      "method = quant_reg_2015_sm\n",
      "method = quant_reg_2018_sm\n",
      "method = grad_boost_2015_fturs\n",
      "method = grad_boost_2018_fturs\n",
      "method = grad_boost_2015_dummy\n",
      "method = grad_boost_2018_dummy\n",
      "method = lightgbm_dummy_2019\n",
      "method = lightgbm_dummy_2020\n",
      "method = lightgbm_dummy_2021\n",
      "method = xgboost_dummy_2019\n",
      "> time taken: 30.75 seconds\n",
      "method = xgboost_dummy_2020\n",
      "> time taken: 24.93 seconds\n",
      "method = xgboost_dummy_2021\n",
      "> time taken: 18.14 seconds\n",
      "- - - - - - - - - - - - - - - \n",
      "scores:\n",
      "lightgbm_dummy_2019      0.345051\n",
      "lightgbm_dummy_2021      0.367991\n",
      "grad_boost_2018_dummy    0.375047\n",
      "lightgbm_dummy_2020      0.380718\n",
      "grad_boost_2018_fturs    0.461038\n",
      "grad_boost_2015_fturs    0.493797\n",
      "grad_boost_2015_dummy    0.495655\n",
      "bench_pm_2weeks          0.512334\n",
      "mstl_0.5                 0.525645\n",
      "quant_reg_2018_sk        0.530148\n",
      "xgboost_dummy_2020       0.561867\n",
      "xgboost_dummy_2019       0.564927\n",
      "xgboost_dummy_2021       0.589556\n",
      "quant_reg_2015_sk        0.605626\n",
      "mstl_1                   0.616017\n",
      "bench_pm_1month           0.63018\n",
      "bench_same_month         0.717091\n",
      "quant_reg_2018_sm        0.730246\n",
      "quant_reg_2015_sm        0.822782\n",
      "dtype: object\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2023-12-06 ...\n",
      "Submission timestamps = 2023-12-08 12:00:00+01:00 to 2023-12-09 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "method = bench_pm_2weeks\n",
      "method = bench_same_month\n",
      "method = bench_pm_1month\n",
      "method = mstl_1\n",
      "method = mstl_0.5\n",
      "method = quant_reg_2015_sk\n",
      "method = quant_reg_2018_sk\n",
      "method = quant_reg_2015_sm\n",
      "method = quant_reg_2018_sm\n",
      "method = grad_boost_2015_fturs\n",
      "method = grad_boost_2018_fturs\n",
      "method = grad_boost_2015_dummy\n",
      "method = grad_boost_2018_dummy\n",
      "method = lightgbm_dummy_2019\n",
      "method = lightgbm_dummy_2020\n",
      "method = lightgbm_dummy_2021\n",
      "method = xgboost_dummy_2019\n",
      "> time taken: 44.25 seconds\n",
      "method = xgboost_dummy_2020\n",
      "> time taken: 30.47 seconds\n",
      "method = xgboost_dummy_2021\n",
      "> time taken: 18.50 seconds\n",
      "- - - - - - - - - - - - - - - \n",
      "scores:\n",
      "lightgbm_dummy_2020       0.40908\n",
      "lightgbm_dummy_2021      0.425927\n",
      "lightgbm_dummy_2019      0.435414\n",
      "mstl_0.5                 0.485847\n",
      "xgboost_dummy_2021       0.550562\n",
      "xgboost_dummy_2020        0.59274\n",
      "xgboost_dummy_2019       0.593181\n",
      "bench_pm_1month           0.59588\n",
      "mstl_1                    0.62863\n",
      "bench_pm_2weeks          0.655419\n",
      "bench_same_month         0.736746\n",
      "grad_boost_2018_fturs    0.770609\n",
      "grad_boost_2018_dummy    0.833484\n",
      "quant_reg_2018_sk        0.892206\n",
      "grad_boost_2015_fturs    0.898415\n",
      "grad_boost_2015_dummy    0.949314\n",
      "quant_reg_2015_sk        0.994042\n",
      "quant_reg_2018_sm        1.116896\n",
      "quant_reg_2015_sm        1.221858\n",
      "dtype: object\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2023-12-13 ...\n",
      "Submission timestamps = 2023-12-15 12:00:00+01:00 to 2023-12-16 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "method = bench_pm_2weeks\n",
      "method = bench_same_month\n",
      "method = bench_pm_1month\n",
      "method = mstl_1\n",
      "method = mstl_0.5\n",
      "method = quant_reg_2015_sk\n",
      "method = quant_reg_2018_sk\n",
      "method = quant_reg_2015_sm\n",
      "method = quant_reg_2018_sm\n",
      "method = grad_boost_2015_fturs\n",
      "method = grad_boost_2018_fturs\n",
      "method = grad_boost_2015_dummy\n",
      "method = grad_boost_2018_dummy\n",
      "method = lightgbm_dummy_2019\n",
      "method = lightgbm_dummy_2020\n",
      "method = lightgbm_dummy_2021\n",
      "method = xgboost_dummy_2019\n",
      "> time taken: 28.96 seconds\n",
      "method = xgboost_dummy_2020\n",
      "> time taken: 28.67 seconds\n",
      "method = xgboost_dummy_2021\n",
      "> time taken: 21.49 seconds\n",
      "- - - - - - - - - - - - - - - \n",
      "scores:\n",
      "mstl_0.5                 0.556668\n",
      "mstl_1                   0.655904\n",
      "xgboost_dummy_2021       0.852273\n",
      "bench_pm_1month          0.878493\n",
      "xgboost_dummy_2020       0.907604\n",
      "xgboost_dummy_2019       0.912484\n",
      "bench_same_month         0.918924\n",
      "bench_pm_2weeks          0.935608\n",
      "lightgbm_dummy_2021       0.94621\n",
      "lightgbm_dummy_2019       0.96611\n",
      "lightgbm_dummy_2020      0.978269\n",
      "grad_boost_2018_fturs    1.580132\n",
      "quant_reg_2018_sk        1.587525\n",
      "grad_boost_2018_dummy    1.589888\n",
      "grad_boost_2015_fturs    1.727347\n",
      "grad_boost_2015_dummy    1.762019\n",
      "quant_reg_2015_sk        1.763417\n",
      "quant_reg_2018_sm        1.834628\n",
      "quant_reg_2015_sm        2.012653\n",
      "dtype: object\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2023-12-20 ...\n",
      "Submission timestamps = 2023-12-22 12:00:00+01:00 to 2023-12-23 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "method = bench_pm_2weeks\n",
      "method = bench_same_month\n",
      "method = bench_pm_1month\n",
      "method = mstl_1\n",
      "method = mstl_0.5\n",
      "method = quant_reg_2015_sk\n",
      "method = quant_reg_2018_sk\n",
      "method = quant_reg_2015_sm\n",
      "method = quant_reg_2018_sm\n",
      "method = grad_boost_2015_fturs\n",
      "method = grad_boost_2018_fturs\n",
      "method = grad_boost_2015_dummy\n",
      "method = grad_boost_2018_dummy\n",
      "method = lightgbm_dummy_2019\n",
      "method = lightgbm_dummy_2020\n",
      "method = lightgbm_dummy_2021\n",
      "method = xgboost_dummy_2019\n",
      "> time taken: 47.50 seconds\n",
      "method = xgboost_dummy_2020\n",
      "> time taken: 26.59 seconds\n",
      "method = xgboost_dummy_2021\n",
      "> time taken: 30.09 seconds\n",
      "- - - - - - - - - - - - - - - \n",
      "scores:\n",
      "mstl_0.5                 0.571368\n",
      "mstl_1                   0.638343\n",
      "xgboost_dummy_2021       1.030355\n",
      "bench_pm_2weeks          1.082114\n",
      "xgboost_dummy_2020       1.240329\n",
      "bench_same_month         1.321246\n",
      "xgboost_dummy_2019       1.350852\n",
      "bench_pm_1month          1.391922\n",
      "quant_reg_2018_sk        1.809459\n",
      "quant_reg_2015_sk        1.852032\n",
      "quant_reg_2018_sm        1.934358\n",
      "quant_reg_2015_sm        2.023638\n",
      "lightgbm_dummy_2020      2.164646\n",
      "grad_boost_2018_fturs    2.221364\n",
      "grad_boost_2018_dummy    2.253075\n",
      "grad_boost_2015_dummy    2.358454\n",
      "grad_boost_2015_fturs    2.481701\n",
      "lightgbm_dummy_2021      2.538469\n",
      "lightgbm_dummy_2019      2.560719\n",
      "dtype: object\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2023-12-27 ...\n",
      "Submission timestamps = 2023-12-29 12:00:00+01:00 to 2023-12-30 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "method = bench_pm_2weeks\n",
      "method = bench_same_month\n",
      "method = bench_pm_1month\n",
      "method = mstl_1\n",
      "method = mstl_0.5\n",
      "method = quant_reg_2015_sk\n",
      "method = quant_reg_2018_sk\n",
      "method = quant_reg_2015_sm\n",
      "method = quant_reg_2018_sm\n",
      "method = grad_boost_2015_fturs\n",
      "method = grad_boost_2018_fturs\n",
      "method = grad_boost_2015_dummy\n",
      "method = grad_boost_2018_dummy\n",
      "method = lightgbm_dummy_2019\n",
      "method = lightgbm_dummy_2020\n",
      "method = lightgbm_dummy_2021\n",
      "method = xgboost_dummy_2019\n",
      "> time taken: 27.33 seconds\n",
      "method = xgboost_dummy_2020\n",
      "> time taken: 27.85 seconds\n",
      "method = xgboost_dummy_2021\n",
      "> time taken: 25.58 seconds\n",
      "- - - - - - - - - - - - - - - \n",
      "scores:\n",
      "xgboost_dummy_2020       0.367458\n",
      "xgboost_dummy_2019       0.443816\n",
      "xgboost_dummy_2021       0.623515\n",
      "quant_reg_2018_sk        0.747086\n",
      "quant_reg_2015_sk        0.794881\n",
      "quant_reg_2018_sm        0.946581\n",
      "quant_reg_2015_sm        0.983195\n",
      "grad_boost_2018_dummy    1.149974\n",
      "lightgbm_dummy_2020      1.154514\n",
      "mstl_1                   1.233439\n",
      "grad_boost_2015_dummy    1.259202\n",
      "mstl_0.5                 1.266604\n",
      "grad_boost_2018_fturs    1.340954\n",
      "lightgbm_dummy_2021      1.431848\n",
      "lightgbm_dummy_2019      1.511377\n",
      "grad_boost_2015_fturs    1.562247\n",
      "bench_pm_2weeks          1.855197\n",
      "bench_same_month         2.778302\n",
      "bench_pm_1month          3.093067\n",
      "dtype: object\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2024-01-03 ...\n",
      "Submission timestamps = 2024-01-05 12:00:00+01:00 to 2024-01-06 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "method = bench_pm_2weeks\n",
      "method = bench_same_month\n",
      "method = bench_pm_1month\n",
      "method = mstl_1\n",
      "method = mstl_0.5\n",
      "method = quant_reg_2015_sk\n",
      "method = quant_reg_2018_sk\n",
      "method = quant_reg_2015_sm\n",
      "method = quant_reg_2018_sm\n",
      "method = grad_boost_2015_fturs\n",
      "method = grad_boost_2018_fturs\n",
      "method = grad_boost_2015_dummy\n",
      "method = grad_boost_2018_dummy\n",
      "method = lightgbm_dummy_2019\n",
      "method = lightgbm_dummy_2020\n",
      "method = lightgbm_dummy_2021\n",
      "method = xgboost_dummy_2019\n",
      "> time taken: 35.38 seconds\n",
      "method = xgboost_dummy_2020\n",
      "> time taken: 31.35 seconds\n",
      "method = xgboost_dummy_2021\n",
      "> time taken: 16.37 seconds\n",
      "- - - - - - - - - - - - - - - \n",
      "scores:\n",
      "lightgbm_dummy_2021      0.533195\n",
      "xgboost_dummy_2020       0.593126\n",
      "xgboost_dummy_2021        0.60909\n",
      "lightgbm_dummy_2020      0.619036\n",
      "xgboost_dummy_2019       0.625801\n",
      "lightgbm_dummy_2019      0.693119\n",
      "mstl_0.5                 0.818903\n",
      "mstl_1                   0.825534\n",
      "quant_reg_2018_sm        1.054786\n",
      "quant_reg_2015_sm        1.170113\n",
      "quant_reg_2018_sk        1.331236\n",
      "quant_reg_2015_sk        1.439159\n",
      "grad_boost_2018_dummy    1.485581\n",
      "grad_boost_2015_dummy    1.485914\n",
      "bench_pm_1month          1.506808\n",
      "bench_same_month         1.698662\n",
      "grad_boost_2018_fturs    1.704708\n",
      "grad_boost_2015_fturs    1.727201\n",
      "bench_pm_2weeks           1.79801\n",
      "dtype: object\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2024-01-10 ...\n",
      "Submission timestamps = 2024-01-12 12:00:00+01:00 to 2024-01-13 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "method = bench_pm_2weeks\n",
      "method = bench_same_month\n",
      "method = bench_pm_1month\n",
      "method = mstl_1\n",
      "method = mstl_0.5\n",
      "method = quant_reg_2015_sk\n",
      "method = quant_reg_2018_sk\n",
      "method = quant_reg_2015_sm\n",
      "method = quant_reg_2018_sm\n",
      "method = grad_boost_2015_fturs\n",
      "method = grad_boost_2018_fturs\n",
      "method = grad_boost_2015_dummy\n",
      "method = grad_boost_2018_dummy\n",
      "method = lightgbm_dummy_2019\n",
      "method = lightgbm_dummy_2020\n",
      "method = lightgbm_dummy_2021\n",
      "method = xgboost_dummy_2019\n",
      "> time taken: 38.02 seconds\n",
      "method = xgboost_dummy_2020\n",
      "> time taken: 30.14 seconds\n",
      "method = xgboost_dummy_2021\n",
      "> time taken: 16.89 seconds\n",
      "- - - - - - - - - - - - - - - \n",
      "scores:\n",
      "grad_boost_2018_fturs    0.431999\n",
      "mstl_0.5                 0.441749\n",
      "grad_boost_2018_dummy    0.475966\n",
      "grad_boost_2015_fturs    0.491413\n",
      "quant_reg_2018_sk        0.520324\n",
      "grad_boost_2015_dummy    0.529927\n",
      "quant_reg_2015_sk        0.560401\n",
      "bench_pm_1month          0.561142\n",
      "quant_reg_2015_sm        0.563365\n",
      "mstl_1                   0.589083\n",
      "bench_pm_2weeks          0.603985\n",
      "quant_reg_2018_sm        0.630143\n",
      "bench_same_month         0.650692\n",
      "xgboost_dummy_2019       1.156025\n",
      "xgboost_dummy_2020       1.206123\n",
      "xgboost_dummy_2021       1.284856\n",
      "lightgbm_dummy_2019      1.329004\n",
      "lightgbm_dummy_2020      1.472495\n",
      "lightgbm_dummy_2021      1.574783\n",
      "dtype: object\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2024-01-17 ...\n",
      "Submission timestamps = 2024-01-19 12:00:00+01:00 to 2024-01-20 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "method = bench_pm_2weeks\n",
      "method = bench_same_month\n",
      "method = bench_pm_1month\n",
      "method = mstl_1\n",
      "method = mstl_0.5\n",
      "method = quant_reg_2015_sk\n",
      "method = quant_reg_2018_sk\n",
      "method = quant_reg_2015_sm\n",
      "method = quant_reg_2018_sm\n",
      "method = grad_boost_2015_fturs\n",
      "method = grad_boost_2018_fturs\n",
      "method = grad_boost_2015_dummy\n",
      "method = grad_boost_2018_dummy\n",
      "method = lightgbm_dummy_2019\n",
      "method = lightgbm_dummy_2020\n",
      "method = lightgbm_dummy_2021\n",
      "method = xgboost_dummy_2019\n",
      "> time taken: 29.58 seconds\n",
      "method = xgboost_dummy_2020\n",
      "> time taken: 28.68 seconds\n",
      "method = xgboost_dummy_2021\n",
      "> time taken: 20.50 seconds\n",
      "- - - - - - - - - - - - - - - \n",
      "scores:\n",
      "grad_boost_2015_fturs    0.264688\n",
      "grad_boost_2015_dummy    0.276642\n",
      "grad_boost_2018_fturs    0.290568\n",
      "grad_boost_2018_dummy    0.335407\n",
      "quant_reg_2015_sk        0.449661\n",
      "quant_reg_2018_sk        0.468695\n",
      "quant_reg_2015_sm        0.572612\n",
      "quant_reg_2018_sm        0.666589\n",
      "bench_pm_1month          0.810513\n",
      "bench_pm_2weeks          0.856817\n",
      "bench_same_month         0.913445\n",
      "mstl_1                   0.944972\n",
      "mstl_0.5                  0.95024\n",
      "xgboost_dummy_2019       1.074207\n",
      "xgboost_dummy_2020       1.189597\n",
      "xgboost_dummy_2021       1.249087\n",
      "lightgbm_dummy_2019      1.490371\n",
      "lightgbm_dummy_2020      1.528936\n",
      "lightgbm_dummy_2021      1.692625\n",
      "dtype: object\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2024-01-24 ...\n",
      "Submission timestamps = 2024-01-26 12:00:00+01:00 to 2024-01-27 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "method = bench_pm_2weeks\n",
      "method = bench_same_month\n",
      "method = bench_pm_1month\n",
      "method = mstl_1\n",
      "method = mstl_0.5\n",
      "method = quant_reg_2015_sk\n",
      "method = quant_reg_2018_sk\n",
      "method = quant_reg_2015_sm\n",
      "method = quant_reg_2018_sm\n",
      "method = grad_boost_2015_fturs\n",
      "method = grad_boost_2018_fturs\n",
      "method = grad_boost_2015_dummy\n",
      "method = grad_boost_2018_dummy\n",
      "method = lightgbm_dummy_2019\n",
      "method = lightgbm_dummy_2020\n",
      "method = lightgbm_dummy_2021\n",
      "method = xgboost_dummy_2019\n",
      "> time taken: 31.88 seconds\n",
      "method = xgboost_dummy_2020\n",
      "> time taken: 32.95 seconds\n",
      "method = xgboost_dummy_2021\n",
      "> time taken: 21.42 seconds\n",
      "- - - - - - - - - - - - - - - \n",
      "scores:\n",
      "lightgbm_dummy_2021      0.445047\n",
      "lightgbm_dummy_2019      0.467603\n",
      "lightgbm_dummy_2020      0.476471\n",
      "xgboost_dummy_2020       0.690523\n",
      "xgboost_dummy_2019         0.6957\n",
      "quant_reg_2018_sm        0.698948\n",
      "xgboost_dummy_2021         0.7355\n",
      "quant_reg_2015_sm         0.76393\n",
      "bench_pm_1month          0.919357\n",
      "grad_boost_2018_dummy    0.989412\n",
      "grad_boost_2015_dummy    1.029433\n",
      "grad_boost_2018_fturs    1.037194\n",
      "bench_same_month         1.107247\n",
      "grad_boost_2015_fturs    1.124979\n",
      "quant_reg_2018_sk        1.244387\n",
      "bench_pm_2weeks          1.265511\n",
      "quant_reg_2015_sk        1.329833\n",
      "mstl_1                   1.346015\n",
      "mstl_0.5                 1.351122\n",
      "dtype: object\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2024-01-31 ...\n",
      "Submission timestamps = 2024-02-02 12:00:00+01:00 to 2024-02-03 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "method = bench_pm_2weeks\n",
      "method = bench_same_month\n",
      "method = bench_pm_1month\n",
      "method = mstl_1\n",
      "method = mstl_0.5\n",
      "method = quant_reg_2015_sk\n",
      "method = quant_reg_2018_sk\n",
      "method = quant_reg_2015_sm\n",
      "method = quant_reg_2018_sm\n",
      "method = grad_boost_2015_fturs\n",
      "method = grad_boost_2018_fturs\n",
      "method = grad_boost_2015_dummy\n",
      "method = grad_boost_2018_dummy\n",
      "method = lightgbm_dummy_2019\n",
      "method = lightgbm_dummy_2020\n",
      "method = lightgbm_dummy_2021\n",
      "method = xgboost_dummy_2019\n",
      "> time taken: 38.85 seconds\n",
      "method = xgboost_dummy_2020\n",
      "> time taken: 24.84 seconds\n",
      "method = xgboost_dummy_2021\n",
      "> time taken: 15.60 seconds\n",
      "- - - - - - - - - - - - - - - \n",
      "scores:\n",
      "lightgbm_dummy_2021      0.358767\n",
      "lightgbm_dummy_2020      0.475503\n",
      "bench_pm_1month          0.500956\n",
      "lightgbm_dummy_2019       0.53195\n",
      "xgboost_dummy_2020       0.536825\n",
      "bench_same_month         0.545609\n",
      "xgboost_dummy_2021       0.585272\n",
      "xgboost_dummy_2019       0.647744\n",
      "mstl_0.5                 0.674178\n",
      "mstl_1                   0.676299\n",
      "grad_boost_2018_dummy    0.677432\n",
      "grad_boost_2018_fturs    0.698055\n",
      "grad_boost_2015_fturs     0.73972\n",
      "grad_boost_2015_dummy    0.745919\n",
      "bench_pm_2weeks          0.807487\n",
      "quant_reg_2018_sk        1.000115\n",
      "quant_reg_2015_sk        1.128942\n",
      "quant_reg_2018_sm        1.227368\n",
      "quant_reg_2015_sm        1.352373\n",
      "dtype: object\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2024-02-07 ...\n",
      "Submission timestamps = 2024-02-09 12:00:00+01:00 to 2024-02-10 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "method = bench_pm_2weeks\n",
      "method = bench_same_month\n",
      "method = bench_pm_1month\n",
      "method = mstl_1\n",
      "method = mstl_0.5\n",
      "method = quant_reg_2015_sk\n",
      "method = quant_reg_2018_sk\n",
      "method = quant_reg_2015_sm\n",
      "method = quant_reg_2018_sm\n",
      "method = grad_boost_2015_fturs\n",
      "method = grad_boost_2018_fturs\n",
      "method = grad_boost_2015_dummy\n",
      "method = grad_boost_2018_dummy\n",
      "method = lightgbm_dummy_2019\n",
      "method = lightgbm_dummy_2020\n",
      "method = lightgbm_dummy_2021\n",
      "method = xgboost_dummy_2019\n",
      "> time taken: 34.32 seconds\n",
      "method = xgboost_dummy_2020\n",
      "> time taken: 26.18 seconds\n",
      "method = xgboost_dummy_2021\n",
      "> time taken: 20.30 seconds\n",
      "- - - - - - - - - - - - - - - \n",
      "scores:\n",
      "mstl_0.5                 0.927075\n",
      "mstl_1                   0.929841\n",
      "bench_pm_1month          0.965325\n",
      "xgboost_dummy_2021       1.063821\n",
      "xgboost_dummy_2020        1.18553\n",
      "xgboost_dummy_2019       1.323442\n",
      "bench_same_month         1.385435\n",
      "grad_boost_2018_fturs    1.417374\n",
      "grad_boost_2018_dummy    1.458363\n",
      "bench_pm_2weeks          1.485214\n",
      "lightgbm_dummy_2021      1.497304\n",
      "grad_boost_2015_fturs    1.557466\n",
      "grad_boost_2015_dummy    1.570719\n",
      "lightgbm_dummy_2019      1.641825\n",
      "lightgbm_dummy_2020      1.646867\n",
      "quant_reg_2018_sk        1.768443\n",
      "quant_reg_2015_sk        1.927346\n",
      "quant_reg_2018_sm        1.992302\n",
      "quant_reg_2015_sm         2.15594\n",
      "dtype: object\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2024-02-14 ...\n",
      "Submission timestamps = 2024-02-16 12:00:00+01:00 to 2024-02-17 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "method = bench_pm_2weeks\n",
      "method = bench_same_month\n",
      "method = bench_pm_1month\n",
      "method = mstl_1\n",
      "method = mstl_0.5\n",
      "method = quant_reg_2015_sk\n",
      "method = quant_reg_2018_sk\n",
      "method = quant_reg_2015_sm\n",
      "method = quant_reg_2018_sm\n",
      "method = grad_boost_2015_fturs\n",
      "method = grad_boost_2018_fturs\n",
      "method = grad_boost_2015_dummy\n",
      "method = grad_boost_2018_dummy\n",
      "method = lightgbm_dummy_2019\n",
      "method = lightgbm_dummy_2020\n",
      "method = lightgbm_dummy_2021\n",
      "method = xgboost_dummy_2019\n",
      "> time taken: 47.04 seconds\n",
      "method = xgboost_dummy_2020\n",
      "> time taken: 30.47 seconds\n",
      "method = xgboost_dummy_2021\n",
      "> time taken: 17.96 seconds\n",
      "- - - - - - - - - - - - - - - \n",
      "scores:\n",
      "mstl_0.5                 0.679218\n",
      "mstl_1                   0.682916\n",
      "xgboost_dummy_2021       1.314141\n",
      "bench_pm_1month          1.419873\n",
      "xgboost_dummy_2020       1.519853\n",
      "xgboost_dummy_2019       1.635316\n",
      "bench_pm_2weeks          1.762079\n",
      "bench_same_month         1.903404\n",
      "grad_boost_2018_fturs    2.061438\n",
      "lightgbm_dummy_2021       2.13707\n",
      "grad_boost_2018_dummy    2.158019\n",
      "grad_boost_2015_fturs    2.192423\n",
      "grad_boost_2015_dummy     2.25619\n",
      "lightgbm_dummy_2020        2.2803\n",
      "lightgbm_dummy_2019      2.337554\n",
      "quant_reg_2018_sk        2.353597\n",
      "quant_reg_2015_sk        2.546783\n",
      "quant_reg_2018_sm        2.565652\n",
      "quant_reg_2015_sm        2.780327\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "folder_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "directory = os.path.join(cwd, folder_name)\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "os.chdir(directory)\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = pd.Timestamp('2023-11-15')\n",
    "end_date = pd.Timestamp('2024-02-14')\n",
    "\n",
    "# Generate a list of weekly dates in UTC\n",
    "fcast_dates_cet = pd.date_range(start=start_date, end=end_date, freq='W-WED').tz_localize('CET').strftime('%Y-%m-%d').tolist()\n",
    "dict_all_fcasts = {}\n",
    "dict_all_evals = {}\n",
    "\n",
    "# Iterate over the forecast dates\n",
    "for fcast_date in fcast_dates_cet[:]:\n",
    "\n",
    "    print('= '*30)\n",
    "    print(f\"Forecasting for week starting from {fcast_date} ...\")\n",
    "    \n",
    "    dict_weekly_fcasts = {}\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # generate prediction timestamps based on t0 = following thursday 00:00\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    # Calculate the Thursday and Wednesday of the week\n",
    "    t_wednesday = pd.Timestamp(fcast_date).replace(hour=0, minute=0, second=0, microsecond=0).tz_localize('CET')\n",
    "    t_thursday = t_wednesday + pd.Timedelta(days=1)\n",
    "\n",
    "    # Generate required submission timestamps\n",
    "    subm_timestamps = [(t_thursday + pd.Timedelta(hours=fcast)) for fcast in fcast_hor]\n",
    "    print(f\"Submission timestamps = {subm_timestamps[0]} to {subm_timestamps[-1]}\")\n",
    "    \n",
    "    # Create df with Information at fcast start date\n",
    "    t_thursday_str = t_thursday.strftime('%Y-%m-%d')\n",
    "    df_energy_current = df_energy.loc[df_energy['timestamp_CET'] <= t_thursday_str].copy()\n",
    "    print('= '*30)\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # Data Prep for All Methods\n",
    "    # = = = = = = = = = = = = = \n",
    "    \n",
    "    # create fcast index for next 68 hours\n",
    "    fcast_timestamp_CET = pd.date_range(start=t_thursday, periods=68+1, freq='H')\n",
    "    fcast_timestamp_UTC = fcast_timestamp_CET.tz_convert('UTC')\n",
    "\n",
    "    # create df with fcast timestamps as INPUT for model\n",
    "    df_temp = pd.DataFrame(index=fcast_timestamp_UTC)\n",
    "    df_temp['timestamp_CET'] = fcast_timestamp_CET\n",
    "    df_fcast_dummy = data_prepro.create_dummy_df(df_temp, hour_method='simple', holiday_method='separate')\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # Simple Benchmark\n",
    "    # = = = = = = = = = = = = = \n",
    "    \n",
    "    # create new dataframe with relevant info for benchmark\n",
    "    df_energy_benchmark = df_energy_current.copy()\n",
    "    df_energy_benchmark[\"month\"] = df_energy_benchmark['timestamp_CET'].dt.month\n",
    "    df_energy_benchmark[\"weekday\"] = df_energy_benchmark['timestamp_CET'].dt.weekday # Monday=0, Sunday=6\n",
    "    df_energy_benchmark[\"weeknum\"] = df_energy_benchmark['timestamp_CET'].dt.isocalendar().week\n",
    "\n",
    "    last_t = 150 # if there are more matches only take the most recent\n",
    "    pred_baseline = np.zeros((3,len(fcast_timestamp_CET),5)) # 3 condition types, 5 quantiles\n",
    "\n",
    "    for i,d in enumerate(fcast_timestamp_CET):\n",
    "            \n",
    "        weekday = d.weekday()\n",
    "        hour = d.hour\n",
    "        weeknum = d.week\n",
    "        \n",
    "        # basic condition that the weekday and hour match\n",
    "        basic_cond = (df_energy_benchmark.weekday == weekday) & (df_energy_benchmark.index.time == d.time())\n",
    "        \n",
    "        # AND the weeknum is within +/- 2 weeks of the target\n",
    "        cond1 = (df_energy_benchmark['weeknum'].between(weeknum-2, weeknum+2)) \n",
    "        # AND the month also matches\n",
    "        cond2 = (df_energy_benchmark.index.month == d.month)\n",
    "        # AND the month is within +/- 1 months of the target\n",
    "        cond3 = (df_energy_benchmark['month'].between(d.month-1, d.month+1))\n",
    "\n",
    "        cond_list = [cond1, cond2, cond3]\n",
    "\n",
    "        for cond_idx, cond in enumerate(cond_list):\n",
    "            cond = basic_cond & cond\n",
    "            match_df = df_energy_benchmark[cond]\n",
    "            # print(f\"condition {cond_idx} ... {len(match_df)} matches found\")\n",
    "            pred_baseline[cond_idx, i, :] = np.quantile(match_df.iloc[-last_t:][\"gesamt\"], q=quantiles) # method='linear'\n",
    "\n",
    "    methods = ['bench_pm_2weeks', 'bench_same_month', 'bench_pm_1month']\n",
    "    for m_idx, method in enumerate(methods):\n",
    "\n",
    "        print(f\"method = {method}\")\n",
    "        # create empty df\n",
    "        df_benchmark = pd.DataFrame(index=fcast_timestamp_UTC, columns=[f\"q {q:.3f}\" for q in quantiles])\n",
    "        df_benchmark.loc[:,:] = pred_baseline[m_idx,:,:]\n",
    "\n",
    "        # make sure all cols are float\n",
    "        df_benchmark = df_benchmark.astype(float)\n",
    "        # add CET col\n",
    "        df_benchmark['timestamp_CET'] = df_benchmark.index.tz_convert('CET')\n",
    "        # reorder cols\n",
    "        df_benchmark = df_benchmark[['timestamp_CET', 'q 0.025', 'q 0.250', 'q 0.500', 'q 0.750', 'q 0.975']]\n",
    "        # save to dict\n",
    "        dict_weekly_fcasts[method] = df_benchmark\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # MSTL\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    mstl_train_horizon = 0.5 # in years\n",
    "\n",
    "    for mstl_train_horizon in [1, 0.5]:\n",
    "        \n",
    "        method = f\"mstl_{mstl_train_horizon}\"\n",
    "        print(f\"method = {method}\")\n",
    "\n",
    "        df_mstl_train = df_energy_current.iloc[-int(mstl_train_horizon * 365 * 24):].copy()\n",
    "        mstl_model = MSTL(season_length=[24, 24 * 7]).fit(df_mstl_train[\"gesamt\"])\n",
    "\n",
    "        n_steps = df_benchmark.shape[0]\n",
    "\n",
    "        y_hat_dict = mstl_model.predict(h=n_steps, level=[50, 95])\n",
    "        y_hat_df = pd.DataFrame(y_hat_dict)\n",
    "        y_hat_df[\"timestamp_CET\"] = pd.date_range(start=t_thursday, periods=len(y_hat_df), freq=\"H\")\n",
    "\n",
    "        # rename columns\n",
    "        y_hat_df = y_hat_df.rename(\n",
    "            columns={\n",
    "                \"mean\": \"q 0.500\",\n",
    "                \"lo-50\": \"q 0.250\",\n",
    "                \"hi-50\": \"q 0.750\",\n",
    "                \"lo-95\": \"q 0.025\",\n",
    "                \"hi-95\": \"q 0.975\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # rearrange cols\n",
    "        y_hat_df = y_hat_df[[\"timestamp_CET\", \"q 0.025\", \"q 0.250\", \"q 0.500\", \"q 0.750\", \"q 0.975\"]]\n",
    "\n",
    "        df_mstl_fcast = y_hat_df\n",
    "        df_mstl_fcast.index = fcast_timestamp_UTC\n",
    "\n",
    "        dict_weekly_fcasts[method] = df_mstl_fcast\n",
    "    \n",
    "    # = = = = = = = = = = = = = \n",
    "    # Quantile Reg\n",
    "    # = = = = = = = = = = = = = \n",
    "    \n",
    "    for method, all_models_quant_reg in quant_reg_models.items():\n",
    "        \n",
    "        print(f\"method = {method}\")\n",
    "\n",
    "        # create empty OUTPUT df with columns = quantiles\n",
    "        df_quant_reg_direct_fcast = pd.DataFrame(index=df_fcast_dummy.index)\n",
    "        df_quant_reg_direct_fcast['timestamp_CET'] = fcast_timestamp_CET\n",
    "\n",
    "        # Prediction for Quantile Regression\n",
    "        for name, model in sorted(all_models_quant_reg.items()):\n",
    "            pred = model.predict(df_fcast_dummy.drop('timestamp_CET', axis=1))\n",
    "            df_quant_reg_direct_fcast[name] = pred\n",
    "\n",
    "        dict_weekly_fcasts[method] = df_quant_reg_direct_fcast\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # Grad Boosting\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    for method, all_models_grad_boost in grad_boost_models.items():\n",
    "\n",
    "        print(f\"method = {method}\")\n",
    "\n",
    "        if \"fturs\" in method:\n",
    "            df_fcast_temp = data_prepro.create_features_df(df_temp, holiday_method='separate')\n",
    "            \n",
    "        elif \"dummy\" in method:\n",
    "            df_fcast_temp = data_prepro.create_dummy_df(df_temp, hour_method='simple', holiday_method='separate')\n",
    "\n",
    "        # create empty OUTPUT df with columns = quantiles\n",
    "        df_grad_boost_direct_fcast = pd.DataFrame(index=df_fcast_temp.index)\n",
    "        df_grad_boost_direct_fcast['timestamp_CET'] = fcast_timestamp_CET\n",
    "\n",
    "        # Prediction for Quantile Regression\n",
    "        for name, model in sorted(all_models_grad_boost.items()):\n",
    "            pred = model.predict(df_fcast_temp.drop('timestamp_CET', axis=1))\n",
    "            df_grad_boost_direct_fcast[name] = pred\n",
    "\n",
    "        dict_weekly_fcasts[method] = df_grad_boost_direct_fcast\n",
    "        \n",
    "    # = = = = = = = = = = = = = \n",
    "    # LightGBM\n",
    "    # = = = = = = = = = = = = = \n",
    "    \n",
    "    years = [2019, 2020, 2021]\n",
    "    methods = [f\"lightgbm_dummy_{yr}\" for yr in years]\n",
    "    \n",
    "    for method_idx, method in enumerate(methods):\n",
    "\n",
    "        print(f\"method = {method}\")\n",
    "        start_date = f\"{years[method_idx]}-01-01\"\n",
    "        X_train_dummy, y_train_dummy, X_train_fturs, y_train_fturs = preprocess_data(df_energy_current, start_date)\n",
    "\n",
    "        all_models = model_train.fit_lightgbm(X_train_dummy, y_train_dummy, quantiles)\n",
    "        df_fcast_temp = data_prepro.create_dummy_df(df_temp, hour_method='simple', holiday_method='separate')\n",
    "\n",
    "        # create empty OUTPUT df with columns = quantiles\n",
    "        df_direct_fcast = pd.DataFrame(index=df_fcast_temp.index)\n",
    "        df_direct_fcast['timestamp_CET'] = fcast_timestamp_CET\n",
    "\n",
    "        # Prediction\n",
    "        for name, model in sorted(all_models.items()):\n",
    "            pred = model.predict(df_fcast_temp.drop('timestamp_CET', axis=1))\n",
    "            df_direct_fcast[name] = pred\n",
    "\n",
    "        dict_weekly_fcasts[method] = df_direct_fcast\n",
    "        \n",
    "    # = = = = = = = = = = = = = \n",
    "    # XGBoost model\n",
    "    # = = = = = = = = = = = = = \n",
    "        \n",
    "    years = [2019, 2020, 2021]\n",
    "    methods = [f\"xgboost_dummy_{yr}\" for yr in years]\n",
    "\n",
    "    for method_idx, method in enumerate(methods):\n",
    "\n",
    "        print(f\"method = {method}\")\n",
    "        start_date = f\"{years[method_idx]}-01-01\"\n",
    "        X_train_dummy, y_train_dummy, X_train_fturs, y_train_fturs = preprocess_data(df_energy_current, start_date)\n",
    "    \n",
    "        all_models = model_train.fit_xgboost(X_train_dummy, y_train_dummy, quantiles)\n",
    "        df_fcast_dummy = data_prepro.create_dummy_df(df_temp, hour_method='simple', holiday_method='separate')\n",
    "\n",
    "        # create empty OUTPUT df with columns = quantiles\n",
    "        df_direct_fcast = pd.DataFrame(index=df_fcast_dummy.index)\n",
    "        df_direct_fcast['timestamp_CET'] = fcast_timestamp_CET\n",
    "\n",
    "        # Prediction\n",
    "        for name, model in sorted(all_models.items()):\n",
    "            pred = model.predict(df_fcast_dummy.drop('timestamp_CET', axis=1))\n",
    "            df_direct_fcast[name] = pred\n",
    "\n",
    "        dict_weekly_fcasts[method] = df_direct_fcast\n",
    "    \n",
    "    # = = = = = = = = = = = = = \n",
    "    # Evaluation based on submission timestamps\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    # get actual values at every submission timestamp\n",
    "    df_energy_eval = df_energy.loc[df_energy['timestamp_CET'].isin(subm_timestamps)].copy()\n",
    "    evaluation_results = {}\n",
    "    \n",
    "    for model_name, forecast_df in dict_weekly_fcasts.items():\n",
    "\n",
    "        # Initialize an empty DataFrame to store quantile scores\n",
    "        quantile_scores = pd.DataFrame(index=subm_timestamps, columns=[f\"q {q:.3f}\" for q in quantiles])\n",
    "        # take subset of fcast df at submission timestamps\n",
    "        forecast_df = forecast_df.loc[forecast_df['timestamp_CET'].isin(subm_timestamps)].copy()\n",
    "\n",
    "        # Iterate over each submission timestamp\n",
    "        for q_idx, q in enumerate(quantiles):\n",
    "\n",
    "            qscore = mean_pinball_loss(alpha=q, \n",
    "                                       y_true=df_energy_eval['gesamt'].values, \n",
    "                                       y_pred=forecast_df.iloc[:,q_idx+1].values) # skip timestamp_CET col\n",
    "            \n",
    "            quantile_scores.iloc[:,q_idx] = qscore / 1000\n",
    "        \n",
    "        # Store the quantile scores for the model\n",
    "        evaluation_results[model_name] = quantile_scores\n",
    "    \n",
    "    # Calculate mean scores for each quantile over time\n",
    "    mean_scores = {}\n",
    "    for model_name, quantile_scores in evaluation_results.items():\n",
    "        mean_scores[model_name] = quantile_scores.mean()\n",
    "    \n",
    "    # df = pd.DataFrame(mean_scores).T\n",
    "    # filtered_df = df[df.index.str.contains('lightgbm')]\n",
    "    # display(filtered_df.style.highlight_min(color='lightgreen', axis=0))\n",
    "\n",
    "    # df = pd.DataFrame(mean_scores).T\n",
    "    # filtered_df = df[df.index.str.contains('xgboost')]\n",
    "    # display(filtered_df.style.highlight_min(color='lightgreen', axis=0))\n",
    "\n",
    "    # calculate mean scores over all quantiles\n",
    "    mean_scores_df = pd.DataFrame(mean_scores)\n",
    "    \n",
    "    print('- '*15)\n",
    "    print('scores:')\n",
    "    print(mean_scores_df.mean(axis=0).sort_values(ascending=True))\n",
    "        \n",
    "    # = = = = = = = = = = = = = \n",
    "    # Save all fcasts & trained models for the week\n",
    "    # = = = = = = = = = = = = = \n",
    "    \n",
    "    dict_all_fcasts[fcast_date] = dict_weekly_fcasts\n",
    "    dict_all_evals[fcast_date] = evaluation_results\n",
    "    \n",
    "with open('eval.pickle', 'wb') as handle:\n",
    "    pickle.dump(dict_all_evals, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('fcasts.pickle', 'wb') as handle:\n",
    "    pickle.dump(dict_all_fcasts, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "os.chdir(cwd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
