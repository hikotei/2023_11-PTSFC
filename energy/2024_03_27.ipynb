{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsforecast.models import MSTL\n",
    "from sklearn.metrics import mean_pinball_loss\n",
    "\n",
    "os.chdir(\"C:/2023_11-PTSFC\")\n",
    "import model_train as model_train\n",
    "import data_prepro as data_prepro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"1\"  # Replace \"4\" with the desired number of cores\n",
    "\n",
    "quantiles = [0.025, 0.25, 0.5, 0.75, 0.975]\n",
    "fcast_hor = [36, 40, 44, 60, 64, 68] # in hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 80136 entries, 2014-12-31 23:00:00+00:00 to 2024-02-21 22:00:00+00:00\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype              \n",
      "---  ------         --------------  -----              \n",
      " 0   timestamp_CET  80136 non-null  datetime64[ns, CET]\n",
      " 1   gesamt         80136 non-null  float64            \n",
      "dtypes: datetime64[ns, CET](1), float64(1)\n",
      "memory usage: 1.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# = = = = = = = = = = = = = \n",
    "# get data\n",
    "# df_energy = data_prepro.get_energy_data_today(to_date=t_wednesday.strftime('%Y%m%d'))\n",
    "\n",
    "# Read data from file with specified data types\n",
    "df_energy = pd.read_csv(\"data/2015-01-01_2024-02-21_energy.csv\", index_col=0, parse_dates=[0])\n",
    "df_energy['timestamp_CET'] = pd.to_datetime(df_energy['timestamp_CET'], utc=True).dt.tz_convert('CET')\n",
    "print(df_energy.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df_energy, start_date):\n",
    "    \n",
    "    df_energy_small = df_energy.loc[(df_energy['timestamp_CET'] > start_date)].copy()\n",
    "    \n",
    "    df_energy_dummy = data_prepro.create_dummy_df(df_energy_small, hour_method='seasonal', holiday_method='separate')\n",
    "    df_energy_fturs = data_prepro.create_features_df(df_energy_small, holiday_method='separate')\n",
    "\n",
    "    X_train_fturs = df_energy_fturs.drop(['gesamt', 'timestamp_CET'], axis=1)\n",
    "    y_train_fturs = df_energy_fturs['gesamt']\n",
    "\n",
    "    X_train_dummy = df_energy_dummy.drop(['gesamt', 'timestamp_CET'], axis=1)\n",
    "    y_train_dummy = df_energy_dummy['gesamt']\n",
    "    \n",
    "    return X_train_dummy, y_train_dummy, X_train_fturs, y_train_fturs\n",
    "\n",
    "def generate_param_grids(params):\n",
    "    \n",
    "        param_values = list(itertools.product(*params.values()))\n",
    "        param_names = list(params.keys())\n",
    "\n",
    "        param_grids = []\n",
    "\n",
    "        for values in param_values:\n",
    "            param_dict = dict(zip(param_names, values))\n",
    "            param_grids.append(param_dict)\n",
    "\n",
    "        return param_grids\n",
    "\n",
    "lgbm_params = {\n",
    "    'max_depth': [4, 10],\n",
    "    'num_leaves': [5, 15, 20],\n",
    "    'learning_rate': [0.1, 0.3],\n",
    "    'n_estimators': [100, 200],\n",
    "    'boosting_type': ['gbdt'],\n",
    "    'verbose': [-1]\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'objective': ['reg:quantileerror'],\n",
    "    'eval_metric': ['quantile'],\n",
    "    'booster': ['gbtree'],\n",
    "    'max_depth': [4, 10],\n",
    "    'learning_rate': [0.2],\n",
    "    'n_estimators': [100, 200],\n",
    "}\n",
    "\n",
    "all_lgbm_params = generate_param_grids(lgbm_params)\n",
    "all_xgb_params = generate_param_grids(xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator QuantileRegressor from version 1.3.0 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator DummyRegressor from version 1.3.0 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.3.0 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator GradientBoostingRegressor from version 1.3.0 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "# import trained models\n",
    "path = f\"custom_models\"\n",
    "\n",
    "def load_pickled_object(path, filename):\n",
    "    with open(f\"{path}/{filename}\", \"rb\") as handle:\n",
    "        return pickle.load(handle)\n",
    "    \n",
    "quant_reg_models = {}\n",
    "quant_reg_models['quant_reg_2015_sk'] = load_pickled_object(path, \"20150101_20231031_all_models_quant_reg_sk.pickle\")\n",
    "quant_reg_models['quant_reg_2018_sk'] = load_pickled_object(path, \"20180101_20231031_all_models_quant_reg_sk.pickle\")\n",
    "quant_reg_models['quant_reg_2015_sm'] = load_pickled_object(path, \"20150101_20231031_all_models_quant_reg_sm.pickle\")\n",
    "quant_reg_models['quant_reg_2018_sm'] = load_pickled_object(path, \"20180101_20231031_all_models_quant_reg_sm.pickle\")\n",
    "\n",
    "grad_boost_models = {}\n",
    "grad_boost_models['grad_boost_2015_fturs'] = load_pickled_object(path, \"20150101_20231031_all_models_grad_boost_fturs.pickle\")\n",
    "grad_boost_models['grad_boost_2018_fturs'] = load_pickled_object(path, \"20180101_20231031_all_models_grad_boost_fturs.pickle\")\n",
    "grad_boost_models['grad_boost_2015_dummy'] = load_pickled_object(path, \"20150101_20231031_all_models_grad_boost_dummy.pickle\")\n",
    "grad_boost_models['grad_boost_2018_dummy'] = load_pickled_object(path, \"20180101_20231031_all_models_grad_boost_dummy.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2024-02-07 ...\n",
      "Submission timestamps = 2024-02-09 12:00:00+01:00 to 2024-02-10 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "method = bench_pm_2weeks\n",
      "method = bench_same_month\n",
      "method = bench_pm_1month\n",
      "method = mstl_1\n",
      "method = mstl_0.5\n",
      "method = quant_reg_2015_sk\n",
      "method = quant_reg_2018_sk\n",
      "method = quant_reg_2015_sm\n",
      "method = quant_reg_2018_sm\n",
      "method = grad_boost_2015_fturs\n",
      "method = grad_boost_2018_fturs\n",
      "method = grad_boost_2015_dummy\n",
      "method = grad_boost_2018_dummy\n",
      "method = lightgbm_dummy_0\n",
      "method = lightgbm_dummy_1\n",
      "method = lightgbm_dummy_2\n",
      "method = lightgbm_dummy_3\n",
      "method = lightgbm_dummy_4\n",
      "method = lightgbm_dummy_5\n",
      "method = lightgbm_dummy_6\n",
      "method = lightgbm_dummy_7\n",
      "method = lightgbm_dummy_8\n",
      "method = lightgbm_dummy_9\n",
      "method = lightgbm_dummy_10\n",
      "method = lightgbm_dummy_11\n",
      "method = lightgbm_dummy_12\n",
      "method = lightgbm_dummy_13\n",
      "method = lightgbm_dummy_14\n",
      "method = lightgbm_dummy_15\n",
      "method = lightgbm_dummy_16\n",
      "method = lightgbm_dummy_17\n",
      "method = lightgbm_dummy_18\n",
      "method = lightgbm_dummy_19\n",
      "method = lightgbm_dummy_20\n",
      "method = lightgbm_dummy_21\n",
      "method = lightgbm_dummy_22\n",
      "method = lightgbm_dummy_23\n",
      "method = xgboost_dummy_0\n",
      "> time taken: 6.92 seconds\n",
      "method = xgboost_dummy_1\n",
      "> time taken: 12.84 seconds\n",
      "method = xgboost_dummy_2\n",
      "> time taken: 7.00 seconds\n",
      "method = xgboost_dummy_3\n",
      "> time taken: 12.77 seconds\n",
      "method = xgboost_dummy_4\n",
      "> time taken: 7.34 seconds\n",
      "method = xgboost_dummy_5\n",
      "> time taken: 14.14 seconds\n",
      "method = xgboost_dummy_6\n",
      "> time taken: 7.28 seconds\n",
      "method = xgboost_dummy_7\n",
      "> time taken: 14.22 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b999b_row0_col0, #T_b999b_row0_col1, #T_b999b_row0_col2, #T_b999b_row0_col3, #T_b999b_row12_col0, #T_b999b_row12_col1, #T_b999b_row12_col2, #T_b999b_row12_col3, #T_b999b_row23_col4 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b999b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b999b_level0_col0\" class=\"col_heading level0 col0\" >q 0.025</th>\n",
       "      <th id=\"T_b999b_level0_col1\" class=\"col_heading level0 col1\" >q 0.250</th>\n",
       "      <th id=\"T_b999b_level0_col2\" class=\"col_heading level0 col2\" >q 0.500</th>\n",
       "      <th id=\"T_b999b_level0_col3\" class=\"col_heading level0 col3\" >q 0.750</th>\n",
       "      <th id=\"T_b999b_level0_col4\" class=\"col_heading level0 col4\" >q 0.975</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row0\" class=\"row_heading level0 row0\" >lightgbm_dummy_0</th>\n",
       "      <td id=\"T_b999b_row0_col0\" class=\"data row0 col0\" >2.035629</td>\n",
       "      <td id=\"T_b999b_row0_col1\" class=\"data row0 col1\" >1.659358</td>\n",
       "      <td id=\"T_b999b_row0_col2\" class=\"data row0 col2\" >1.241278</td>\n",
       "      <td id=\"T_b999b_row0_col3\" class=\"data row0 col3\" >0.823199</td>\n",
       "      <td id=\"T_b999b_row0_col4\" class=\"data row0 col4\" >0.446928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row1\" class=\"row_heading level0 row1\" >lightgbm_dummy_1</th>\n",
       "      <td id=\"T_b999b_row1_col0\" class=\"data row1 col0\" >3.655020</td>\n",
       "      <td id=\"T_b999b_row1_col1\" class=\"data row1 col1\" >2.815433</td>\n",
       "      <td id=\"T_b999b_row1_col2\" class=\"data row1 col2\" >1.882558</td>\n",
       "      <td id=\"T_b999b_row1_col3\" class=\"data row1 col3\" >0.949683</td>\n",
       "      <td id=\"T_b999b_row1_col4\" class=\"data row1 col4\" >0.110095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row2\" class=\"row_heading level0 row2\" >lightgbm_dummy_2</th>\n",
       "      <td id=\"T_b999b_row2_col0\" class=\"data row2 col0\" >3.928066</td>\n",
       "      <td id=\"T_b999b_row2_col1\" class=\"data row2 col1\" >3.021589</td>\n",
       "      <td id=\"T_b999b_row2_col2\" class=\"data row2 col2\" >2.014393</td>\n",
       "      <td id=\"T_b999b_row2_col3\" class=\"data row2 col3\" >1.007196</td>\n",
       "      <td id=\"T_b999b_row2_col4\" class=\"data row2 col4\" >0.100720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row3\" class=\"row_heading level0 row3\" >lightgbm_dummy_3</th>\n",
       "      <td id=\"T_b999b_row3_col0\" class=\"data row3 col0\" >3.838087</td>\n",
       "      <td id=\"T_b999b_row3_col1\" class=\"data row3 col1\" >2.952375</td>\n",
       "      <td id=\"T_b999b_row3_col2\" class=\"data row3 col2\" >1.968250</td>\n",
       "      <td id=\"T_b999b_row3_col3\" class=\"data row3 col3\" >0.984125</td>\n",
       "      <td id=\"T_b999b_row3_col4\" class=\"data row3 col4\" >0.098412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row4\" class=\"row_heading level0 row4\" >lightgbm_dummy_4</th>\n",
       "      <td id=\"T_b999b_row4_col0\" class=\"data row4 col0\" >2.529406</td>\n",
       "      <td id=\"T_b999b_row4_col1\" class=\"data row4 col1\" >2.018146</td>\n",
       "      <td id=\"T_b999b_row4_col2\" class=\"data row4 col2\" >1.450080</td>\n",
       "      <td id=\"T_b999b_row4_col3\" class=\"data row4 col3\" >0.882015</td>\n",
       "      <td id=\"T_b999b_row4_col4\" class=\"data row4 col4\" >0.370755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row5\" class=\"row_heading level0 row5\" >lightgbm_dummy_5</th>\n",
       "      <td id=\"T_b999b_row5_col0\" class=\"data row5 col0\" >3.832419</td>\n",
       "      <td id=\"T_b999b_row5_col1\" class=\"data row5 col1\" >2.948015</td>\n",
       "      <td id=\"T_b999b_row5_col2\" class=\"data row5 col2\" >1.965343</td>\n",
       "      <td id=\"T_b999b_row5_col3\" class=\"data row5 col3\" >0.982672</td>\n",
       "      <td id=\"T_b999b_row5_col4\" class=\"data row5 col4\" >0.098267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row6\" class=\"row_heading level0 row6\" >lightgbm_dummy_6</th>\n",
       "      <td id=\"T_b999b_row6_col0\" class=\"data row6 col0\" >4.121118</td>\n",
       "      <td id=\"T_b999b_row6_col1\" class=\"data row6 col1\" >3.170091</td>\n",
       "      <td id=\"T_b999b_row6_col2\" class=\"data row6 col2\" >2.113394</td>\n",
       "      <td id=\"T_b999b_row6_col3\" class=\"data row6 col3\" >1.056697</td>\n",
       "      <td id=\"T_b999b_row6_col4\" class=\"data row6 col4\" >0.105670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row7\" class=\"row_heading level0 row7\" >lightgbm_dummy_7</th>\n",
       "      <td id=\"T_b999b_row7_col0\" class=\"data row7 col0\" >3.618979</td>\n",
       "      <td id=\"T_b999b_row7_col1\" class=\"data row7 col1\" >2.783830</td>\n",
       "      <td id=\"T_b999b_row7_col2\" class=\"data row7 col2\" >1.855887</td>\n",
       "      <td id=\"T_b999b_row7_col3\" class=\"data row7 col3\" >0.927943</td>\n",
       "      <td id=\"T_b999b_row7_col4\" class=\"data row7 col4\" >0.092794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row8\" class=\"row_heading level0 row8\" >lightgbm_dummy_8</th>\n",
       "      <td id=\"T_b999b_row8_col0\" class=\"data row8 col0\" >2.529406</td>\n",
       "      <td id=\"T_b999b_row8_col1\" class=\"data row8 col1\" >2.018146</td>\n",
       "      <td id=\"T_b999b_row8_col2\" class=\"data row8 col2\" >1.450080</td>\n",
       "      <td id=\"T_b999b_row8_col3\" class=\"data row8 col3\" >0.882015</td>\n",
       "      <td id=\"T_b999b_row8_col4\" class=\"data row8 col4\" >0.370755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row9\" class=\"row_heading level0 row9\" >lightgbm_dummy_9</th>\n",
       "      <td id=\"T_b999b_row9_col0\" class=\"data row9 col0\" >3.832419</td>\n",
       "      <td id=\"T_b999b_row9_col1\" class=\"data row9 col1\" >2.948015</td>\n",
       "      <td id=\"T_b999b_row9_col2\" class=\"data row9 col2\" >1.965343</td>\n",
       "      <td id=\"T_b999b_row9_col3\" class=\"data row9 col3\" >0.982672</td>\n",
       "      <td id=\"T_b999b_row9_col4\" class=\"data row9 col4\" >0.098267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row10\" class=\"row_heading level0 row10\" >lightgbm_dummy_10</th>\n",
       "      <td id=\"T_b999b_row10_col0\" class=\"data row10 col0\" >4.121118</td>\n",
       "      <td id=\"T_b999b_row10_col1\" class=\"data row10 col1\" >3.170091</td>\n",
       "      <td id=\"T_b999b_row10_col2\" class=\"data row10 col2\" >2.113394</td>\n",
       "      <td id=\"T_b999b_row10_col3\" class=\"data row10 col3\" >1.056697</td>\n",
       "      <td id=\"T_b999b_row10_col4\" class=\"data row10 col4\" >0.105670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row11\" class=\"row_heading level0 row11\" >lightgbm_dummy_11</th>\n",
       "      <td id=\"T_b999b_row11_col0\" class=\"data row11 col0\" >3.618979</td>\n",
       "      <td id=\"T_b999b_row11_col1\" class=\"data row11 col1\" >2.783830</td>\n",
       "      <td id=\"T_b999b_row11_col2\" class=\"data row11 col2\" >1.855887</td>\n",
       "      <td id=\"T_b999b_row11_col3\" class=\"data row11 col3\" >0.927943</td>\n",
       "      <td id=\"T_b999b_row11_col4\" class=\"data row11 col4\" >0.092794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row12\" class=\"row_heading level0 row12\" >lightgbm_dummy_12</th>\n",
       "      <td id=\"T_b999b_row12_col0\" class=\"data row12 col0\" >2.035629</td>\n",
       "      <td id=\"T_b999b_row12_col1\" class=\"data row12 col1\" >1.659358</td>\n",
       "      <td id=\"T_b999b_row12_col2\" class=\"data row12 col2\" >1.241278</td>\n",
       "      <td id=\"T_b999b_row12_col3\" class=\"data row12 col3\" >0.823199</td>\n",
       "      <td id=\"T_b999b_row12_col4\" class=\"data row12 col4\" >0.446928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row13\" class=\"row_heading level0 row13\" >lightgbm_dummy_13</th>\n",
       "      <td id=\"T_b999b_row13_col0\" class=\"data row13 col0\" >3.655020</td>\n",
       "      <td id=\"T_b999b_row13_col1\" class=\"data row13 col1\" >2.815433</td>\n",
       "      <td id=\"T_b999b_row13_col2\" class=\"data row13 col2\" >1.882558</td>\n",
       "      <td id=\"T_b999b_row13_col3\" class=\"data row13 col3\" >0.949683</td>\n",
       "      <td id=\"T_b999b_row13_col4\" class=\"data row13 col4\" >0.110095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row14\" class=\"row_heading level0 row14\" >lightgbm_dummy_14</th>\n",
       "      <td id=\"T_b999b_row14_col0\" class=\"data row14 col0\" >3.928066</td>\n",
       "      <td id=\"T_b999b_row14_col1\" class=\"data row14 col1\" >3.021589</td>\n",
       "      <td id=\"T_b999b_row14_col2\" class=\"data row14 col2\" >2.014393</td>\n",
       "      <td id=\"T_b999b_row14_col3\" class=\"data row14 col3\" >1.007196</td>\n",
       "      <td id=\"T_b999b_row14_col4\" class=\"data row14 col4\" >0.100720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row15\" class=\"row_heading level0 row15\" >lightgbm_dummy_15</th>\n",
       "      <td id=\"T_b999b_row15_col0\" class=\"data row15 col0\" >3.838087</td>\n",
       "      <td id=\"T_b999b_row15_col1\" class=\"data row15 col1\" >2.952375</td>\n",
       "      <td id=\"T_b999b_row15_col2\" class=\"data row15 col2\" >1.968250</td>\n",
       "      <td id=\"T_b999b_row15_col3\" class=\"data row15 col3\" >0.984125</td>\n",
       "      <td id=\"T_b999b_row15_col4\" class=\"data row15 col4\" >0.098412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row16\" class=\"row_heading level0 row16\" >lightgbm_dummy_16</th>\n",
       "      <td id=\"T_b999b_row16_col0\" class=\"data row16 col0\" >3.632743</td>\n",
       "      <td id=\"T_b999b_row16_col1\" class=\"data row16 col1\" >2.806433</td>\n",
       "      <td id=\"T_b999b_row16_col2\" class=\"data row16 col2\" >1.888310</td>\n",
       "      <td id=\"T_b999b_row16_col3\" class=\"data row16 col3\" >0.970187</td>\n",
       "      <td id=\"T_b999b_row16_col4\" class=\"data row16 col4\" >0.143877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row17\" class=\"row_heading level0 row17\" >lightgbm_dummy_17</th>\n",
       "      <td id=\"T_b999b_row17_col0\" class=\"data row17 col0\" >3.668449</td>\n",
       "      <td id=\"T_b999b_row17_col1\" class=\"data row17 col1\" >2.821884</td>\n",
       "      <td id=\"T_b999b_row17_col2\" class=\"data row17 col2\" >1.881256</td>\n",
       "      <td id=\"T_b999b_row17_col3\" class=\"data row17 col3\" >0.940628</td>\n",
       "      <td id=\"T_b999b_row17_col4\" class=\"data row17 col4\" >0.094063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row18\" class=\"row_heading level0 row18\" >lightgbm_dummy_18</th>\n",
       "      <td id=\"T_b999b_row18_col0\" class=\"data row18 col0\" >3.607495</td>\n",
       "      <td id=\"T_b999b_row18_col1\" class=\"data row18 col1\" >2.774996</td>\n",
       "      <td id=\"T_b999b_row18_col2\" class=\"data row18 col2\" >1.849998</td>\n",
       "      <td id=\"T_b999b_row18_col3\" class=\"data row18 col3\" >0.924999</td>\n",
       "      <td id=\"T_b999b_row18_col4\" class=\"data row18 col4\" >0.092500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row19\" class=\"row_heading level0 row19\" >lightgbm_dummy_19</th>\n",
       "      <td id=\"T_b999b_row19_col0\" class=\"data row19 col0\" >3.472231</td>\n",
       "      <td id=\"T_b999b_row19_col1\" class=\"data row19 col1\" >2.670947</td>\n",
       "      <td id=\"T_b999b_row19_col2\" class=\"data row19 col2\" >1.780631</td>\n",
       "      <td id=\"T_b999b_row19_col3\" class=\"data row19 col3\" >0.890316</td>\n",
       "      <td id=\"T_b999b_row19_col4\" class=\"data row19 col4\" >0.089032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row20\" class=\"row_heading level0 row20\" >lightgbm_dummy_20</th>\n",
       "      <td id=\"T_b999b_row20_col0\" class=\"data row20 col0\" >3.401005</td>\n",
       "      <td id=\"T_b999b_row20_col1\" class=\"data row20 col1\" >2.634220</td>\n",
       "      <td id=\"T_b999b_row20_col2\" class=\"data row20 col2\" >1.782237</td>\n",
       "      <td id=\"T_b999b_row20_col3\" class=\"data row20 col3\" >0.930254</td>\n",
       "      <td id=\"T_b999b_row20_col4\" class=\"data row20 col4\" >0.163469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row21\" class=\"row_heading level0 row21\" >lightgbm_dummy_21</th>\n",
       "      <td id=\"T_b999b_row21_col0\" class=\"data row21 col0\" >3.533378</td>\n",
       "      <td id=\"T_b999b_row21_col1\" class=\"data row21 col1\" >2.717983</td>\n",
       "      <td id=\"T_b999b_row21_col2\" class=\"data row21 col2\" >1.811989</td>\n",
       "      <td id=\"T_b999b_row21_col3\" class=\"data row21 col3\" >0.905994</td>\n",
       "      <td id=\"T_b999b_row21_col4\" class=\"data row21 col4\" >0.090599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row22\" class=\"row_heading level0 row22\" >lightgbm_dummy_22</th>\n",
       "      <td id=\"T_b999b_row22_col0\" class=\"data row22 col0\" >3.491415</td>\n",
       "      <td id=\"T_b999b_row22_col1\" class=\"data row22 col1\" >2.685704</td>\n",
       "      <td id=\"T_b999b_row22_col2\" class=\"data row22 col2\" >1.790469</td>\n",
       "      <td id=\"T_b999b_row22_col3\" class=\"data row22 col3\" >0.895235</td>\n",
       "      <td id=\"T_b999b_row22_col4\" class=\"data row22 col4\" >0.089523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b999b_level0_row23\" class=\"row_heading level0 row23\" >lightgbm_dummy_23</th>\n",
       "      <td id=\"T_b999b_row23_col0\" class=\"data row23 col0\" >3.367846</td>\n",
       "      <td id=\"T_b999b_row23_col1\" class=\"data row23 col1\" >2.590651</td>\n",
       "      <td id=\"T_b999b_row23_col2\" class=\"data row23 col2\" >1.727101</td>\n",
       "      <td id=\"T_b999b_row23_col3\" class=\"data row23 col3\" >0.863550</td>\n",
       "      <td id=\"T_b999b_row23_col4\" class=\"data row23 col4\" >0.086355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x199b449f890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_74dc9_row0_col1, #T_74dc9_row0_col3, #T_74dc9_row5_col0, #T_74dc9_row5_col4, #T_74dc9_row7_col2 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_74dc9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_74dc9_level0_col0\" class=\"col_heading level0 col0\" >q 0.025</th>\n",
       "      <th id=\"T_74dc9_level0_col1\" class=\"col_heading level0 col1\" >q 0.250</th>\n",
       "      <th id=\"T_74dc9_level0_col2\" class=\"col_heading level0 col2\" >q 0.500</th>\n",
       "      <th id=\"T_74dc9_level0_col3\" class=\"col_heading level0 col3\" >q 0.750</th>\n",
       "      <th id=\"T_74dc9_level0_col4\" class=\"col_heading level0 col4\" >q 0.975</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_74dc9_level0_row0\" class=\"row_heading level0 row0\" >xgboost_dummy_0</th>\n",
       "      <td id=\"T_74dc9_row0_col0\" class=\"data row0 col0\" >0.322995</td>\n",
       "      <td id=\"T_74dc9_row0_col1\" class=\"data row0 col1\" >1.024482</td>\n",
       "      <td id=\"T_74dc9_row0_col2\" class=\"data row0 col2\" >1.475861</td>\n",
       "      <td id=\"T_74dc9_row0_col3\" class=\"data row0 col3\" >1.182766</td>\n",
       "      <td id=\"T_74dc9_row0_col4\" class=\"data row0 col4\" >0.234152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74dc9_level0_row1\" class=\"row_heading level0 row1\" >xgboost_dummy_1</th>\n",
       "      <td id=\"T_74dc9_row1_col0\" class=\"data row1 col0\" >0.235914</td>\n",
       "      <td id=\"T_74dc9_row1_col1\" class=\"data row1 col1\" >1.185276</td>\n",
       "      <td id=\"T_74dc9_row1_col2\" class=\"data row1 col2\" >1.798276</td>\n",
       "      <td id=\"T_74dc9_row1_col3\" class=\"data row1 col3\" >1.480671</td>\n",
       "      <td id=\"T_74dc9_row1_col4\" class=\"data row1 col4\" >0.236916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74dc9_level0_row2\" class=\"row_heading level0 row2\" >xgboost_dummy_2</th>\n",
       "      <td id=\"T_74dc9_row2_col0\" class=\"data row2 col0\" >0.152435</td>\n",
       "      <td id=\"T_74dc9_row2_col1\" class=\"data row2 col1\" >1.267020</td>\n",
       "      <td id=\"T_74dc9_row2_col2\" class=\"data row2 col2\" >1.870694</td>\n",
       "      <td id=\"T_74dc9_row2_col3\" class=\"data row2 col3\" >1.701778</td>\n",
       "      <td id=\"T_74dc9_row2_col4\" class=\"data row2 col4\" >0.238023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74dc9_level0_row3\" class=\"row_heading level0 row3\" >xgboost_dummy_3</th>\n",
       "      <td id=\"T_74dc9_row3_col0\" class=\"data row3 col0\" >0.247873</td>\n",
       "      <td id=\"T_74dc9_row3_col1\" class=\"data row3 col1\" >1.257904</td>\n",
       "      <td id=\"T_74dc9_row3_col2\" class=\"data row3 col2\" >1.609496</td>\n",
       "      <td id=\"T_74dc9_row3_col3\" class=\"data row3 col3\" >1.696193</td>\n",
       "      <td id=\"T_74dc9_row3_col4\" class=\"data row3 col4\" >0.217344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74dc9_level0_row4\" class=\"row_heading level0 row4\" >xgboost_dummy_4</th>\n",
       "      <td id=\"T_74dc9_row4_col0\" class=\"data row4 col0\" >0.281442</td>\n",
       "      <td id=\"T_74dc9_row4_col1\" class=\"data row4 col1\" >1.109021</td>\n",
       "      <td id=\"T_74dc9_row4_col2\" class=\"data row4 col2\" >1.339661</td>\n",
       "      <td id=\"T_74dc9_row4_col3\" class=\"data row4 col3\" >1.574613</td>\n",
       "      <td id=\"T_74dc9_row4_col4\" class=\"data row4 col4\" >0.216000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74dc9_level0_row5\" class=\"row_heading level0 row5\" >xgboost_dummy_5</th>\n",
       "      <td id=\"T_74dc9_row5_col0\" class=\"data row5 col0\" >0.140824</td>\n",
       "      <td id=\"T_74dc9_row5_col1\" class=\"data row5 col1\" >1.049162</td>\n",
       "      <td id=\"T_74dc9_row5_col2\" class=\"data row5 col2\" >1.274824</td>\n",
       "      <td id=\"T_74dc9_row5_col3\" class=\"data row5 col3\" >1.645738</td>\n",
       "      <td id=\"T_74dc9_row5_col4\" class=\"data row5 col4\" >0.212347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74dc9_level0_row6\" class=\"row_heading level0 row6\" >xgboost_dummy_6</th>\n",
       "      <td id=\"T_74dc9_row6_col0\" class=\"data row6 col0\" >0.213383</td>\n",
       "      <td id=\"T_74dc9_row6_col1\" class=\"data row6 col1\" >1.034239</td>\n",
       "      <td id=\"T_74dc9_row6_col2\" class=\"data row6 col2\" >1.363723</td>\n",
       "      <td id=\"T_74dc9_row6_col3\" class=\"data row6 col3\" >1.573237</td>\n",
       "      <td id=\"T_74dc9_row6_col4\" class=\"data row6 col4\" >0.217011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74dc9_level0_row7\" class=\"row_heading level0 row7\" >xgboost_dummy_7</th>\n",
       "      <td id=\"T_74dc9_row7_col0\" class=\"data row7 col0\" >0.147166</td>\n",
       "      <td id=\"T_74dc9_row7_col1\" class=\"data row7 col1\" >1.026704</td>\n",
       "      <td id=\"T_74dc9_row7_col2\" class=\"data row7 col2\" >1.274263</td>\n",
       "      <td id=\"T_74dc9_row7_col3\" class=\"data row7 col3\" >1.581007</td>\n",
       "      <td id=\"T_74dc9_row7_col4\" class=\"data row7 col4\" >0.215913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x199b4420390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - - - - - - - \n",
      "scores:\n",
      "xgboost_dummy_0          0.848051\n",
      "xgboost_dummy_7           0.84901\n",
      "xgboost_dummy_5          0.864579\n",
      "xgboost_dummy_6          0.880319\n",
      "xgboost_dummy_4          0.904147\n",
      "mstl_0.5                 0.927075\n",
      "mstl_1                   0.929841\n",
      "bench_pm_1month          0.965325\n",
      "xgboost_dummy_1           0.98741\n",
      "xgboost_dummy_3          1.005762\n",
      "xgboost_dummy_2           1.04599\n",
      "lightgbm_dummy_0         1.241278\n",
      "lightgbm_dummy_12        1.241278\n",
      "bench_same_month         1.385435\n",
      "grad_boost_2018_fturs    1.417374\n",
      "grad_boost_2018_dummy    1.436414\n",
      "lightgbm_dummy_8          1.45008\n",
      "lightgbm_dummy_4          1.45008\n",
      "bench_pm_2weeks          1.485214\n",
      "grad_boost_2015_dummy    1.518415\n",
      "grad_boost_2015_fturs    1.557466\n",
      "lightgbm_dummy_23        1.727101\n",
      "quant_reg_2018_sk        1.745476\n",
      "lightgbm_dummy_19        1.780631\n",
      "lightgbm_dummy_20        1.782237\n",
      "lightgbm_dummy_22        1.790469\n",
      "lightgbm_dummy_21        1.811989\n",
      "lightgbm_dummy_18        1.849998\n",
      "lightgbm_dummy_7         1.855887\n",
      "lightgbm_dummy_11        1.855887\n",
      "lightgbm_dummy_17        1.881256\n",
      "lightgbm_dummy_1         1.882558\n",
      "lightgbm_dummy_13        1.882558\n",
      "lightgbm_dummy_16         1.88831\n",
      "quant_reg_2015_sk        1.945777\n",
      "lightgbm_dummy_9         1.965343\n",
      "lightgbm_dummy_5         1.965343\n",
      "lightgbm_dummy_15         1.96825\n",
      "lightgbm_dummy_3          1.96825\n",
      "lightgbm_dummy_14        2.014393\n",
      "lightgbm_dummy_2         2.014393\n",
      "quant_reg_2018_sm        2.082864\n",
      "lightgbm_dummy_10        2.113394\n",
      "lightgbm_dummy_6         2.113394\n",
      "quant_reg_2015_sm        2.265156\n",
      "dtype: object\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2024-02-14 ...\n",
      "Submission timestamps = 2024-02-16 12:00:00+01:00 to 2024-02-17 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "method = bench_pm_2weeks\n",
      "method = bench_same_month\n",
      "method = bench_pm_1month\n",
      "method = mstl_1\n",
      "method = mstl_0.5\n",
      "method = quant_reg_2015_sk\n",
      "method = quant_reg_2018_sk\n",
      "method = quant_reg_2015_sm\n",
      "method = quant_reg_2018_sm\n",
      "method = grad_boost_2015_fturs\n",
      "method = grad_boost_2018_fturs\n",
      "method = grad_boost_2015_dummy\n",
      "method = grad_boost_2018_dummy\n",
      "method = lightgbm_dummy_0\n",
      "method = lightgbm_dummy_1\n",
      "method = lightgbm_dummy_2\n",
      "method = lightgbm_dummy_3\n",
      "method = lightgbm_dummy_4\n",
      "method = lightgbm_dummy_5\n",
      "method = lightgbm_dummy_6\n",
      "method = lightgbm_dummy_7\n",
      "method = lightgbm_dummy_8\n",
      "method = lightgbm_dummy_9\n",
      "method = lightgbm_dummy_10\n",
      "method = lightgbm_dummy_11\n",
      "method = lightgbm_dummy_12\n",
      "method = lightgbm_dummy_13\n",
      "method = lightgbm_dummy_14\n",
      "method = lightgbm_dummy_15\n",
      "method = lightgbm_dummy_16\n",
      "method = lightgbm_dummy_17\n",
      "method = lightgbm_dummy_18\n",
      "method = lightgbm_dummy_19\n",
      "method = lightgbm_dummy_20\n",
      "method = lightgbm_dummy_21\n",
      "method = lightgbm_dummy_22\n",
      "method = lightgbm_dummy_23\n",
      "method = xgboost_dummy_0\n",
      "> time taken: 7.65 seconds\n",
      "method = xgboost_dummy_1\n",
      "> time taken: 13.96 seconds\n",
      "method = xgboost_dummy_2\n",
      "> time taken: 8.57 seconds\n",
      "method = xgboost_dummy_3\n",
      "> time taken: 14.55 seconds\n",
      "method = xgboost_dummy_4\n",
      "> time taken: 8.68 seconds\n",
      "method = xgboost_dummy_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <bound method DataIter._next_wrapper of <xgboost.data.SingleBatchInternalIter object at 0x00000199BA131D10>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\core.py\", line 641, in _next_wrapper\n",
      "    return self._handle_exception(lambda: self.next(input_data), 0)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\core.py\", line 557, in _handle_exception\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\core.py\", line 641, in <lambda>\n",
      "    return self._handle_exception(lambda: self.next(input_data), 0)\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\data.py\", line 1280, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\core.py\", line 624, in input_data\n",
      "    new, cat_codes, feature_names, feature_types = _proxy_transform(\n",
      "                                                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\data.py\", line 1315, in _proxy_transform\n",
      "    arr, feature_names, feature_types = _transform_pandas_df(\n",
      "                                        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\data.py\", line 498, in _transform_pandas_df\n",
      "    transformed = pandas_cat_null(data)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\data.py\", line 415, in pandas_cat_null\n",
      "    elif is_nullable_dtype(dtype):\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\data.py\", line 351, in is_nullable_dtype\n",
      "    is_bool = is_bool_dtype(dtype) and dtype.name == \"boolean\"\n",
      "              ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\common.py\", line 1235, in is_bool_dtype\n",
      "    if isinstance(arr_or_dtype, ABCIndex):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\generic.py\", line 44, in _instancecheck\n",
      "    return _check(inst) and not isinstance(inst, type)\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\generic.py\", line 37, in _check\n",
      "    def _check(inst) -> bool:\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[22:36:39] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\data\\proxy_dmatrix.h:158: Unknown type: void",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 239\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    237\u001b[0m params \u001b[38;5;241m=\u001b[39m all_xgb_params[method_idx]\n\u001b[1;32m--> 239\u001b[0m all_models \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_xgboost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_dummy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_dummy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m dict_weekly_models[method] \u001b[38;5;241m=\u001b[39m all_models\n\u001b[0;32m    242\u001b[0m \u001b[38;5;66;03m# create empty OUTPUT df with columns = quantiles\u001b[39;00m\n",
      "File \u001b[1;32mC:\\2023_11-PTSFC\\model_train.py:30\u001b[0m, in \u001b[0;36mfit_xgboost\u001b[1;34m(X_train, y_train, quantiles, params)\u001b[0m\n\u001b[0;32m     27\u001b[0m all_models \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m alpha \u001b[38;5;129;01min\u001b[39;00m quantiles:\n\u001b[1;32m---> 30\u001b[0m     xgb_model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBRegressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantile_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     all_models[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malpha\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m xgb_model\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# print time taken\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1055\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[0;32m   1054\u001b[0m     evals_result: TrainingCallback\u001b[38;5;241m.\u001b[39mEvalsLog \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1055\u001b[0m     train_dmatrix, evals \u001b[38;5;241m=\u001b[39m \u001b[43m_wrap_evaluation_matrices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1064\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_qid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_dmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1073\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1075\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "File \u001b[1;32mc:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\sklearn.py:521\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_evaluation_matrices\u001b[39m(\n\u001b[0;32m    502\u001b[0m     missing: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[0;32m    503\u001b[0m     X: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    517\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[0;32m    518\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m    519\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;124;03m    way.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 521\u001b[0m     train_dmatrix \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dmatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m     n_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(eval_set)\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence:\n",
      "File \u001b[1;32mc:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\sklearn.py:958\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[1;34m(self, ref, **kwargs)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _can_use_qdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_method) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbooster \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 958\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mQuantileDMatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnthread\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_bin\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[0;32m    962\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\core.py:1529\u001b[0m, in \u001b[0;36mQuantileDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m   1510\u001b[0m         info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1511\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1522\u001b[0m         )\n\u001b[0;32m   1523\u001b[0m     ):\n\u001b[0;32m   1524\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1525\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf data iterator is used as input, data like label should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1526\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified as batch argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1527\u001b[0m         )\n\u001b[1;32m-> 1529\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\core.py:1590\u001b[0m, in \u001b[0;36mQuantileDMatrix._init\u001b[1;34m(self, data, ref, enable_categorical, **meta)\u001b[0m\n\u001b[0;32m   1588\u001b[0m it\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[0;32m   1589\u001b[0m \u001b[38;5;66;03m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[1;32m-> 1590\u001b[0m \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1591\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;241m=\u001b[39m handle\n",
      "File \u001b[1;32mc:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\core.py:282\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \n\u001b[0;32m    273\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [22:36:39] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\data\\proxy_dmatrix.h:158: Unknown type: void"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "folder_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "directory = os.path.join(cwd, folder_name)\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "os.chdir(directory)\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = pd.Timestamp('2023-11-15')\n",
    "end_date = pd.Timestamp('2024-02-14')\n",
    "\n",
    "# Generate a list of weekly dates in UTC\n",
    "fcast_dates_cet = pd.date_range(start=start_date, end=end_date, freq='W-WED').tz_localize('CET').strftime('%Y-%m-%d').tolist()\n",
    "dict_all_fcasts = {}\n",
    "dict_all_evals = {}\n",
    "\n",
    "# Iterate over the forecast dates\n",
    "for fcast_date in fcast_dates_cet[-2:]:\n",
    "\n",
    "    print('= '*30)\n",
    "    print(f\"Forecasting for week starting from {fcast_date} ...\")\n",
    "    \n",
    "    dict_weekly_fcasts = {}\n",
    "    dict_weekly_models = {}\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # generate prediction timestamps based on t0 = following thursday 00:00\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    # Calculate the Thursday and Wednesday of the week\n",
    "    t_wednesday = pd.Timestamp(fcast_date).replace(hour=0, minute=0, second=0, microsecond=0).tz_localize('CET')\n",
    "    t_thursday = t_wednesday + pd.Timedelta(days=1)\n",
    "\n",
    "    # Generate required submission timestamps\n",
    "    subm_timestamps = [(t_thursday + pd.Timedelta(hours=fcast)) for fcast in fcast_hor]\n",
    "    print(f\"Submission timestamps = {subm_timestamps[0]} to {subm_timestamps[-1]}\")\n",
    "    \n",
    "    # Create df with Information at fcast start date\n",
    "    t_thursday_str = t_thursday.strftime('%Y-%m-%d')\n",
    "    df_energy_current = df_energy.loc[df_energy['timestamp_CET'] <= t_thursday_str].copy()\n",
    "    print('= '*30)\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # Simple Benchmark\n",
    "    # = = = = = = = = = = = = = \n",
    "    \n",
    "    # create fcast index for next 68 hours\n",
    "    fcast_timestamp_CET = pd.date_range(start=t_thursday, periods=68+1, freq='H')\n",
    "    fcast_timestamp_UTC = fcast_timestamp_CET.tz_convert('UTC')\n",
    "    \n",
    "    # create new dataframe with relevant info for benchmark\n",
    "    df_energy_benchmark = df_energy_current.copy()\n",
    "    df_energy_benchmark[\"month\"] = df_energy_benchmark['timestamp_CET'].dt.month\n",
    "    df_energy_benchmark[\"weekday\"] = df_energy_benchmark['timestamp_CET'].dt.weekday # Monday=0, Sunday=6\n",
    "    df_energy_benchmark[\"weeknum\"] = df_energy_benchmark['timestamp_CET'].dt.isocalendar().week\n",
    "\n",
    "    last_t = 150 # if there are more matches only take the most recent\n",
    "    pred_baseline = np.zeros((3,len(fcast_timestamp_CET),5)) # 3 condition types, 5 quantiles\n",
    "\n",
    "    for i,d in enumerate(fcast_timestamp_CET):\n",
    "            \n",
    "        weekday = d.weekday()\n",
    "        hour = d.hour\n",
    "        weeknum = d.week\n",
    "        \n",
    "        # basic condition that the weekday and hour match\n",
    "        basic_cond = (df_energy_benchmark.weekday == weekday) & (df_energy_benchmark.index.time == d.time())\n",
    "        \n",
    "        # AND the weeknum is within +/- 2 weeks of the target\n",
    "        cond1 = (df_energy_benchmark['weeknum'].between(weeknum-2, weeknum+2)) \n",
    "        # AND the month also matches\n",
    "        cond2 = (df_energy_benchmark.index.month == d.month)\n",
    "        # AND the month is within +/- 1 months of the target\n",
    "        cond3 = (df_energy_benchmark['month'].between(d.month-1, d.month+1))\n",
    "\n",
    "        cond_list = [cond1, cond2, cond3]\n",
    "\n",
    "        for cond_idx, cond in enumerate(cond_list):\n",
    "            cond = basic_cond & cond\n",
    "            match_df = df_energy_benchmark[cond]\n",
    "            # print(f\"condition {cond_idx} ... {len(match_df)} matches found\")\n",
    "            pred_baseline[cond_idx, i, :] = np.quantile(match_df.iloc[-last_t:][\"gesamt\"], q=quantiles) # method='linear'\n",
    "\n",
    "    methods = ['bench_pm_2weeks', 'bench_same_month', 'bench_pm_1month']\n",
    "    for m_idx, method in enumerate(methods):\n",
    "\n",
    "        print(f\"method = {method}\")\n",
    "        # create empty df\n",
    "        df_benchmark = pd.DataFrame(index=fcast_timestamp_UTC, columns=[f\"q {q:.3f}\" for q in quantiles])\n",
    "        df_benchmark.loc[:,:] = pred_baseline[m_idx,:,:]\n",
    "\n",
    "        # make sure all cols are float\n",
    "        df_benchmark = df_benchmark.astype(float)\n",
    "        # add CET col\n",
    "        df_benchmark['timestamp_CET'] = df_benchmark.index.tz_convert('CET')\n",
    "        # reorder cols\n",
    "        df_benchmark = df_benchmark[['timestamp_CET', 'q 0.025', 'q 0.250', 'q 0.500', 'q 0.750', 'q 0.975']]\n",
    "        # save to dict\n",
    "        dict_weekly_fcasts[method] = df_benchmark\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # MSTL\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    mstl_train_horizon = 0.5 # in years\n",
    "\n",
    "    for mstl_train_horizon in [1, 0.5]:\n",
    "        \n",
    "        method = f\"mstl_{mstl_train_horizon}\"\n",
    "        print(f\"method = {method}\")\n",
    "\n",
    "        df_mstl_train = df_energy_current.iloc[-int(mstl_train_horizon * 365 * 24):].copy()\n",
    "        mstl_model = MSTL(season_length=[24, 24 * 7]).fit(df_mstl_train[\"gesamt\"])\n",
    "\n",
    "        n_steps = df_benchmark.shape[0]\n",
    "\n",
    "        y_hat_dict = mstl_model.predict(h=n_steps, level=[50, 95])\n",
    "        y_hat_df = pd.DataFrame(y_hat_dict)\n",
    "        y_hat_df[\"timestamp_CET\"] = pd.date_range(start=t_thursday, periods=len(y_hat_df), freq=\"H\")\n",
    "\n",
    "        # rename columns\n",
    "        y_hat_df = y_hat_df.rename(\n",
    "            columns={\n",
    "                \"mean\": \"q 0.500\",\n",
    "                \"lo-50\": \"q 0.250\",\n",
    "                \"hi-50\": \"q 0.750\",\n",
    "                \"lo-95\": \"q 0.025\",\n",
    "                \"hi-95\": \"q 0.975\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # rearrange cols\n",
    "        y_hat_df = y_hat_df[[\"timestamp_CET\", \"q 0.025\", \"q 0.250\", \"q 0.500\", \"q 0.750\", \"q 0.975\"]]\n",
    "\n",
    "        df_mstl_fcast = y_hat_df\n",
    "        df_mstl_fcast.index = fcast_timestamp_UTC\n",
    "\n",
    "        dict_weekly_fcasts[method] = df_mstl_fcast\n",
    "    \n",
    "    # = = = = = = = = = = = = = \n",
    "    # Quantile Reg\n",
    "    # = = = = = = = = = = = = = \n",
    "        \n",
    "    # create df with fcast timestamps as INPUT for model\n",
    "    df_temp = pd.DataFrame(index=fcast_timestamp_UTC)\n",
    "    df_temp['timestamp_CET'] = fcast_timestamp_CET\n",
    "    df_fcast_dummy = data_prepro.create_dummy_df(df_temp, hour_method='seasonal', holiday_method='separate')\n",
    "\n",
    "    for method, all_models_quant_reg in quant_reg_models.items():\n",
    "        \n",
    "        print(f\"method = {method}\")\n",
    "\n",
    "        # create empty OUTPUT df with columns = quantiles\n",
    "        df_quant_reg_direct_fcast = pd.DataFrame(index=df_fcast_dummy.index)\n",
    "        df_quant_reg_direct_fcast['timestamp_CET'] = fcast_timestamp_CET\n",
    "\n",
    "        # Prediction for Quantile Regression\n",
    "        for name, model in sorted(all_models_quant_reg.items()):\n",
    "            pred = model.predict(df_fcast_dummy.drop('timestamp_CET', axis=1))\n",
    "            df_quant_reg_direct_fcast[name] = pred\n",
    "\n",
    "        dict_weekly_fcasts[method] = df_quant_reg_direct_fcast\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # Grad Boosting\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    for method, all_models_grad_boost in grad_boost_models.items():\n",
    "\n",
    "        print(f\"method = {method}\")\n",
    "\n",
    "        if \"fturs\" in method:\n",
    "            df_fcast_dummy = data_prepro.create_features_df(df_temp, holiday_method='separate')\n",
    "            \n",
    "        elif \"dummy\" in method:\n",
    "            df_fcast_dummy = data_prepro.create_dummy_df(df_temp, hour_method='seasonal', holiday_method='separate')\n",
    "\n",
    "        # create empty OUTPUT df with columns = quantiles\n",
    "        df_grad_boost_direct_fcast = pd.DataFrame(index=df_fcast_dummy.index)\n",
    "        df_grad_boost_direct_fcast['timestamp_CET'] = fcast_timestamp_CET\n",
    "\n",
    "        # Prediction for Quantile Regression\n",
    "        for name, model in sorted(all_models_grad_boost.items()):\n",
    "            pred = model.predict(df_fcast_dummy.drop('timestamp_CET', axis=1))\n",
    "            df_grad_boost_direct_fcast[name] = pred\n",
    "\n",
    "        dict_weekly_fcasts[method] = df_grad_boost_direct_fcast\n",
    "        \n",
    "    # = = = = = = = = = = = = = \n",
    "    # LightGBM\n",
    "    # = = = = = = = = = = = = = \n",
    "    \n",
    "    start_date = \"2022-01-01\"\n",
    "    X_train_dummy, y_train_dummy, X_train_fturs, y_train_fturs = preprocess_data(df_energy_current, start_date)\n",
    "\n",
    "    methods = [f\"lightgbm_dummy_{i}\" for i in range(len(all_lgbm_params))]\n",
    "    \n",
    "    for method_idx, method in enumerate(methods):\n",
    "\n",
    "        print(f\"method = {method}\")\n",
    "        params = all_lgbm_params[method_idx]\n",
    "\n",
    "        if \"fturs\" in method:\n",
    "            all_models = model_train.fit_lightgbm(X_train_fturs, y_train_fturs, quantiles, params)\n",
    "            df_fcast_dummy = data_prepro.create_features_df(df_temp, holiday_method='separate')\n",
    "            \n",
    "        elif \"dummy\" in method:\n",
    "            all_models = model_train.fit_lightgbm(X_train_dummy, y_train_dummy, quantiles, params)\n",
    "            df_fcast_dummy = data_prepro.create_dummy_df(df_temp, hour_method='seasonal', holiday_method='separate')\n",
    "\n",
    "        # create empty OUTPUT df with columns = quantiles\n",
    "        df_direct_fcast = pd.DataFrame(index=df_fcast_dummy.index)\n",
    "        df_direct_fcast['timestamp_CET'] = fcast_timestamp_CET\n",
    "\n",
    "        # Prediction\n",
    "        for name, model in sorted(all_models.items()):\n",
    "            pred = model.predict(df_fcast_dummy.drop('timestamp_CET', axis=1))\n",
    "            df_direct_fcast[name] = pred\n",
    "\n",
    "        dict_weekly_fcasts[method] = df_direct_fcast\n",
    "        \n",
    "    # = = = = = = = = = = = = = \n",
    "    # XGBoost model\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    start_date = \"2022-01-01\"\n",
    "    X_train_dummy, y_train_dummy, X_train_fturs, y_train_fturs = preprocess_data(df_energy_current, start_date)\n",
    "    \n",
    "    df_fcast_dummy = data_prepro.create_dummy_df(df_temp, hour_method='seasonal', holiday_method='separate')\n",
    "    \n",
    "    methods = [f\"xgboost_dummy_{i}\" for i in range(len(all_xgb_params))]\n",
    "    \n",
    "    for method_idx, method in enumerate(methods):\n",
    "\n",
    "        print(f\"method = {method}\")\n",
    "        params = all_xgb_params[method_idx]\n",
    "    \n",
    "        all_models = model_train.fit_xgboost(X_train_dummy, y_train_dummy, quantiles, params)\n",
    "        dict_weekly_models[method] = all_models\n",
    "\n",
    "        # create empty OUTPUT df with columns = quantiles\n",
    "        df_direct_fcast = pd.DataFrame(index=df_fcast_dummy.index)\n",
    "        df_direct_fcast['timestamp_CET'] = fcast_timestamp_CET\n",
    "\n",
    "        # Prediction\n",
    "        for name, model in sorted(all_models.items()):\n",
    "            pred = model.predict(df_fcast_dummy.drop('timestamp_CET', axis=1))\n",
    "            df_direct_fcast[name] = pred\n",
    "\n",
    "        dict_weekly_fcasts[method] = df_direct_fcast\n",
    "    \n",
    "    # = = = = = = = = = = = = = \n",
    "    # Evaluation based on submission timestamps\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    # get actual values at every submission timestamp\n",
    "    df_energy_eval = df_energy.loc[df_energy['timestamp_CET'].isin(subm_timestamps)].copy()\n",
    "    evaluation_results = {}\n",
    "    \n",
    "    for model_name, forecast_df in dict_weekly_fcasts.items():\n",
    "\n",
    "        # Initialize an empty DataFrame to store quantile scores\n",
    "        quantile_scores = pd.DataFrame(index=subm_timestamps, columns=[f\"q {q:.3f}\" for q in quantiles])\n",
    "        # take subset of fcast df at submission timestamps\n",
    "        forecast_df = forecast_df.loc[forecast_df['timestamp_CET'].isin(subm_timestamps)].copy()\n",
    "\n",
    "        # Iterate over each submission timestamp\n",
    "        for q_idx, q in enumerate(quantiles):\n",
    "\n",
    "            qscore = mean_pinball_loss(alpha=q, \n",
    "                                       y_true=df_energy_eval['gesamt'].values, \n",
    "                                       y_pred=forecast_df.iloc[:,q_idx+1].values) # skip timestamp_CET col\n",
    "            \n",
    "            quantile_scores.iloc[:,q_idx] = qscore / 1000\n",
    "        \n",
    "        # Store the quantile scores for the model\n",
    "        evaluation_results[model_name] = quantile_scores\n",
    "    \n",
    "    # Calculate mean scores for each quantile over time\n",
    "    mean_scores = {}\n",
    "    for model_name, quantile_scores in evaluation_results.items():\n",
    "        mean_scores[model_name] = quantile_scores.mean()\n",
    "    \n",
    "    df = pd.DataFrame(mean_scores).T\n",
    "    filtered_df = df[df.index.str.contains('lightgbm')]\n",
    "    display(filtered_df.style.highlight_min(color='lightgreen', axis=0))\n",
    "\n",
    "    df = pd.DataFrame(mean_scores).T\n",
    "    filtered_df = df[df.index.str.contains('xgboost')]\n",
    "    display(filtered_df.style.highlight_min(color='lightgreen', axis=0))\n",
    "\n",
    "    # calculate mean scores over all quantiles\n",
    "    mean_scores_df = pd.DataFrame(mean_scores)\n",
    "    \n",
    "    print('- '*15)\n",
    "    print('scores:')\n",
    "    print(mean_scores_df.mean(axis=0).sort_values(ascending=True))\n",
    "        \n",
    "    # = = = = = = = = = = = = = \n",
    "    # Save all fcasts & trained models for the week\n",
    "    # = = = = = = = = = = = = = \n",
    "    \n",
    "    dict_all_fcasts[fcast_date] = dict_weekly_fcasts\n",
    "    dict_all_evals[fcast_date] = evaluation_results\n",
    "    \n",
    "    with open(f'{fcast_date}_models.pickle', 'wb') as handle:\n",
    "        pickle.dump(dict_weekly_models, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(f'eval.pickle', 'wb') as handle:\n",
    "    pickle.dump(dict_all_evals, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(f'fcasts.pickle', 'wb') as handle:\n",
    "    pickle.dump(dict_all_fcasts, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "os.chdir(cwd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
