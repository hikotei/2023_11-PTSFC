{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\statsforecast\\core.py:26: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsforecast.models import MSTL\n",
    "from sklearn.metrics import mean_pinball_loss\n",
    "\n",
    "os.chdir(\"C:/2023_11-PTSFC\")\n",
    "import model_train as model_train\n",
    "import data_prepro as data_prepro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"1\"  # Replace \"4\" with the desired number of cores\n",
    "\n",
    "quantiles = [0.025, 0.25, 0.5, 0.75, 0.975]\n",
    "fcast_hor = [36, 40, 44, 60, 64, 68] # in hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 80136 entries, 2014-12-31 23:00:00+00:00 to 2024-02-21 22:00:00+00:00\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype              \n",
      "---  ------         --------------  -----              \n",
      " 0   timestamp_CET  80136 non-null  datetime64[ns, CET]\n",
      " 1   gesamt         80136 non-null  float64            \n",
      "dtypes: datetime64[ns, CET](1), float64(1)\n",
      "memory usage: 1.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# = = = = = = = = = = = = = \n",
    "# get data\n",
    "# df_energy = data_prepro.get_energy_data_today(to_date=t_wednesday.strftime('%Y%m%d'))\n",
    "\n",
    "# Read data from file with specified data types\n",
    "df_energy = pd.read_csv(\"data/2015-01-01_2024-02-21_energy.csv\", index_col=0, parse_dates=[0])\n",
    "df_energy['timestamp_CET'] = pd.to_datetime(df_energy['timestamp_CET'], utc=True).dt.tz_convert('CET')\n",
    "print(df_energy.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df_energy, start_date):\n",
    "    \n",
    "    df_energy_small = df_energy.loc[(df_energy['timestamp_CET'] > start_date)].copy()\n",
    "    \n",
    "    df_energy_dummy = data_prepro.create_dummy_df(df_energy_small, hour_method='simple', holiday_method='separate')\n",
    "    df_energy_fturs = data_prepro.create_features_df(df_energy_small, holiday_method='separate')\n",
    "\n",
    "    X_train_fturs = df_energy_fturs.drop(['gesamt', 'timestamp_CET'], axis=1)\n",
    "    y_train_fturs = df_energy_fturs['gesamt']\n",
    "\n",
    "    X_train_dummy = df_energy_dummy.drop(['gesamt', 'timestamp_CET'], axis=1)\n",
    "    y_train_dummy = df_energy_dummy['gesamt']\n",
    "    \n",
    "    return X_train_dummy, y_train_dummy, X_train_fturs, y_train_fturs\n",
    "\n",
    "def generate_param_grids(params):\n",
    "    \n",
    "        param_values = list(itertools.product(*params.values()))\n",
    "        param_names = list(params.keys())\n",
    "\n",
    "        param_grids = []\n",
    "\n",
    "        for values in param_values:\n",
    "            param_dict = dict(zip(param_names, values))\n",
    "            param_grids.append(param_dict)\n",
    "\n",
    "        return param_grids\n",
    "\n",
    "lgbm_params = {\n",
    "    'max_depth': [4, 10],\n",
    "    'num_leaves': [5, 15, 20],\n",
    "    'learning_rate': [0.1, 0.3],\n",
    "    'n_estimators': [100, 200],\n",
    "    'boosting_type': ['gbdt'],\n",
    "    'verbose': [-1]\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'objective': ['reg:quantileerror'],\n",
    "    'eval_metric': ['quantile'],\n",
    "    'booster': ['gbtree'],\n",
    "    'max_depth': [4, 10, 15],\n",
    "    'learning_rate': [0.1, 0.3],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "}\n",
    "\n",
    "all_lgbm_params = generate_param_grids(lgbm_params)\n",
    "all_xgb_params = generate_param_grids(xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2023-11-15 ...\n",
      "Submission timestamps = 2023-11-17 12:00:00+01:00 to 2023-11-18 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "method = xgboost_dummy_2019_0\n",
      "> time taken: 31.27 seconds\n",
      "method = xgboost_dummy_2019_1\n",
      "> time taken: 40.42 seconds\n",
      "method = xgboost_dummy_2019_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <bound method DataIter._next_wrapper of <xgboost.data.SingleBatchInternalIter object at 0x00000240D31F6B90>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\core.py\", line 641, in _next_wrapper\n",
      "    return self._handle_exception(lambda: self.next(input_data), 0)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\core.py\", line 557, in _handle_exception\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\core.py\", line 641, in <lambda>\n",
      "    return self._handle_exception(lambda: self.next(input_data), 0)\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\data.py\", line 1280, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\core.py\", line 624, in input_data\n",
      "    new, cat_codes, feature_names, feature_types = _proxy_transform(\n",
      "                                                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\data.py\", line 1315, in _proxy_transform\n",
      "    arr, feature_names, feature_types = _transform_pandas_df(\n",
      "                                        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\data.py\", line 498, in _transform_pandas_df\n",
      "    transformed = pandas_cat_null(data)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\data.py\", line 409, in pandas_cat_null\n",
      "    if is_pd_cat_dtype(dtype):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\data.py\", line 374, in is_pd_cat_dtype\n",
      "    if Version(pd.__version__) >= Version(\"2.1.0\"):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\pandas\\util\\version\\__init__.py\", line 359, in __init__\n",
      "    self._key = _cmpkey(\n",
      "                ^^^^^^^^\n",
      "  File \"c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\pandas\\util\\version\\__init__.py\", line 535, in _cmpkey\n",
      "    reversed(list(itertools.dropwhile(lambda x: x == 0, reversed(release))))\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[13:47:26] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\data\\proxy_dmatrix.h:158: Unknown type: void",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 74\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     72\u001b[0m params \u001b[38;5;241m=\u001b[39m all_xgb_params[method_idx]\n\u001b[1;32m---> 74\u001b[0m all_models \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_xgboost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_dummy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_dummy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m dict_weekly_models[method] \u001b[38;5;241m=\u001b[39m all_models\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# create empty OUTPUT df with columns = quantiles\u001b[39;00m\n",
      "File \u001b[1;32mC:\\2023_11-PTSFC\\model_train.py:30\u001b[0m, in \u001b[0;36mfit_xgboost\u001b[1;34m(X_train, y_train, quantiles, params)\u001b[0m\n\u001b[0;32m     27\u001b[0m all_models \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m alpha \u001b[38;5;129;01min\u001b[39;00m quantiles:\n\u001b[1;32m---> 30\u001b[0m     xgb_model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBRegressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantile_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     all_models[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malpha\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m xgb_model\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# print time taken\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1055\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[0;32m   1054\u001b[0m     evals_result: TrainingCallback\u001b[38;5;241m.\u001b[39mEvalsLog \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1055\u001b[0m     train_dmatrix, evals \u001b[38;5;241m=\u001b[39m \u001b[43m_wrap_evaluation_matrices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1064\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_qid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_dmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1073\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1075\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "File \u001b[1;32mc:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\sklearn.py:521\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_evaluation_matrices\u001b[39m(\n\u001b[0;32m    502\u001b[0m     missing: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[0;32m    503\u001b[0m     X: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    517\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[0;32m    518\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m    519\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;124;03m    way.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 521\u001b[0m     train_dmatrix \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dmatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m     n_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(eval_set)\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence:\n",
      "File \u001b[1;32mc:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\sklearn.py:958\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[1;34m(self, ref, **kwargs)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _can_use_qdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_method) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbooster \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 958\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mQuantileDMatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnthread\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_bin\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[0;32m    962\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\core.py:1529\u001b[0m, in \u001b[0;36mQuantileDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m   1510\u001b[0m         info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1511\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1522\u001b[0m         )\n\u001b[0;32m   1523\u001b[0m     ):\n\u001b[0;32m   1524\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1525\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf data iterator is used as input, data like label should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1526\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified as batch argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1527\u001b[0m         )\n\u001b[1;32m-> 1529\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\core.py:1590\u001b[0m, in \u001b[0;36mQuantileDMatrix._init\u001b[1;34m(self, data, ref, enable_categorical, **meta)\u001b[0m\n\u001b[0;32m   1588\u001b[0m it\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[0;32m   1589\u001b[0m \u001b[38;5;66;03m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[1;32m-> 1590\u001b[0m \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1591\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;241m=\u001b[39m handle\n",
      "File \u001b[1;32mc:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\xgboost\\core.py:282\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \n\u001b[0;32m    273\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [13:47:26] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\data\\proxy_dmatrix.h:158: Unknown type: void"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "folder_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "directory = os.path.join(cwd, folder_name)\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "os.chdir(directory)\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = pd.Timestamp('2023-11-15')\n",
    "end_date = pd.Timestamp('2024-02-14')\n",
    "\n",
    "# Generate a list of weekly dates in UTC\n",
    "fcast_dates_cet = pd.date_range(start=start_date, end=end_date, freq='W-WED').tz_localize('CET').strftime('%Y-%m-%d').tolist()\n",
    "dict_all_fcasts = {}\n",
    "dict_all_evals = {}\n",
    "\n",
    "# Iterate over the forecast dates\n",
    "for fcast_date in fcast_dates_cet[:]:\n",
    "\n",
    "    print('= '*30)\n",
    "    print(f\"Forecasting for week starting from {fcast_date} ...\")\n",
    "    \n",
    "    dict_weekly_fcasts = {}\n",
    "    dict_weekly_models = {}\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # generate prediction timestamps based on t0 = following thursday 00:00\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    # Calculate the Thursday and Wednesday of the week\n",
    "    t_wednesday = pd.Timestamp(fcast_date).replace(hour=0, minute=0, second=0, microsecond=0).tz_localize('CET')\n",
    "    t_thursday = t_wednesday + pd.Timedelta(days=1)\n",
    "\n",
    "    # Generate required submission timestamps\n",
    "    subm_timestamps = [(t_thursday + pd.Timedelta(hours=fcast)) for fcast in fcast_hor]\n",
    "    print(f\"Submission timestamps = {subm_timestamps[0]} to {subm_timestamps[-1]}\")\n",
    "    \n",
    "    # Create df with Information at fcast start date\n",
    "    t_thursday_str = t_thursday.strftime('%Y-%m-%d')\n",
    "    df_energy_current = df_energy.loc[df_energy['timestamp_CET'] <= t_thursday_str].copy()\n",
    "    print('= '*30)\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # Data Prep for All Methods\n",
    "    # = = = = = = = = = = = = = \n",
    "    \n",
    "    # create fcast index for next 68 hours\n",
    "    fcast_timestamp_CET = pd.date_range(start=t_thursday, periods=68+1, freq='H')\n",
    "    fcast_timestamp_UTC = fcast_timestamp_CET.tz_convert('UTC')\n",
    "\n",
    "    # create df with fcast timestamps as INPUT for model\n",
    "    df_temp = pd.DataFrame(index=fcast_timestamp_UTC)\n",
    "    df_temp['timestamp_CET'] = fcast_timestamp_CET\n",
    "    df_fcast_dummy = data_prepro.create_dummy_df(df_temp, hour_method='simple', holiday_method='separate')\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # XGBoost model\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    yr = 2019\n",
    "    start_date = f\"{yr}-01-01\"\n",
    "    X_train_dummy, y_train_dummy, X_train_fturs, y_train_fturs = preprocess_data(df_energy_current, start_date)\n",
    "\n",
    "    df_fcast_dummy = data_prepro.create_dummy_df(df_temp, hour_method='simple', holiday_method='separate')\n",
    "    \n",
    "    methods = [f\"xgboost_dummy_{yr}_{i}\" for i in range(len(all_xgb_params))]\n",
    "    \n",
    "    for method_idx, method in enumerate(methods):\n",
    "\n",
    "        print(f\"method = {method}\")\n",
    "        params = all_xgb_params[method_idx]\n",
    "    \n",
    "        all_models = model_train.fit_xgboost(X_train_dummy, y_train_dummy, quantiles, params)\n",
    "        dict_weekly_models[method] = all_models\n",
    "\n",
    "        # create empty OUTPUT df with columns = quantiles\n",
    "        df_direct_fcast = pd.DataFrame(index=df_fcast_dummy.index)\n",
    "        df_direct_fcast['timestamp_CET'] = fcast_timestamp_CET\n",
    "\n",
    "        # Prediction\n",
    "        for name, model in sorted(all_models.items()):\n",
    "            pred = model.predict(df_fcast_dummy.drop('timestamp_CET', axis=1))\n",
    "            df_direct_fcast[name] = pred\n",
    "\n",
    "        dict_weekly_fcasts[method] = df_direct_fcast\n",
    "    \n",
    "    # = = = = = = = = = = = = = \n",
    "    # Evaluation based on submission timestamps\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    # get actual values at every submission timestamp\n",
    "    df_energy_eval = df_energy.loc[df_energy['timestamp_CET'].isin(subm_timestamps)].copy()\n",
    "    evaluation_results = {}\n",
    "    \n",
    "    for model_name, forecast_df in dict_weekly_fcasts.items():\n",
    "\n",
    "        # Initialize an empty DataFrame to store quantile scores\n",
    "        quantile_scores = pd.DataFrame(index=subm_timestamps, columns=[f\"q {q:.3f}\" for q in quantiles])\n",
    "        # take subset of fcast df at submission timestamps\n",
    "        forecast_df = forecast_df.loc[forecast_df['timestamp_CET'].isin(subm_timestamps)].copy()\n",
    "\n",
    "        # Iterate over each submission timestamp\n",
    "        for q_idx, q in enumerate(quantiles):\n",
    "\n",
    "            qscore = mean_pinball_loss(alpha=q, \n",
    "                                       y_true=df_energy_eval['gesamt'].values, \n",
    "                                       y_pred=forecast_df.iloc[:,q_idx+1].values) # skip timestamp_CET col\n",
    "            \n",
    "            quantile_scores.iloc[:,q_idx] = qscore / 1000\n",
    "        \n",
    "        # Store the quantile scores for the model\n",
    "        evaluation_results[model_name] = quantile_scores\n",
    "    \n",
    "    # Calculate mean scores for each quantile over time\n",
    "    mean_scores = {}\n",
    "    for model_name, quantile_scores in evaluation_results.items():\n",
    "        mean_scores[model_name] = quantile_scores.mean()\n",
    "\n",
    "    # calculate mean scores over all quantiles\n",
    "    mean_scores_df = pd.DataFrame(mean_scores)\n",
    "    \n",
    "    print('- '*15)\n",
    "    print('scores:')\n",
    "    print(mean_scores_df.mean(axis=0).sort_values(ascending=True))\n",
    "        \n",
    "    # = = = = = = = = = = = = = \n",
    "    # Save all fcasts & trained models for the week\n",
    "    # = = = = = = = = = = = = = \n",
    "    \n",
    "    dict_all_fcasts[fcast_date] = dict_weekly_fcasts\n",
    "    dict_all_evals[fcast_date] = evaluation_results\n",
    "    \n",
    "    # with open(f'{fcast_date}_models.pickle', 'wb') as handle:\n",
    "    #     pickle.dump(dict_weekly_models, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('eval.pickle', 'wb') as handle:\n",
    "    pickle.dump(dict_all_evals, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('fcasts.pickle', 'wb') as handle:\n",
    "    pickle.dump(dict_all_fcasts, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "os.chdir(cwd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
