{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\statsforecast\\core.py:26: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsforecast.models import MSTL\n",
    "from sklearn.metrics import mean_pinball_loss\n",
    "\n",
    "os.chdir(\"C:/2023_11-PTSFC\")\n",
    "import model_train as model_train\n",
    "import data_prepro as data_prepro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"1\"  # Replace \"4\" with the desired number of cores\n",
    "\n",
    "quantiles = [0.025, 0.25, 0.5, 0.75, 0.975]\n",
    "fcast_hor = [36, 40, 44, 60, 64, 68] # in hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 80136 entries, 2014-12-31 23:00:00+00:00 to 2024-02-21 22:00:00+00:00\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype              \n",
      "---  ------         --------------  -----              \n",
      " 0   timestamp_CET  80136 non-null  datetime64[ns, CET]\n",
      " 1   gesamt         80136 non-null  float64            \n",
      "dtypes: datetime64[ns, CET](1), float64(1)\n",
      "memory usage: 1.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# = = = = = = = = = = = = = \n",
    "# get data\n",
    "# df_energy = data_prepro.get_energy_data_today(to_date=t_wednesday.strftime('%Y%m%d'))\n",
    "\n",
    "# Read data from file with specified data types\n",
    "df_energy = pd.read_csv(\"data/2015-01-01_2024-02-21_energy.csv\", index_col=0, parse_dates=[0])\n",
    "df_energy['timestamp_CET'] = pd.to_datetime(df_energy['timestamp_CET'], utc=True).dt.tz_convert('CET')\n",
    "print(df_energy.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2023-11-15 ...\n",
      "Submission timestamps = 2023-11-17 12:00:00+01:00 to 2023-11-18 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "method = mstl_4\n",
      "method = mstl_3\n",
      "method = mstl_2\n",
      "method = mstl_1.5\n",
      "method = mstl_1\n",
      "method = mstl_0.5\n",
      "method = mstl_0.25\n",
      "- - - - - - - - - - - - - - - \n",
      "scores:\n",
      "mstl_0.25    0.655269\n",
      "mstl_0.5     0.660708\n",
      "mstl_4       0.686128\n",
      "mstl_3       0.687457\n",
      "mstl_2       0.692538\n",
      "mstl_1.5     0.694185\n",
      "mstl_1       0.702681\n",
      "dtype: object\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2023-11-22 ...\n",
      "Submission timestamps = 2023-11-24 12:00:00+01:00 to 2023-11-25 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "method = mstl_4\n",
      "method = mstl_3\n",
      "method = mstl_2\n",
      "method = mstl_1.5\n",
      "method = mstl_1\n",
      "method = mstl_0.5\n",
      "method = mstl_0.25\n",
      "- - - - - - - - - - - - - - - \n",
      "scores:\n",
      "mstl_0.5     0.630093\n",
      "mstl_0.25    0.665803\n",
      "mstl_4       0.726744\n",
      "mstl_3       0.728284\n",
      "mstl_2       0.735492\n",
      "mstl_1.5     0.735625\n",
      "mstl_1       0.736854\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "folder_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "directory = os.path.join(cwd, folder_name)\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "os.chdir(directory)\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = pd.Timestamp('2023-11-15')\n",
    "end_date = pd.Timestamp('2024-02-14')\n",
    "\n",
    "# Generate a list of weekly dates in UTC\n",
    "fcast_dates_cet = pd.date_range(start=start_date, end=end_date, freq='W-WED').tz_localize('CET').strftime('%Y-%m-%d').tolist()\n",
    "dict_all_fcasts = {}\n",
    "dict_all_evals = {}\n",
    "dict_all_model_scores = {}\n",
    "\n",
    "# Iterate over the forecast dates\n",
    "for fcast_date in fcast_dates_cet[:2]:\n",
    "\n",
    "    print('= '*30)\n",
    "    print(f\"Forecasting for week starting from {fcast_date} ...\")\n",
    "    \n",
    "    dict_weekly_fcasts = {}\n",
    "    dict_weekly_models = {}\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # generate prediction timestamps based on t0 = following thursday 00:00\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    # Calculate the Thursday and Wednesday of the week\n",
    "    t_wednesday = pd.Timestamp(fcast_date).replace(hour=0, minute=0, second=0, microsecond=0).tz_localize('CET')\n",
    "    t_thursday = t_wednesday + pd.Timedelta(days=1)\n",
    "\n",
    "    # Generate required submission timestamps\n",
    "    subm_timestamps = [(t_thursday + pd.Timedelta(hours=fcast)) for fcast in fcast_hor]\n",
    "    print(f\"Submission timestamps = {subm_timestamps[0]} to {subm_timestamps[-1]}\")\n",
    "    \n",
    "    # Create df with Information at fcast start date\n",
    "    t_thursday_str = t_thursday.strftime('%Y-%m-%d')\n",
    "    df_energy_current = df_energy.loc[df_energy['timestamp_CET'] <= t_thursday_str].copy()\n",
    "    print('= '*30)\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # Data Prep for All Methods\n",
    "    # = = = = = = = = = = = = = \n",
    "    \n",
    "    # create fcast index for next 68 hours\n",
    "    fcast_timestamp_CET = pd.date_range(start=t_thursday, periods=68+1, freq='H')\n",
    "    fcast_timestamp_UTC = fcast_timestamp_CET.tz_convert('UTC')\n",
    "\n",
    "    # create df with fcast timestamps as INPUT for model\n",
    "    df_temp = pd.DataFrame(index=fcast_timestamp_UTC)\n",
    "    df_temp['timestamp_CET'] = fcast_timestamp_CET\n",
    "    df_fcast_dummy = data_prepro.create_dummy_df(df_temp, hour_method='simple', holiday_method='separate')\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # Simple Benchmark\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    df_benchmark = pd.DataFrame(index=fcast_timestamp_UTC, columns=[f\"q {q:.3f}\" for q in quantiles])\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # MSTL\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    mstl_train_horizon = 0.5 # in years\n",
    "\n",
    "    for mstl_train_horizon in [4, 3, 2, 1.5, 1, 0.5, 0.25]:\n",
    "        \n",
    "        method = f\"mstl_{mstl_train_horizon}\"\n",
    "        print(f\"method = {method}\")\n",
    "\n",
    "        df_mstl_train = df_energy_current.iloc[-int(mstl_train_horizon * 365 * 24):].copy()\n",
    "        mstl_model = MSTL(season_length=[24, 24 * 7]).fit(df_mstl_train[\"gesamt\"])\n",
    "\n",
    "        n_steps = df_benchmark.shape[0]\n",
    "\n",
    "        y_hat_dict = mstl_model.predict(h=n_steps, level=[50, 95])\n",
    "        y_hat_df = pd.DataFrame(y_hat_dict)\n",
    "        y_hat_df[\"timestamp_CET\"] = pd.date_range(start=t_thursday, periods=len(y_hat_df), freq=\"H\")\n",
    "\n",
    "        # rename columns\n",
    "        y_hat_df = y_hat_df.rename(\n",
    "            columns={\n",
    "                \"mean\": \"q 0.500\",\n",
    "                \"lo-50\": \"q 0.250\",\n",
    "                \"hi-50\": \"q 0.750\",\n",
    "                \"lo-95\": \"q 0.025\",\n",
    "                \"hi-95\": \"q 0.975\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # rearrange cols\n",
    "        y_hat_df = y_hat_df[[\"timestamp_CET\", \"q 0.025\", \"q 0.250\", \"q 0.500\", \"q 0.750\", \"q 0.975\"]]\n",
    "\n",
    "        df_mstl_fcast = y_hat_df\n",
    "        df_mstl_fcast.index = fcast_timestamp_UTC\n",
    "\n",
    "        dict_weekly_fcasts[method] = df_mstl_fcast\n",
    "        \n",
    "    # = = = = = = = = = = = = = \n",
    "    # Evaluation based on submission timestamps\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    # get actual values at every submission timestamp\n",
    "    df_energy_eval = df_energy.loc[df_energy['timestamp_CET'].isin(subm_timestamps)].copy()\n",
    "    evaluation_results = {}\n",
    "    \n",
    "    for model_name, forecast_df in dict_weekly_fcasts.items():\n",
    "\n",
    "        # Initialize an empty DataFrame to store quantile scores\n",
    "        quantile_scores = pd.DataFrame(index=subm_timestamps, columns=[f\"q {q:.3f}\" for q in quantiles])\n",
    "        # take subset of fcast df at submission timestamps\n",
    "        forecast_df = forecast_df.loc[forecast_df['timestamp_CET'].isin(subm_timestamps)].copy()\n",
    "\n",
    "        # Iterate over each submission timestamp\n",
    "        for q_idx, q in enumerate(quantiles):\n",
    "\n",
    "            qscore = mean_pinball_loss(alpha=q, \n",
    "                                       y_true=df_energy_eval['gesamt'].values, \n",
    "                                       y_pred=forecast_df.iloc[:,q_idx+1].values) # skip timestamp_CET col\n",
    "            \n",
    "            quantile_scores.iloc[:,q_idx] = qscore / 1000\n",
    "        \n",
    "        # Store the quantile scores for the model\n",
    "        evaluation_results[model_name] = quantile_scores\n",
    "    \n",
    "    # Calculate mean scores for each quantile over time\n",
    "    mean_scores = {}\n",
    "    for model_name, quantile_scores in evaluation_results.items():\n",
    "        mean_scores[model_name] = quantile_scores.mean()\n",
    "\n",
    "    # calculate mean scores over all quantiles\n",
    "    mean_scores_df = pd.DataFrame(mean_scores)\n",
    "    \n",
    "    print('- '*15)\n",
    "    print('scores:')\n",
    "    print(mean_scores_df.mean(axis=0).sort_values(ascending=True))\n",
    "    dict_all_model_scores[fcast_date] = mean_scores_df.mean(axis=0).sort_values(ascending=True)\n",
    "        \n",
    "    # = = = = = = = = = = = = = \n",
    "    # Save all fcasts & trained models for the week\n",
    "    # = = = = = = = = = = = = = \n",
    "    \n",
    "    dict_all_fcasts[fcast_date] = dict_weekly_fcasts\n",
    "    dict_all_evals[fcast_date] = evaluation_results\n",
    "\n",
    "with open('eval.pickle', 'wb') as handle:\n",
    "    pickle.dump(dict_all_evals, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('fcasts.pickle', 'wb') as handle:\n",
    "    pickle.dump(dict_all_fcasts, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2023-11-15</th>\n",
       "      <th>2023-11-22</th>\n",
       "      <th>2023-11-29</th>\n",
       "      <th>2023-12-06</th>\n",
       "      <th>2023-12-13</th>\n",
       "      <th>2023-12-20</th>\n",
       "      <th>2023-12-27</th>\n",
       "      <th>2024-01-03</th>\n",
       "      <th>2024-01-10</th>\n",
       "      <th>2024-01-17</th>\n",
       "      <th>2024-01-24</th>\n",
       "      <th>2024-01-31</th>\n",
       "      <th>2024-02-07</th>\n",
       "      <th>2024-02-14</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mstl_0.5</th>\n",
       "      <td>0.660708</td>\n",
       "      <td>0.630093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mstl_0.25</th>\n",
       "      <td>0.655269</td>\n",
       "      <td>0.665803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mstl_4</th>\n",
       "      <td>0.686128</td>\n",
       "      <td>0.726744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mstl_3</th>\n",
       "      <td>0.687457</td>\n",
       "      <td>0.728284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.70787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mstl_2</th>\n",
       "      <td>0.692538</td>\n",
       "      <td>0.735492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mstl_1.5</th>\n",
       "      <td>0.694185</td>\n",
       "      <td>0.735625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mstl_1</th>\n",
       "      <td>0.702681</td>\n",
       "      <td>0.736854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.719767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          2023-11-15 2023-11-22 2023-11-29 2023-12-06 2023-12-13 2023-12-20  \\\n",
       "mstl_0.5    0.660708   0.630093        NaN        NaN        NaN        NaN   \n",
       "mstl_0.25   0.655269   0.665803        NaN        NaN        NaN        NaN   \n",
       "mstl_4      0.686128   0.726744        NaN        NaN        NaN        NaN   \n",
       "mstl_3      0.687457   0.728284        NaN        NaN        NaN        NaN   \n",
       "mstl_2      0.692538   0.735492        NaN        NaN        NaN        NaN   \n",
       "mstl_1.5    0.694185   0.735625        NaN        NaN        NaN        NaN   \n",
       "mstl_1      0.702681   0.736854        NaN        NaN        NaN        NaN   \n",
       "\n",
       "          2023-12-27 2024-01-03 2024-01-10 2024-01-17 2024-01-24 2024-01-31  \\\n",
       "mstl_0.5         NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "mstl_0.25        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "mstl_4           NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "mstl_3           NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "mstl_2           NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "mstl_1.5         NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "mstl_1           NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "          2024-02-07 2024-02-14      mean  \n",
       "mstl_0.5         NaN        NaN  0.645401  \n",
       "mstl_0.25        NaN        NaN  0.660536  \n",
       "mstl_4           NaN        NaN  0.706436  \n",
       "mstl_3           NaN        NaN   0.70787  \n",
       "mstl_2           NaN        NaN  0.714015  \n",
       "mstl_1.5         NaN        NaN  0.714905  \n",
       "mstl_1           NaN        NaN  0.719767  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create empty df to store scores\n",
    "df_scores = pd.DataFrame(columns=fcast_dates_cet, \n",
    "                         index=dict_all_evals[fcast_dates_cet[0]].keys())\n",
    "\n",
    "for week_key, scores_dict in dict_all_evals.items():\n",
    "    for model_key, scores_df in scores_dict.items():\n",
    "        # print(f\"{week_key} - {model_key} : {scores_df.values.mean()}\")\n",
    "        df_scores.loc[model_key, week_key] = scores_df.values.mean() \n",
    "\n",
    "df_scores['mean'] = df_scores.mean(axis=1)\n",
    "df_scores.sort_values(by='mean', ascending=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
