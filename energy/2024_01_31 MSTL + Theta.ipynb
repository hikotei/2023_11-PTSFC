{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ytl_c\\miniconda3\\Lib\\site-packages\\statsforecast\\core.py:26: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import MSTL, HoltWinters\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# this makes it so that the outputs of the predict methods have the id as a column \n",
    "# instead of as the index\n",
    "os.environ['NIXTLA_ID_AS_COL'] = '1'\n",
    "\n",
    "# = = = = = =\n",
    "# own stuff\n",
    "# = = = = = =\n",
    "os.chdir('../')\n",
    "import data_prepro as data_prepro  # noqa: E402\n",
    "import model_train as model_train # noqa: E402\n",
    "import model_fcast as model_fcast # noqa: E402\n",
    "import model_eval as model_eval # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wed = 2024-01-24 00:00:00+01:00\n",
      "thu = 2024-01-25 00:00:00+01:00\n",
      "sun = 2024-01-28 00:00:00+01:00\n",
      "next wed = 2024-01-31 00:00:00+01:00\n",
      "[Timestamp('2024-01-26 12:00:00+0100', tz='CET'), Timestamp('2024-01-26 16:00:00+0100', tz='CET'), Timestamp('2024-01-26 20:00:00+0100', tz='CET'), Timestamp('2024-01-27 12:00:00+0100', tz='CET'), Timestamp('2024-01-27 16:00:00+0100', tz='CET'), Timestamp('2024-01-27 20:00:00+0100', tz='CET')]\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"1\"  # Replace \"4\" with the desired number of cores\n",
    "\n",
    "quantiles = [0.025, 0.25, 0.5, 0.75, 0.975]\n",
    "fcast_hor = [36, 40, 44, 60, 64, 68] # in hours\n",
    "\n",
    "# = = = = = = = = = = = = = \n",
    "# >>> generate prediction timestamps based on t0 = following thursday 00:00 dynamically\n",
    "# = = = = = = = = = = = = = \n",
    "\n",
    "# get current date and set time to 00:00\n",
    "t_now = pd.Timestamp.now(tz='CET').replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "t_now = '2024-01-24'\n",
    "t_now = pd.Timestamp(t_now, tz='CET')\n",
    "\n",
    "# get thursday and wednesday\n",
    "days_left = 3 - t_now.weekday() # get days left till thursday\n",
    "t_thursday = t_now + pd.Timedelta(days=days_left)\n",
    "t_wednesday = t_thursday - pd.Timedelta(days=1)\n",
    "t_sunday = t_thursday + pd.Timedelta(days=3)\n",
    "print(f\"wed = {t_wednesday}\")\n",
    "print(f\"thu = {t_thursday}\")\n",
    "print(f\"sun = {t_sunday}\")\n",
    "\n",
    "# t_monday_next = t_thursday + pd.Timedelta(days=4)\n",
    "t_wednesday_next = t_wednesday + pd.Timedelta(days=7)\n",
    "# print(f\"next mon = {t_monday_next}\")\n",
    "print(f\"next wed = {t_wednesday_next}\")\n",
    "\n",
    "# get required submission horizons\n",
    "# based on fcast horizons generate timestamps from t0\n",
    "subm_timestamps = []\n",
    "for fcast in fcast_hor:\n",
    "    subm_timestamps.append((t_thursday + pd.Timedelta(hours=fcast)))\n",
    "print(subm_timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### statsmodels & sktime MSTL (BAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mstl = MSTL(df_energy_small['gesamt'], periods=[24, 24*7], iterate=1, \n",
    "#             stl_kwargs={\"seasonal_deg\": 0,\n",
    "#                         \"inner_iter\": 2,\n",
    "#                         \"outer_iter\": 0})\n",
    "\n",
    "# res = mstl.fit()\n",
    "\n",
    "# plt.rc(\"figure\", figsize=(15, 10))\n",
    "# res.plot()\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sktime.datasets import load_airline\n",
    "# from sktime.forecasting.statsforecast import StatsForecastMSTL\n",
    "\n",
    "# y = df_energy_small['gesamt']\n",
    "# model = StatsForecastMSTL(season_length=[24, 24*7], pred_int_kwargs={'n_windows':2, 'h':12})\n",
    "# fitted_model = model.fit(y=y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = fitted_model.predict(fh=np.arange(1,69)) \n",
    "\n",
    "# plt.figure(figsize=(15, 5))\n",
    "# plt.plot(y_pred)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = fitted_model.predict_interval(fh=np.arange(1,69), coverage=0.95) \n",
    "\n",
    "# plt.figure(figsize=(15, 5))\n",
    "# plt.plot(y_pred)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsforecast MSTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsforecast import StatsForecast\n",
    "# from statsforecast.models import MSTL, HoltWinters\n",
    "# from tqdm.autonotebook import tqdm\n",
    "\n",
    "# # this makes it so that the outputs of the predict methods have the id as a column \n",
    "# # instead of as the index\n",
    "# os.environ['NIXTLA_ID_AS_COL'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # = = = = = = = = = = = = = \n",
    "# # get true data\n",
    "# df_energy = data_prepro.get_energy_data_today(to_date=t_wednesday_next.strftime('%Y%m%d'))\n",
    "\n",
    "# # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "# # take smaller train dataset\n",
    "# start   = '2022-01-01'\n",
    "# end     = df_energy['timestamp_CET'].max()\n",
    "# end     = t_thursday.strftime('%Y-%m-%d')\n",
    "# df_energy_small = df_energy.loc[(df_energy['timestamp_CET'] > start) &\n",
    "#                                 (df_energy['timestamp_CET'] <= end)]\n",
    "\n",
    "# print('- '*15)\n",
    "# print(f\"take smaller dataset ... from {start} to {end}\")\n",
    "# print(df_energy_small.info())\n",
    "\n",
    "# # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "# # take the required week \n",
    "# start   = t_thursday.strftime('%Y-%m-%d')\n",
    "# end     = t_sunday.strftime('%Y-%m-%d')\n",
    "# df_energy_true = df_energy.loc[(df_energy['timestamp_CET'] >= start) &\n",
    "#                                (df_energy['timestamp_CET'] <= end)]\n",
    "\n",
    "# print('- '*15)\n",
    "# print(f\"true data ... from {start} to {end}\")\n",
    "# print(df_energy_true.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from importlib import reload\n",
    "# reload(data_prepro)\n",
    "# reload(model_train)\n",
    "# reload(model_fcast)\n",
    "# reload(model_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # StatsForecast needs this format\n",
    "# df = df_energy_small.copy().rename(columns={'timestamp_CET': 'ds', 'gesamt': 'y'})\n",
    "# df['unique_id'] = 'energy'\n",
    "\n",
    "# # Use past 2 years data for MSTL ... take last 365 * 24 values\n",
    "# df_mstl = df_energy_small.iloc[-2*365*24:].copy()\n",
    "# # Use past 4 weeks data for HoltWinters\n",
    "# df_hw = df_energy_small.iloc[-4*7*24:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MSTL's usage example\n",
    "# mstl_model = MSTL(season_length=[24, 24*7])\n",
    "# mstl_model = mstl_model.fit(df_mstl['gesamt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculate how many step aheads in hours to last submission timestamp\n",
    "# # to get the required number of hourly predictions\n",
    "# n_steps = int((subm_timestamps[-1] - df['ds'].max()) / pd.Timedelta(hours=1)) + 5\n",
    "\n",
    "# y_hat_dict = mstl_model.predict(h=n_steps, level=[50, 95])\n",
    "# # y_hat_dict\n",
    "# # turn the dictionary into a dataframe\n",
    "# y_hat_df = pd.DataFrame(y_hat_dict)\n",
    "\n",
    "# # add timestamp_CET column\n",
    "# y_hat_df['timestamp_CET'] = pd.date_range(start=df['ds'].max(), periods=len(y_hat_df), freq='H')\n",
    "# y_hat_df\n",
    "\n",
    "# # rename columns\n",
    "# y_hat_df = y_hat_df.rename(columns={'mean': 'q 0.500', \n",
    "#                                     'lo-50': 'q 0.250', \n",
    "#                                     'hi-50': 'q 0.750', \n",
    "#                                     'lo-95': 'q 0.025', \n",
    "#                                     'hi-95': 'q 0.975'})\n",
    "# y_hat_df = y_hat_df[['timestamp_CET', 'q 0.025', 'q 0.250', 'q 0.500', 'q 0.750', 'q 0.975']]\n",
    "\n",
    "# model_train.plot_quantile_fcast(y_hat_df, subm_timestamps, y_true=df_energy_true, title='MSTL fcast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_eval.eval_fcast(y_hat_df, df_energy_true, subm_timestamps, quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holt Winters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Holt-Winters' usage example\n",
    "# holt_winters_model = HoltWinters(season_length=24, error_type='A')\n",
    "# holt_winters_model = holt_winters_model.fit(y=df_hw['gesamt'].values)\n",
    "\n",
    "# # = = = = = = = = = = = = = = = = = = = = = = = = = #\n",
    "# # !!! can only use 1 single seasonality parameter !!!\n",
    "# # = = = = = = = = = = = = = = = = = = = = = = = = = #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculate how many step aheads in hours to last submission timestamp\n",
    "# # to get the required number of hourly predictions\n",
    "# n_steps = int((subm_timestamps[-1] - df['ds'].max()) / pd.Timedelta(hours=1)) + 5\n",
    "\n",
    "# y_hat_dict = holt_winters_model.predict(h=n_steps, level=[50, 95])\n",
    "# # y_hat_dict\n",
    "# # turn the dictionary into a dataframe\n",
    "# y_hat_df = pd.DataFrame(y_hat_dict)\n",
    "\n",
    "# # add timestamp_CET column\n",
    "# y_hat_df['timestamp_CET'] = pd.date_range(start=df['ds'].max(), periods=len(y_hat_df), freq='H')\n",
    "# y_hat_df\n",
    "\n",
    "# # rename columns\n",
    "# y_hat_df = y_hat_df.rename(columns={'mean': 'q 0.500', \n",
    "#                                     'lo-50': 'q 0.250', \n",
    "#                                     'hi-50': 'q 0.750', \n",
    "#                                     'lo-95': 'q 0.025', \n",
    "#                                     'hi-95': 'q 0.975'})\n",
    "# y_hat_df = y_hat_df[['timestamp_CET', 'q 0.025', 'q 0.250', 'q 0.500', 'q 0.750', 'q 0.975']]\n",
    "\n",
    "# model_train.plot_quantile_fcast(y_hat_df, subm_timestamps, y_true=df_energy_true, title='Holt Winters fcast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_eval.eval_fcast(y_hat_df, df_energy_true, subm_timestamps, quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Fcast Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model_eval' from 'c:\\\\2023_11-PTSFC\\\\model_eval.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(data_prepro)\n",
    "reload(model_train)\n",
    "reload(model_fcast)\n",
    "reload(model_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> cwd = c:\\2023_11-PTSFC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> to_date is later than 2023-11-01, using recent data as well !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:07<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 0 NA in df\n",
      "> last valid index = 2024-01-31 18:15:00+00:00\n",
      "> done and saved to 2015-01-01_2024-01-31_energy.csv\n",
      "- - - - - - - - - - - - - - - \n",
      "take smaller dataset ... from 2020-01-01 to 2024-01-31 19:00:00+01:00\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 35803 entries, 2020-01-01 00:00:00+00:00 to 2024-01-31 18:00:00+00:00\n",
      "Freq: H\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype              \n",
      "---  ------         --------------  -----              \n",
      " 0   timestamp_CET  35803 non-null  datetime64[ns, CET]\n",
      " 1   gesamt         35803 non-null  float64            \n",
      "dtypes: datetime64[ns, CET](1), float64(1)\n",
      "memory usage: 839.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# = = = = = = = = = = = = = \n",
    "# get all data\n",
    "t_now = pd.Timestamp.now(tz='CET').replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "df_energy = data_prepro.get_energy_data_today(to_date=t_now.strftime('%Y%m%d'))\n",
    "\n",
    "# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "# take smaller train dataset\n",
    "start   = '2020-01-01'\n",
    "end     = df_energy['timestamp_CET'].max()\n",
    "df_energy_small = df_energy.loc[(df_energy['timestamp_CET'] > start) &\n",
    "                                (df_energy['timestamp_CET'] <= end)]\n",
    "\n",
    "print('- '*15)\n",
    "print(f\"take smaller dataset ... from {start} to {end}\")\n",
    "print(df_energy_small.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - - - - - - - \n",
      "fold 1/5\n",
      "- - - - - - - - - - - - - - - \n",
      "train from: 2020-01-01 01:00:00+01:00 to 2024-01-24 00:00:00+01:00\n",
      "test from:  2024-01-24 00:00:00+01:00 to 2024-01-28 00:00:00+01:00\n"
     ]
    }
   ],
   "source": [
    "n_fold = 5\n",
    "# get past n_fold + 1 wednesdays\n",
    "t_wednesday = t_now - pd.Timedelta(days=2-t_now.weekday())\n",
    "past_wednesdays = [t_wednesday - pd.Timedelta(days=7*(i+1)) for i in range(n_fold)]\n",
    "past_sundays = [t_wednesday + pd.Timedelta(days=4) for t_wednesday in past_wednesdays]\n",
    "\n",
    "res_dict = {}\n",
    "preds_dict = {}\n",
    "\n",
    "for fold_idx, t_wednesday in enumerate(past_wednesdays):\n",
    "\n",
    "    print('- '*15)\n",
    "    print(f\"fold {fold_idx+1}/{n_fold}\")\n",
    "    print('- '*15)\n",
    "\n",
    "    wed = t_wednesday.strftime('%Y-%m-%d')\n",
    "    sun = past_sundays[fold_idx].strftime('%Y-%m-%d')\n",
    "\n",
    "    subm_timestamps = []\n",
    "    for fcast in fcast_hor:\n",
    "        subm_timestamps.append((t_wednesday + pd.Timedelta(days=1) + pd.Timedelta(hours=fcast)))\n",
    "        \n",
    "    df_train = df_energy_small.loc[df_energy_small['timestamp_CET'] <= wed]\n",
    "    print(f\"train from: {df_train['timestamp_CET'].min()} to {df_train['timestamp_CET'].max()}\")\n",
    "    df_test = df_energy_small.loc[(df_energy_small['timestamp_CET'] >= wed) & (df_energy_small['timestamp_CET'] <= sun)]\n",
    "    print(f\"test from:  {df_test['timestamp_CET'].min()} to {df_test['timestamp_CET'].max()}\")   \n",
    "\n",
    "    # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "    # # Use past 2 years data for MSTL ... take last 365 * 24 values\n",
    "    # df_mstl = df_train.iloc[-1*365*24:].copy()\n",
    "    # # Use past 4 weeks data for HoltWinters\n",
    "    # df_hw = df_train.iloc[-4*7*24:].copy()\n",
    "\n",
    "    train_horizons = [4, 3, 2, 1, 0.5, 0.25]\n",
    "\n",
    "    # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "    # MSTL's usage example\n",
    "    mstl_models = {}\n",
    "\n",
    "    # For different train horizons (in years)\n",
    "    for train_horizon in train_horizons:\n",
    "        df_mstl_train = df_train.iloc[-int(train_horizon*365*24):].copy()\n",
    "        mstl_model = MSTL(season_length=[24, 24*7]).fit(df_mstl_train['gesamt'])\n",
    "        mstl_models[train_horizon] = mstl_model\n",
    "\n",
    "    # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "    # Holt-Winters' usage example\n",
    "    hw_models = {}\n",
    "\n",
    "    # [TODO] for different train horizons\n",
    "    for train_horizon in train_horizons:\n",
    "        df_hw_train = df_train.iloc[-int(train_horizon*365*24):].copy()\n",
    "        holt_winters_model = HoltWinters(season_length=24, error_type='A').fit(y=df_hw_train['gesamt'].values)\n",
    "        hw_models[train_horizon] = holt_winters_model\n",
    "\n",
    "    # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "    # Predictions\n",
    "    n_steps = 100\n",
    "    fcast_timestamps = pd.date_range(start=df_train['timestamp_CET'].max(), periods=n_steps, freq='H')\n",
    "\n",
    "    models = [mstl_models, hw_models]\n",
    "    model_names = ['mstl', 'holt_winters']\n",
    "\n",
    "    for model_idx, model_dict in enumerate(models):\n",
    "        for train_horizon, model in model_dict.items():\n",
    "            y_hat_dict = model.predict(h=n_steps, level=[50, 95])\n",
    "            y_hat_df = pd.DataFrame(y_hat_dict)\n",
    "\n",
    "            # add timestamp_CET column\n",
    "            y_hat_df['timestamp_CET'] = fcast_timestamps\n",
    "            y_hat_df\n",
    "\n",
    "            # rename columns\n",
    "            y_hat_df = y_hat_df.rename(columns={'mean': 'q 0.500',\n",
    "                                                'lo-50': 'q 0.250',\n",
    "                                                'hi-50': 'q 0.750',\n",
    "                                                'lo-95': 'q 0.025',\n",
    "                                                'hi-95': 'q 0.975'})\n",
    "            y_hat_df = y_hat_df[['timestamp_CET', 'q 0.025', 'q 0.250', 'q 0.500', 'q 0.750', 'q 0.975']]\n",
    "\n",
    "            # save predictions\n",
    "            preds_dict[f\"{model_names[model_idx]}_{train_horizon}\"] = y_hat_df\n",
    "\n",
    "            model_train.plot_quantile_fcast(y_hat_df, subm_timestamps, y_true=df_test, \n",
    "                                            title=f\"{model_names[model_idx]}-{train_horizon}y fcast\")\n",
    "            \n",
    "            df_scores = model_eval.eval_fcast(y_hat_df, df_test, subm_timestamps, quantiles)\n",
    "            # save the last row of the scores dataframe to final output\n",
    "            res_dict[f\"{model_names[model_idx]}_{train_horizon}\"] = df_scores.iloc[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abs error q 0.5</th>\n",
       "      <th>q-score 0.025</th>\n",
       "      <th>q-score 0.250</th>\n",
       "      <th>q-score 0.500</th>\n",
       "      <th>q-score 0.750</th>\n",
       "      <th>q-score 0.975</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mstl_0.5</th>\n",
       "      <td>3619.763069</td>\n",
       "      <td>0.459895</td>\n",
       "      <td>2.504522</td>\n",
       "      <td>3.619763</td>\n",
       "      <td>3.380971</td>\n",
       "      <td>0.727475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holt_winters_0.5</th>\n",
       "      <td>7493.730251</td>\n",
       "      <td>4.842286</td>\n",
       "      <td>8.659068</td>\n",
       "      <td>7.493730</td>\n",
       "      <td>5.203441</td>\n",
       "      <td>0.797945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  abs error q 0.5  q-score 0.025  q-score 0.250  \\\n",
       "mstl_0.5              3619.763069       0.459895       2.504522   \n",
       "holt_winters_0.5      7493.730251       4.842286       8.659068   \n",
       "\n",
       "                  q-score 0.500  q-score 0.750  q-score 0.975  \n",
       "mstl_0.5               3.619763       3.380971       0.727475  \n",
       "holt_winters_0.5       7.493730       5.203441       0.797945  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make dataframe from dictionary\n",
    "df_res = pd.concat(res_dict.values())\n",
    "df_res.index = res_dict.keys()\n",
    "df_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
