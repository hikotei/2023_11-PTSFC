{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_pinball_loss\n",
    "\n",
    "os.chdir(\"C:/2023_11-PTSFC\")\n",
    "import model_train as model_train\n",
    "import data_prepro as data_prepro\n",
    "import model_eval as model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model_eval' from 'C:\\\\2023_11-PTSFC\\\\model_eval.py'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(model_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 80136 entries, 2014-12-31 23:00:00+00:00 to 2024-02-21 22:00:00+00:00\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype              \n",
      "---  ------         --------------  -----              \n",
      " 0   timestamp_CET  80136 non-null  datetime64[ns, CET]\n",
      " 1   gesamt         80136 non-null  float64            \n",
      "dtypes: datetime64[ns, CET](1), float64(1)\n",
      "memory usage: 1.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"1\"  # Replace \"4\" with the desired number of cores\n",
    "\n",
    "quantiles = [0.025, 0.25, 0.5, 0.75, 0.975]\n",
    "fcast_hor = [36, 40, 44, 60, 64, 68] # in hours\n",
    "\n",
    "# = = = = = = = = = = = = = \n",
    "# get data\n",
    "# df_energy = data_prepro.get_energy_data_today(to_date=t_wednesday.strftime('%Y%m%d'))\n",
    "\n",
    "# Read data from file with specified data types\n",
    "df_energy = pd.read_csv(\"data/2015-01-01_2024-02-21_energy.csv\", index_col=0, parse_dates=[0])\n",
    "df_energy['timestamp_CET'] = pd.to_datetime(df_energy['timestamp_CET'], utc=True).dt.tz_convert('CET')\n",
    "print(df_energy.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Pickle File of Scores\n",
    "with open(\"2024-03-28_14-29-58 final all models/eval.pickle\", \"rb\") as f:\n",
    "    scores_dict = pickle.load(f)\n",
    "\n",
    "# Read Pickle File of Fcasts\n",
    "with open(\"2024-03-28_14-29-58 final all models/fcasts.pickle\", \"rb\") as f:\n",
    "    fcasts_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Models Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ranking sum\n",
      "xgboost_dummy_2020      92.0\n",
      "xgboost_dummy_2021      99.0\n",
      "mstl_0.5               102.0\n",
      "xgboost_dummy_2019     104.0\n",
      "lightgbm_dummy_2020    123.0\n",
      "dtype: float64\n",
      "> qscore sum\n",
      "mstl_0.5                 0.752816\n",
      "mstl_1                   0.800466\n",
      "xgboost_dummy_2021        0.82362\n",
      "xgboost_dummy_2020       0.828085\n",
      "xgboost_dummy_2019       0.860353\n",
      "lightgbm_dummy_2020      1.030033\n",
      "bench_pm_1month          1.044384\n",
      "grad_boost_2018_dummy    1.053459\n",
      "lightgbm_dummy_2021      1.064932\n",
      "grad_boost_2018_fturs    1.070209\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "input_dict = scores_dict\n",
    "weekly_scores_df_out = pd.DataFrame(columns=input_dict.keys(),\n",
    "                                    index=list(input_dict[list(input_dict.keys())[0]].keys()))\n",
    "\n",
    "for week_key, weekly_scores in input_dict.items():\n",
    "\n",
    "    for key, model_scores in weekly_scores.items():\n",
    "        \n",
    "        # print(model_scores)\n",
    "\n",
    "        # entire mean\n",
    "        model_qscore_mean = model_scores.values.mean()\n",
    "\n",
    "        # print(f\"> {key}: {model_qscore_mean}\")\n",
    "        weekly_scores_df_out.loc[key, week_key] = model_qscore_mean\n",
    "\n",
    "ranking_df = weekly_scores_df_out.rank(axis=0, method='min')\n",
    "ranking_sum = ranking_df.sum(axis=1)\n",
    "ranking_sum = ranking_sum.sort_values(ascending=True)\n",
    "print(\"> ranking sum\")\n",
    "pprint(ranking_sum.head(5))\n",
    "\n",
    "mean_qscores_df = weekly_scores_df_out.mean(axis=1).sort_values(ascending=True)\n",
    "print(\"> qscore sum\")\n",
    "pprint(mean_qscores_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Combinations ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bench_pm_2weeks', 'bench_same_month', 'bench_pm_1month', 'mstl_1', 'mstl_0.5', 'quant_reg_2015_sk', 'quant_reg_2018_sk', 'quant_reg_2015_sm', 'quant_reg_2018_sm', 'grad_boost_2015_fturs', 'grad_boost_2018_fturs', 'grad_boost_2015_dummy', 'grad_boost_2018_dummy', 'lightgbm_dummy_2019', 'lightgbm_dummy_2020', 'lightgbm_dummy_2021', 'xgboost_dummy_2019', 'xgboost_dummy_2020', 'xgboost_dummy_2021']\n"
     ]
    }
   ],
   "source": [
    "fcasts_dict_all = fcasts_dict\n",
    "all_models = list(fcasts_dict_all['2023-11-15'].keys())\n",
    "print(all_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969\n",
      "ensemble | bench_pm_2weeks, bench_same_month, bench_pm_1month\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2023-11-15 ...\n",
      "Submission timestamps = 2023-11-17 12:00:00+01:00 to 2023-11-18 20:00:00+01:00\n"
     ]
    }
   ],
   "source": [
    "all_models = list(fcasts_dict_all['2023-11-15'].keys())\n",
    "# Generate all possible combinations\n",
    "ens_size = 3\n",
    "combis = list(itertools.combinations(all_models, ens_size))\n",
    "# filter out all ensembles with repeating models\n",
    "combis = [combi for combi in combis if len(set(combi)) == ens_size]\n",
    "print(len(combis))\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = pd.Timestamp('2023-11-15')\n",
    "end_date = pd.Timestamp('2024-02-14')\n",
    "\n",
    "# Generate a list of weekly dates in UTC\n",
    "fcast_dates_cet = pd.date_range(start=start_date, end=end_date, freq='W-WED').tz_localize('CET').strftime('%Y-%m-%d').tolist()\n",
    "\n",
    "all_combi_names = [f\"ensemble | {', '.join(combi)}\" for combi in combis]\n",
    "print(all_combi_names[0])\n",
    "res_df = pd.DataFrame(index=all_combi_names, columns=fcast_dates_cet)\n",
    "\n",
    "# Iterate over the forecast dates\n",
    "for fcast_idx, fcast_date in enumerate(fcast_dates_cet):\n",
    "\n",
    "    print('= '*30)\n",
    "    print(f\"Forecasting for week starting from {fcast_date} ...\")\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # generate prediction timestamps based on t0 = following thursday 00:00\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    # Calculate the Thursday and Wednesday of the week\n",
    "    t_wednesday = pd.Timestamp(fcast_date).replace(hour=0, minute=0, second=0, microsecond=0).tz_localize('CET')\n",
    "    t_thursday = t_wednesday + pd.Timedelta(days=1)\n",
    "\n",
    "    # Generate required submission timestamps\n",
    "    subm_timestamps = [(t_thursday + pd.Timedelta(hours=fcast)) for fcast in fcast_hor]\n",
    "    print(f\"Submission timestamps = {subm_timestamps[0]} to {subm_timestamps[-1]}\")\n",
    "\n",
    "    weekly_fcasts = fcasts_dict_all[fcast_date]\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # Evaluation based on submission timestamps\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    # get actual values at every submission timestamp\n",
    "    df_energy_eval = df_energy.loc[df_energy['timestamp_CET'].isin(subm_timestamps)].copy()\n",
    "\n",
    "    for combi_idx, combi in enumerate(combis):\n",
    "\n",
    "        # calculate ensemble between the preds of the models in the current combination\n",
    "        pred_list = [weekly_fcasts[model] for model in combi]\n",
    "        new_name = f\"ensemble | {', '.join(combi)}\"\n",
    "\n",
    "        # Ignore timestamp_CET column and take the average of the quantiles\n",
    "        pred_vals_list = [pred.iloc[:, 1:].copy() for pred in pred_list]\n",
    "\n",
    "        # Take the average of the quantiles across all models in the ensemble\n",
    "        ens_pred_df = pred_list[0].copy()\n",
    "        ens_pred_df.iloc[:, 1:] = sum(pred_vals_list) / len(pred_vals_list)\n",
    "        \n",
    "        df_scores = model_eval.eval_fcast_qscore(ens_pred_df, df_energy_eval, subm_timestamps, quantiles)\n",
    "\n",
    "        # Save the last row of the scores dataframe to final output\n",
    "        res_df.loc[new_name, fcast_date] = df_scores.values.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ensemble | mstl_0.5, grad_boost_2018_fturs, xgboost_dummy_2021    1.214518\n",
       "ensemble | mstl_0.5, grad_boost_2018_dummy, xgboost_dummy_2021    1.221724\n",
       "ensemble | mstl_0.5, grad_boost_2015_dummy, xgboost_dummy_2021     1.23793\n",
       "ensemble | mstl_0.5, grad_boost_2015_fturs, xgboost_dummy_2021    1.239091\n",
       "ensemble | mstl_0.5, xgboost_dummy_2019, xgboost_dummy_2021       1.243077\n",
       "ensemble | mstl_1, mstl_0.5, xgboost_dummy_2021                   1.247709\n",
       "ensemble | mstl_1, mstl_0.5, grad_boost_2015_dummy                1.251296\n",
       "ensemble | mstl_1, mstl_0.5, grad_boost_2015_fturs                1.251526\n",
       "ensemble | mstl_0.5, grad_boost_2015_fturs, xgboost_dummy_2019    1.254158\n",
       "ensemble | bench_pm_2weeks, mstl_0.5, xgboost_dummy_2021          1.258444\n",
       "ensemble | mstl_0.5, grad_boost_2015_dummy, xgboost_dummy_2019    1.260238\n",
       "ensemble | mstl_1, grad_boost_2018_fturs, xgboost_dummy_2021       1.26158\n",
       "ensemble | mstl_1, mstl_0.5, grad_boost_2018_dummy                1.265321\n",
       "ensemble | mstl_1, grad_boost_2018_dummy, xgboost_dummy_2021      1.265393\n",
       "ensemble | mstl_1, mstl_0.5, grad_boost_2018_fturs                1.269515\n",
       "ensemble | mstl_1, mstl_0.5, xgboost_dummy_2019                   1.270842\n",
       "ensemble | mstl_1, grad_boost_2015_dummy, xgboost_dummy_2021      1.279676\n",
       "ensemble | mstl_1, grad_boost_2015_fturs, xgboost_dummy_2021      1.279856\n",
       "ensemble | bench_pm_2weeks, mstl_0.5, xgboost_dummy_2019          1.281114\n",
       "ensemble | mstl_0.5, grad_boost_2018_fturs, xgboost_dummy_2019    1.285668\n",
       "dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.mean(axis=1).sort_values(ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission timestamps = 2023-11-17 12:00:00+01:00 to 2023-11-18 20:00:00+01:00\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'lightgbm_dummy_2020_5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m weekly_fcasts \u001b[38;5;241m=\u001b[39m fcasts_dict_all[fcast_date]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# calculate ensemble between the preds of the models in the current combination\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m pred_list \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mweekly_fcasts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_list\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     20\u001b[0m new_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensemble | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(combi)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Ignore timestamp_CET column and take the average of the quantiles\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[62], line 19\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     16\u001b[0m weekly_fcasts \u001b[38;5;241m=\u001b[39m fcasts_dict_all[fcast_date]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# calculate ensemble between the preds of the models in the current combination\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m pred_list \u001b[38;5;241m=\u001b[39m [\u001b[43mweekly_fcasts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m model_list]\n\u001b[0;32m     20\u001b[0m new_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensemble | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(combi)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Ignore timestamp_CET column and take the average of the quantiles\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'lightgbm_dummy_2020_5'"
     ]
    }
   ],
   "source": [
    "# Create Own Ensembles\n",
    "model_list = ['mstl_0.5', 'bench_pm_1month', 'lightgbm_dummy_2020', 'xgboost_dummy_2021']\n",
    "\n",
    "model_scores = np.zeros(len(fcast_dates_cet))                \n",
    "# Iterate over the forecast dates\n",
    "for fcast_idx, fcast_date in enumerate(fcast_dates_cet):\n",
    "\n",
    "    # Calculate the Thursday and Wednesday of the week\n",
    "    t_wednesday = pd.Timestamp(fcast_date).replace(hour=0, minute=0, second=0, microsecond=0).tz_localize('CET')\n",
    "    subm_timestamps = [(t_wednesday + pd.Timedelta(days=1, hours=fcast)) for fcast in fcast_hor]\n",
    "    print(f\"Submission timestamps = {subm_timestamps[0]} to {subm_timestamps[-1]}\")\n",
    "\n",
    "    # get actual values at every submission timestamp\n",
    "    df_energy_eval = df_energy.loc[df_energy['timestamp_CET'].isin(subm_timestamps)].copy()\n",
    "    # get weekly fcast\n",
    "    weekly_fcasts = fcasts_dict_all[fcast_date]\n",
    "\n",
    "    # calculate ensemble between the preds of the models in the current combination\n",
    "    pred_list = [weekly_fcasts[model] for model in model_list]\n",
    "    new_name = f\"ensemble | {', '.join(combi)}\"\n",
    "\n",
    "    # Ignore timestamp_CET column and take the average of the quantiles\n",
    "    pred_vals_list = [pred.iloc[:, 1:].copy() for pred in pred_list]\n",
    "\n",
    "    # Take the average of the quantiles across all models in the ensemble\n",
    "    ens_pred_df = pred_list[0].copy()\n",
    "    ens_pred_df.iloc[:, 1:] = sum(pred_vals_list) / len(pred_vals_list)\n",
    "\n",
    "    df_scores = model_eval.eval_fcast_qscore(ens_pred_df, df_energy_eval, subm_timestamps, quantiles)\n",
    "    model_scores[fcast_idx] = df_scores.values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2579703451958013"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
