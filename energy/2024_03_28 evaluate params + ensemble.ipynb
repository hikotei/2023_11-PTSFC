{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_pinball_loss\n",
    "\n",
    "os.chdir(\"C:/2023_11-PTSFC\")\n",
    "import model_train as model_train\n",
    "import data_prepro as data_prepro\n",
    "import model_eval as model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model_eval' from 'C:\\\\2023_11-PTSFC\\\\model_eval.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(model_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 80136 entries, 2014-12-31 23:00:00+00:00 to 2024-02-21 22:00:00+00:00\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype              \n",
      "---  ------         --------------  -----              \n",
      " 0   timestamp_CET  80136 non-null  datetime64[ns, CET]\n",
      " 1   gesamt         80136 non-null  float64            \n",
      "dtypes: datetime64[ns, CET](1), float64(1)\n",
      "memory usage: 1.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"1\"  # Replace \"4\" with the desired number of cores\n",
    "\n",
    "quantiles = [0.025, 0.25, 0.5, 0.75, 0.975]\n",
    "fcast_hor = [36, 40, 44, 60, 64, 68] # in hours\n",
    "\n",
    "# = = = = = = = = = = = = = \n",
    "# get data\n",
    "# df_energy = data_prepro.get_energy_data_today(to_date=t_wednesday.strftime('%Y%m%d'))\n",
    "\n",
    "# Read data from file with specified data types\n",
    "df_energy = pd.read_csv(\"data/2015-01-01_2024-02-21_energy.csv\", index_col=0, parse_dates=[0])\n",
    "df_energy['timestamp_CET'] = pd.to_datetime(df_energy['timestamp_CET'], utc=True).dt.tz_convert('CET')\n",
    "print(df_energy.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Pickle File of Scores\n",
    "with open(\"2024-03-28_01-32-39 lightgbm, xgboost 2020/eval.pickle\", \"rb\") as f:\n",
    "    scores_dict_2020 = pickle.load(f)\n",
    "\n",
    "# Read Pickle File of Scores\n",
    "with open(\"2024-03-28_01-11-41 lightgbm, xgboost 2022/eval.pickle\", \"rb\") as f:\n",
    "    scores_dict_2022 = pickle.load(f)\n",
    "\n",
    "# Read Pickle File of Fcasts\n",
    "with open(\"2024-03-28_01-32-39 lightgbm, xgboost 2020/fcasts.pickle\", \"rb\") as f:\n",
    "    fcasts_dict_2020 = pickle.load(f)\n",
    "\n",
    "# Read Pickle File of Fcasts\n",
    "with open(\"2024-03-28_01-11-41 lightgbm, xgboost 2022/fcasts.pickle\", \"rb\") as f:\n",
    "    fcasts_dict_2022 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_dict(scores_dict, model_name):\n",
    "    scores_dict_out = scores_dict.copy()\n",
    "    for key in scores_dict.keys():\n",
    "        scores_dict_out[key] = {k: v for k, v in scores_dict[key].items() if model_name in k}\n",
    "    return scores_dict_out\n",
    "\n",
    "scores_dict_2020_lgbm = subset_dict(scores_dict_2020, \"lightgbm\")\n",
    "scores_dict_2022_lgbm = subset_dict(scores_dict_2022, \"lightgbm\")\n",
    "\n",
    "scores_dict_2020_xgb = subset_dict(scores_dict_2020, \"xgboost\")\n",
    "scores_dict_2022_xgb = subset_dict(scores_dict_2022, \"xgboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all sub dictionaries with same key in 2 dictionaries\n",
    "def combine_dicts(dict1, dict2):\n",
    "    dict_out = dict1.copy()\n",
    "    for key in dict1.keys():\n",
    "        dict_out[key] = {k: v for k, v in dict1[key].items()}\n",
    "        dict_out[key].update({k: v for k, v in dict2[key].items()})\n",
    "    return dict_out \n",
    "\n",
    "scores_dict_lgbm = combine_dicts(scores_dict_2020_lgbm, scores_dict_2022_lgbm)\n",
    "scores_dict_xgb = combine_dicts(scores_dict_2020_xgb, scores_dict_2022_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Models Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ranking sum\n",
      "xgboost_dummy_2020_1      77.0\n",
      "xgboost_dummy_2           83.0\n",
      "mstl_0.5                  84.0\n",
      "grad_boost_2018_dummy    102.0\n",
      "bench_pm_1month          104.0\n",
      "dtype: float64\n",
      "> qscore sum\n",
      "mstl_0.5                 0.752816\n",
      "mstl_1                   0.800466\n",
      "xgboost_dummy_2020_1     0.843151\n",
      "xgboost_dummy_2          0.874116\n",
      "bench_pm_1month          1.044384\n",
      "grad_boost_2018_dummy    1.053459\n",
      "grad_boost_2018_fturs    1.070209\n",
      "bench_pm_2weeks          1.076728\n",
      "quant_reg_2018_sk        1.109495\n",
      "grad_boost_2015_dummy    1.145172\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "scores_dict_all = combine_dicts(scores_dict_2020, scores_dict_2022)\n",
    "\n",
    "# Remove all keys in subdicts except for the specified patterns\n",
    "for key in scores_dict_all.keys():\n",
    "    scores_dict_all[key] = {k: v for k, v in scores_dict_all[key].items() \n",
    "                            if (\"xgboost_dummy_2020_1\" in k) \n",
    "                            or (\"xgboost_dummy_2\" in k and \"2020\" not in k) \n",
    "                            or (\"lightgbm_dummy_2020_5\" in k) \n",
    "                            or (\"lightgbm_dummy_21\" in k) \n",
    "                            or (\"xgboost\" not in k and \"lightgbm\" not in k)}\n",
    "\n",
    "input_dict = scores_dict_all\n",
    "\n",
    "weekly_scores_df_out = pd.DataFrame(columns=input_dict.keys(),\n",
    "                                    index=list(input_dict[list(input_dict.keys())[0]].keys()))\n",
    "\n",
    "for week_key, weekly_scores in input_dict.items():\n",
    "\n",
    "    for key, model_scores in weekly_scores.items():\n",
    "        \n",
    "        # print(model_scores)\n",
    "\n",
    "        # entire mean\n",
    "        model_qscore_mean = model_scores.values.mean()\n",
    "\n",
    "        # print(f\"> {key}: {model_qscore_mean}\")\n",
    "        weekly_scores_df_out.loc[key, week_key] = model_qscore_mean\n",
    "\n",
    "ranking_df = weekly_scores_df_out.rank(axis=0, method='min')\n",
    "ranking_sum = ranking_df.sum(axis=1)\n",
    "ranking_sum = ranking_sum.sort_values(ascending=True)\n",
    "print(\"> ranking sum\")\n",
    "pprint(ranking_sum.head(5))\n",
    "\n",
    "mean_qscores_df = weekly_scores_df_out.mean(axis=1).sort_values(ascending=True)\n",
    "print(\"> qscore sum\")\n",
    "pprint(mean_qscores_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Combinations ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bench_pm_2weeks', 'bench_same_month', 'bench_pm_1month', 'mstl_1', 'mstl_0.5', 'quant_reg_2015_sk', 'quant_reg_2018_sk', 'quant_reg_2015_sm', 'quant_reg_2018_sm', 'grad_boost_2015_fturs', 'grad_boost_2018_fturs', 'grad_boost_2015_dummy', 'grad_boost_2018_dummy', 'lightgbm_dummy_2020_5', 'xgboost_dummy_2020_1'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcasts_dict_all = combine_dicts(fcasts_dict_2020, fcasts_dict_2020)\n",
    "\n",
    "# Remove all keys in subdicts except for the specified patterns\n",
    "for key in fcasts_dict_all.keys():\n",
    "    fcasts_dict_all[key] = {k: v for k, v in fcasts_dict_all[key].items() \n",
    "                            if (\"xgboost_dummy_2020_1\" in k) \n",
    "                            or (\"xgboost_dummy_2\" in k and \"2020\" not in k) \n",
    "                            or (\"lightgbm_dummy_2020_5\" in k) \n",
    "                            or (\"lightgbm_dummy_21\" in k) \n",
    "                            or (\"xgboost\" not in k and \"lightgbm\" not in k)}\n",
    "\n",
    "fcasts_dict_all['2023-11-15'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455\n",
      "ensemble | bench_pm_2weeks, bench_same_month, bench_pm_1month\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2023-11-15 ...\n",
      "Submission timestamps = 2023-11-17 12:00:00+01:00 to 2023-11-18 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2023-11-22 ...\n",
      "Submission timestamps = 2023-11-24 12:00:00+01:00 to 2023-11-25 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2023-11-29 ...\n",
      "Submission timestamps = 2023-12-01 12:00:00+01:00 to 2023-12-02 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2023-12-06 ...\n",
      "Submission timestamps = 2023-12-08 12:00:00+01:00 to 2023-12-09 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2023-12-13 ...\n",
      "Submission timestamps = 2023-12-15 12:00:00+01:00 to 2023-12-16 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2023-12-20 ...\n",
      "Submission timestamps = 2023-12-22 12:00:00+01:00 to 2023-12-23 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2023-12-27 ...\n",
      "Submission timestamps = 2023-12-29 12:00:00+01:00 to 2023-12-30 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2024-01-03 ...\n",
      "Submission timestamps = 2024-01-05 12:00:00+01:00 to 2024-01-06 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2024-01-10 ...\n",
      "Submission timestamps = 2024-01-12 12:00:00+01:00 to 2024-01-13 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2024-01-17 ...\n",
      "Submission timestamps = 2024-01-19 12:00:00+01:00 to 2024-01-20 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2024-01-24 ...\n",
      "Submission timestamps = 2024-01-26 12:00:00+01:00 to 2024-01-27 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2024-01-31 ...\n",
      "Submission timestamps = 2024-02-02 12:00:00+01:00 to 2024-02-03 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2024-02-07 ...\n",
      "Submission timestamps = 2024-02-09 12:00:00+01:00 to 2024-02-10 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2024-02-14 ...\n",
      "Submission timestamps = 2024-02-16 12:00:00+01:00 to 2024-02-17 20:00:00+01:00\n"
     ]
    }
   ],
   "source": [
    "all_models = list(fcasts_dict_all['2023-11-15'].keys())\n",
    "# Generate all possible combinations\n",
    "ens_size = 3\n",
    "combis = list(itertools.combinations(all_models, ens_size))\n",
    "# filter out all ensembles with repeating models\n",
    "combis = [combi for combi in combis if len(set(combi)) == ens_size]\n",
    "print(len(combis))\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = pd.Timestamp('2023-11-15')\n",
    "end_date = pd.Timestamp('2024-02-14')\n",
    "\n",
    "# Generate a list of weekly dates in UTC\n",
    "fcast_dates_cet = pd.date_range(start=start_date, end=end_date, freq='W-WED').tz_localize('CET').strftime('%Y-%m-%d').tolist()\n",
    "\n",
    "all_combi_names = [f\"ensemble | {', '.join(combi)}\" for combi in combis]\n",
    "print(all_combi_names[0])\n",
    "res_df = pd.DataFrame(index=all_combi_names, columns=fcast_dates_cet)\n",
    "\n",
    "# Iterate over the forecast dates\n",
    "for fcast_idx, fcast_date in enumerate(fcast_dates_cet):\n",
    "\n",
    "    print('= '*30)\n",
    "    print(f\"Forecasting for week starting from {fcast_date} ...\")\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # generate prediction timestamps based on t0 = following thursday 00:00\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    # Calculate the Thursday and Wednesday of the week\n",
    "    t_wednesday = pd.Timestamp(fcast_date).replace(hour=0, minute=0, second=0, microsecond=0).tz_localize('CET')\n",
    "    t_thursday = t_wednesday + pd.Timedelta(days=1)\n",
    "\n",
    "    # Generate required submission timestamps\n",
    "    subm_timestamps = [(t_thursday + pd.Timedelta(hours=fcast)) for fcast in fcast_hor]\n",
    "    print(f\"Submission timestamps = {subm_timestamps[0]} to {subm_timestamps[-1]}\")\n",
    "\n",
    "    weekly_fcasts = fcasts_dict_all[fcast_date]\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # Evaluation based on submission timestamps\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    # get actual values at every submission timestamp\n",
    "    df_energy_eval = df_energy.loc[df_energy['timestamp_CET'].isin(subm_timestamps)].copy()\n",
    "\n",
    "    for combi_idx, combi in enumerate(combis):\n",
    "\n",
    "        # calculate ensemble between the preds of the models in the current combination\n",
    "        pred_list = [weekly_fcasts[model] for model in combi]\n",
    "        new_name = f\"ensemble | {', '.join(combi)}\"\n",
    "\n",
    "        # Ignore timestamp_CET column and take the average of the quantiles\n",
    "        pred_vals_list = [pred.iloc[:, 1:].copy() for pred in pred_list]\n",
    "\n",
    "        # Take the average of the quantiles across all models in the ensemble\n",
    "        ens_pred_df = pred_list[0].copy()\n",
    "        ens_pred_df.iloc[:, 1:] = sum(pred_vals_list) / len(pred_vals_list)\n",
    "        \n",
    "        df_scores = model_eval.eval_fcast_qscore(ens_pred_df, df_energy_eval, subm_timestamps, quantiles)\n",
    "\n",
    "        # Save the last row of the scores dataframe to final output\n",
    "        res_df.loc[new_name, fcast_date] = df_scores.values.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ensemble | mstl_1, mstl_0.5, lightgbm_dummy_2020_5                    1.12704\n",
       "ensemble | mstl_0.5, lightgbm_dummy_2020_5, xgboost_dummy_2020_1     1.177848\n",
       "ensemble | mstl_1, lightgbm_dummy_2020_5, xgboost_dummy_2020_1       1.181781\n",
       "ensemble | mstl_1, grad_boost_2018_fturs, lightgbm_dummy_2020_5      1.193096\n",
       "ensemble | mstl_1, grad_boost_2018_dummy, lightgbm_dummy_2020_5      1.196894\n",
       "ensemble | mstl_1, grad_boost_2015_fturs, lightgbm_dummy_2020_5      1.199461\n",
       "ensemble | mstl_0.5, grad_boost_2018_fturs, lightgbm_dummy_2020_5    1.200798\n",
       "ensemble | mstl_0.5, grad_boost_2018_dummy, lightgbm_dummy_2020_5    1.201326\n",
       "ensemble | mstl_1, grad_boost_2015_dummy, lightgbm_dummy_2020_5      1.203797\n",
       "ensemble | mstl_0.5, grad_boost_2015_dummy, lightgbm_dummy_2020_5    1.210538\n",
       "ensemble | mstl_0.5, grad_boost_2015_fturs, lightgbm_dummy_2020_5    1.212675\n",
       "ensemble | bench_pm_1month, mstl_1, lightgbm_dummy_2020_5            1.234264\n",
       "ensemble | bench_pm_1month, mstl_0.5, lightgbm_dummy_2020_5          1.236335\n",
       "ensemble | bench_pm_2weeks, mstl_0.5, lightgbm_dummy_2020_5          1.238246\n",
       "ensemble | bench_pm_2weeks, mstl_1, lightgbm_dummy_2020_5             1.24208\n",
       "ensemble | mstl_0.5, quant_reg_2018_sk, lightgbm_dummy_2020_5        1.244013\n",
       "ensemble | mstl_1, mstl_0.5, grad_boost_2015_dummy                   1.251296\n",
       "ensemble | mstl_1, mstl_0.5, grad_boost_2015_fturs                   1.251526\n",
       "ensemble | mstl_1, quant_reg_2018_sk, lightgbm_dummy_2020_5          1.260829\n",
       "ensemble | mstl_1, mstl_0.5, grad_boost_2018_dummy                   1.265321\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.mean(axis=1).sort_values(ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission timestamps = 2023-11-17 12:00:00+01:00 to 2023-11-18 20:00:00+01:00\n",
      "Submission timestamps = 2023-11-24 12:00:00+01:00 to 2023-11-25 20:00:00+01:00\n",
      "Submission timestamps = 2023-12-01 12:00:00+01:00 to 2023-12-02 20:00:00+01:00\n",
      "Submission timestamps = 2023-12-08 12:00:00+01:00 to 2023-12-09 20:00:00+01:00\n",
      "Submission timestamps = 2023-12-15 12:00:00+01:00 to 2023-12-16 20:00:00+01:00\n",
      "Submission timestamps = 2023-12-22 12:00:00+01:00 to 2023-12-23 20:00:00+01:00\n",
      "Submission timestamps = 2023-12-29 12:00:00+01:00 to 2023-12-30 20:00:00+01:00\n",
      "Submission timestamps = 2024-01-05 12:00:00+01:00 to 2024-01-06 20:00:00+01:00\n",
      "Submission timestamps = 2024-01-12 12:00:00+01:00 to 2024-01-13 20:00:00+01:00\n",
      "Submission timestamps = 2024-01-19 12:00:00+01:00 to 2024-01-20 20:00:00+01:00\n",
      "Submission timestamps = 2024-01-26 12:00:00+01:00 to 2024-01-27 20:00:00+01:00\n",
      "Submission timestamps = 2024-02-02 12:00:00+01:00 to 2024-02-03 20:00:00+01:00\n",
      "Submission timestamps = 2024-02-09 12:00:00+01:00 to 2024-02-10 20:00:00+01:00\n",
      "Submission timestamps = 2024-02-16 12:00:00+01:00 to 2024-02-17 20:00:00+01:00\n"
     ]
    }
   ],
   "source": [
    "# Create Own Ensembles\n",
    "model_list = ['mstl_0.5', 'lightgbm_dummy_2020_5', 'bench_pm_1month', 'xgboost_dummy_2020_1']\n",
    "\n",
    "model_scores = np.zeros(len(fcast_dates_cet))                \n",
    "# Iterate over the forecast dates\n",
    "for fcast_idx, fcast_date in enumerate(fcast_dates_cet):\n",
    "\n",
    "    # Calculate the Thursday and Wednesday of the week\n",
    "    t_wednesday = pd.Timestamp(fcast_date).replace(hour=0, minute=0, second=0, microsecond=0).tz_localize('CET')\n",
    "    subm_timestamps = [(t_wednesday + pd.Timedelta(days=1, hours=fcast)) for fcast in fcast_hor]\n",
    "    print(f\"Submission timestamps = {subm_timestamps[0]} to {subm_timestamps[-1]}\")\n",
    "\n",
    "    # get actual values at every submission timestamp\n",
    "    df_energy_eval = df_energy.loc[df_energy['timestamp_CET'].isin(subm_timestamps)].copy()\n",
    "    # get weekly fcast\n",
    "    weekly_fcasts = fcasts_dict_all[fcast_date]\n",
    "\n",
    "    # calculate ensemble between the preds of the models in the current combination\n",
    "    pred_list = [weekly_fcasts[model] for model in model_list]\n",
    "    new_name = f\"ensemble | {', '.join(combi)}\"\n",
    "\n",
    "    # Ignore timestamp_CET column and take the average of the quantiles\n",
    "    pred_vals_list = [pred.iloc[:, 1:].copy() for pred in pred_list]\n",
    "\n",
    "    # Take the average of the quantiles across all models in the ensemble\n",
    "    ens_pred_df = pred_list[0].copy()\n",
    "    ens_pred_df.iloc[:, 1:] = sum(pred_vals_list) / len(pred_vals_list)\n",
    "\n",
    "    df_scores = model_eval.eval_fcast_qscore(ens_pred_df, df_energy_eval, subm_timestamps, quantiles)\n",
    "    model_scores[fcast_idx] = df_scores.values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2579703451958013"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM & XGBoost Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ranking sum\n",
      "lightgbm_dummy_2020_9    273.0\n",
      "lightgbm_dummy_2020_5    273.0\n",
      "lightgbm_dummy_21        276.0\n",
      "lightgbm_dummy_2020_4    285.0\n",
      "lightgbm_dummy_2020_8    285.0\n",
      "dtype: float64\n",
      "> qscore sum\n",
      "lightgbm_dummy_2020_5     1.328925\n",
      "lightgbm_dummy_2020_9     1.328925\n",
      "lightgbm_dummy_2020_23    1.347638\n",
      "lightgbm_dummy_2020_22    1.348782\n",
      "lightgbm_dummy_21         1.379352\n",
      "lightgbm_dummy_2020_6     1.384033\n",
      "lightgbm_dummy_2020_10    1.384033\n",
      "lightgbm_dummy_2020_7     1.395336\n",
      "lightgbm_dummy_2020_11    1.395336\n",
      "lightgbm_dummy_20         1.397269\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# input_dict = scores_dict_xgb\n",
    "input_dict = scores_dict_lgbm\n",
    "\n",
    "weekly_scores_df_out = pd.DataFrame(columns=input_dict.keys(),\n",
    "                                    index=list(input_dict[list(input_dict.keys())[0]].keys()))\n",
    "\n",
    "for week_key, weekly_scores in input_dict.items():\n",
    "\n",
    "    for key, model_scores in weekly_scores.items():\n",
    "        \n",
    "        # print(model_scores)\n",
    "\n",
    "        # entire mean\n",
    "        model_qscore_mean = model_scores.values.mean()\n",
    "        # quantile mean\n",
    "        # model_qscore_mean = model_scores.mean(axis=0).values[quantile]\n",
    "\n",
    "        # print(f\"> {key}: {model_qscore_mean}\")\n",
    "        weekly_scores_df_out.loc[key, week_key] = model_qscore_mean\n",
    "\n",
    "    # output keys of weekly top 5 models with lowest mean score\n",
    "    # top5 = weekly_scores_df_out.loc[:, week_key].sort_values().head(5)\n",
    "    # print(f\"{week_key}: {top5.index.to_list()}\")\n",
    "\n",
    "# take dataframe weekly_scores_dict_out\n",
    "# assign rankings to each model (index) for each week (columns)\n",
    "# sum the rankings for each model and sort by the sum\n",
    "\n",
    "ranking_df = weekly_scores_df_out.rank(axis=0, method='min')\n",
    "ranking_sum = ranking_df.sum(axis=1)\n",
    "ranking_sum = ranking_sum.sort_values(ascending=True)\n",
    "print(\"> ranking sum\")\n",
    "pprint(ranking_sum.head(5))\n",
    "\n",
    "# # plot ranking_sum values as points and colour point red if 2020 is in index\n",
    "# plt.figure(figsize=(6,3))\n",
    "# plt.plot(ranking_sum.values, 'o', ms=4)\n",
    "# for i, model in enumerate(ranking_sum.index):\n",
    "#     if '2020' in model:\n",
    "#         plt.plot(i, ranking_sum[model], 'ro', ms=4)\n",
    "# plt.show()\n",
    "\n",
    "# instead of taking sum of rankings, take lowest qscore\n",
    "mean_qscores_df = weekly_scores_df_out.mean(axis=1).sort_values(ascending=True)\n",
    "print(\"> qscore sum\")\n",
    "pprint(mean_qscores_df.head(10))\n",
    "\n",
    "# # plot mean of qscores for each model\n",
    "# plt.figure(figsize=(6,3))\n",
    "# plt.plot(mean_qscores_df.values, 'o', ms=4)\n",
    "# # plt.bar(mean_qscores_df.index, mean_qscores_df.values)\n",
    "# for i, model in enumerate(mean_qscores_df.index):\n",
    "#     if '2020' in model:\n",
    "#         plt.plot(i, mean_qscores_df[model], 'ro', ms=4)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'booster': 'gbtree',\n",
      " 'eval_metric': 'quantile',\n",
      " 'learning_rate': 0.2,\n",
      " 'max_depth': 4,\n",
      " 'n_estimators': 100,\n",
      " 'objective': 'reg:quantileerror'}\n",
      "{'booster': 'gbtree',\n",
      " 'eval_metric': 'quantile',\n",
      " 'learning_rate': 0.2,\n",
      " 'max_depth': 4,\n",
      " 'n_estimators': 200,\n",
      " 'objective': 'reg:quantileerror'}\n",
      "{'booster': 'gbtree',\n",
      " 'eval_metric': 'quantile',\n",
      " 'learning_rate': 0.2,\n",
      " 'max_depth': 10,\n",
      " 'n_estimators': 100,\n",
      " 'objective': 'reg:quantileerror'}\n",
      "{'booster': 'gbtree',\n",
      " 'eval_metric': 'quantile',\n",
      " 'learning_rate': 0.2,\n",
      " 'max_depth': 10,\n",
      " 'n_estimators': 200,\n",
      " 'objective': 'reg:quantileerror'}\n",
      "= = = = = = = = = = = = = = = = = = = = \n",
      "= = = = = = = = = = = = = = = = = = = = \n",
      "{'boosting_type': 'gbdt',\n",
      " 'learning_rate': 0.1,\n",
      " 'max_depth': 4,\n",
      " 'n_estimators': 100,\n",
      " 'num_leaves': 15,\n",
      " 'verbose': -1}\n",
      "{'boosting_type': 'gbdt',\n",
      " 'learning_rate': 0.1,\n",
      " 'max_depth': 4,\n",
      " 'n_estimators': 200,\n",
      " 'num_leaves': 15,\n",
      " 'verbose': -1}\n",
      "{'boosting_type': 'gbdt',\n",
      " 'learning_rate': 0.3,\n",
      " 'max_depth': 10,\n",
      " 'n_estimators': 200,\n",
      " 'num_leaves': 20,\n",
      " 'verbose': -1}\n"
     ]
    }
   ],
   "source": [
    "def generate_param_grids(params):\n",
    "    \n",
    "        param_values = list(itertools.product(*params.values()))\n",
    "        param_names = list(params.keys())\n",
    "\n",
    "        param_grids = []\n",
    "\n",
    "        for values in param_values:\n",
    "            param_dict = dict(zip(param_names, values))\n",
    "            param_grids.append(param_dict)\n",
    "\n",
    "        return param_grids\n",
    "\n",
    "lgbm_params = {\n",
    "    'max_depth': [4, 10],\n",
    "    'num_leaves': [5, 15, 20],\n",
    "    'learning_rate': [0.1, 0.3],\n",
    "    'n_estimators': [100, 200],\n",
    "    'boosting_type': ['gbdt'],\n",
    "    'verbose': [-1]\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'objective': ['reg:quantileerror'],\n",
    "    'eval_metric': ['quantile'],\n",
    "    'booster': ['gbtree'],\n",
    "    'max_depth': [4, 10],\n",
    "    'learning_rate': [0.2],\n",
    "    'n_estimators': [100, 200],\n",
    "}\n",
    "\n",
    "all_lgbm_params = generate_param_grids(lgbm_params)\n",
    "all_xgb_params = generate_param_grids(xgb_params)\n",
    "\n",
    "# pretty print 1, 0, 2 from all_xgb_params\n",
    "xgb_idx_list = [0, 1, 2, 3]\n",
    "lgbm_idx_list = [4, 5, 23]\n",
    "\n",
    "for idx in xgb_idx_list:\n",
    "    pprint(all_xgb_params[idx])\n",
    "\n",
    "print('= '*20)\n",
    "print('= '*20)\n",
    "\n",
    "for idx in lgbm_idx_list:\n",
    "    pprint(all_lgbm_params[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
