{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanting/opt/anaconda3/lib/python3.9/site-packages/statsforecast/core.py:26: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import statsmodels.api as sm\n",
    "# from sklearn.linear_model import QuantileRegressor, LinearRegression\n",
    "# from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_pinball_loss # mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "from statsforecast.models import MSTL\n",
    "\n",
    "# = = = = = =\n",
    "# own stuff\n",
    "# = = = = = =\n",
    "# os.chdir(\"C:/2023_11-PTSFC\")\n",
    "os.chdir(\"/Users/yanting/Desktop/2023_11-PTSFC\")\n",
    "import data_prepro as data_prepro\n",
    "import model_train as model_train\n",
    "import model_fcast as model_fcast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"1\"  # Replace \"4\" with the desired number of cores\n",
    "\n",
    "quantiles = [0.025, 0.25, 0.5, 0.75, 0.975]\n",
    "fcast_hor = [36, 40, 44, 60, 64, 68] # in hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 80136 entries, 2014-12-31 23:00:00+00:00 to 2024-02-21 22:00:00+00:00\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype              \n",
      "---  ------         --------------  -----              \n",
      " 0   timestamp_CET  80136 non-null  datetime64[ns, CET]\n",
      " 1   gesamt         80136 non-null  float64            \n",
      "dtypes: datetime64[ns, CET](1), float64(1)\n",
      "memory usage: 1.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# = = = = = = = = = = = = = \n",
    "# get data\n",
    "# df_energy = data_prepro.get_energy_data_today(to_date=t_wednesday.strftime('%Y%m%d'))\n",
    "\n",
    "# Read data from file with specified data types\n",
    "df_energy = pd.read_csv(\"data/2015-01-01_2024-02-21_energy.csv\", index_col=0, parse_dates=[0])\n",
    "df_energy['timestamp_CET'] = pd.to_datetime(df_energy['timestamp_CET'], utc=True).dt.tz_convert('CET')\n",
    "print(df_energy.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Forecasting for week starting from 2024-02-14 ...\n",
      "Submission timestamps = 2024-02-16 12:00:00+01:00 to 2024-02-17 20:00:00+01:00\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "method = bench_pm_2weeks\n",
      "method = same_month\n",
      "method = bench_pm_1month\n",
      "method = mstl_1\n",
      "method = mstl_0.5\n",
      "- - - - - - - - - - - - - - - \n",
      "take smaller dataset ... from 2023-01-01 to 2024-02-15 00:00:00+01:00\n",
      "method = quant_reg\n",
      "- - - - - - - - - - - - - - - \n",
      "> start training quantile regression models ...\n",
      ">> alpha = 0.025 ...\n",
      ">> alpha = 0.250 ...\n",
      ">> alpha = 0.500 ...\n",
      ">> alpha = 0.750 ...\n",
      ">> alpha = 0.975 ...\n",
      "- - - - - - - - - - - - - - - \n",
      "> time taken: 67.96 seconds\n",
      "- - - - - - - - - - - - - - - \n",
      "method = grad_boost_ftrs\n",
      "- - - - - - - - - - - - - - - \n",
      "> start training gradient boosting models ...\n",
      ">> alpha = 0.025 ...\n",
      ">> alpha = 0.250 ...\n",
      ">> alpha = 0.500 ...\n",
      ">> alpha = 0.750 ...\n",
      ">> alpha = 0.975 ...\n",
      "- - - - - - - - - - - - - - - \n",
      "> time taken: 49.70 seconds\n",
      "- - - - - - - - - - - - - - - \n",
      "method = grad_boost_dummy\n",
      "- - - - - - - - - - - - - - - \n",
      "> start training gradient boosting models ...\n",
      ">> alpha = 0.025 ...\n",
      ">> alpha = 0.250 ...\n",
      ">> alpha = 0.500 ...\n",
      ">> alpha = 0.750 ...\n",
      ">> alpha = 0.975 ...\n",
      "- - - - - - - - - - - - - - - \n",
      "> time taken: 44.45 seconds\n",
      "- - - - - - - - - - - - - - - \n",
      "- - - - - - - - - - - - - - - \n",
      "scores:\n",
      "bench_pm_2weeks     1.762079\n",
      "same_month          1.903404\n",
      "bench_pm_1month     1.419873\n",
      "mstl_1              0.707875\n",
      "mstl_0.5            0.703590\n",
      "quant_reg           0.843860\n",
      "grad_boost_ftrs     0.903431\n",
      "grad_boost_dummy    0.878247\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Define the start and end dates\n",
    "start_date = pd.Timestamp('2023-11-15')\n",
    "end_date = pd.Timestamp('2024-02-14')\n",
    "\n",
    "# Generate a list of weekly dates in UTC\n",
    "fcast_dates_cet = pd.date_range(start=start_date, end=end_date, freq='W-WED').tz_localize('CET').strftime('%Y-%m-%d').tolist()\n",
    "dict_all_fcasts = {}\n",
    "\n",
    "# Iterate over the forecast dates\n",
    "for fcast_date in fcast_dates_cet[-1:]:\n",
    "\n",
    "    print('= '*30)\n",
    "    print(f\"Forecasting for week starting from {fcast_date} ...\")\n",
    "    dict_weekly_fcasts = {}\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # generate prediction timestamps based on t0 = following thursday 00:00\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    # Calculate the Thursday and Wednesday of the week\n",
    "    t_wednesday = pd.Timestamp(fcast_date).replace(hour=0, minute=0, second=0, microsecond=0).tz_localize('CET')\n",
    "    t_thursday = t_wednesday + pd.Timedelta(days=1)\n",
    "\n",
    "    # Generate required submission timestamps\n",
    "    subm_timestamps = [(t_thursday + pd.Timedelta(hours=fcast)) for fcast in fcast_hor]\n",
    "    print(f\"Submission timestamps = {subm_timestamps[0]} to {subm_timestamps[-1]}\")\n",
    "\n",
    "    # parse t_thursday to string\n",
    "    t_thursday_str = t_thursday.strftime('%Y-%m-%d')\n",
    "    df_energy_current = df_energy.loc[df_energy['timestamp_CET'] <= t_thursday_str].copy()\n",
    "    # print(df_energy_current.info())\n",
    "    print('= '*30)\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # use pretrained models\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    # ... TBD\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # train necessary models\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    # Create a folder for the week\n",
    "    week_folder_name = f\"models/{t_wednesday.strftime('%Y%m%d')}\"\n",
    "    os.makedirs(week_folder_name, exist_ok=True)\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # Simple Benchmark\n",
    "    # = = = = = = = = = = = = = \n",
    "    \n",
    "    # create fcast index for next 68 hours\n",
    "    fcast_timestamp_CET = pd.date_range(start=t_thursday, periods=68+1, freq='H')\n",
    "    fcast_timestamp_UTC = fcast_timestamp_CET.tz_convert('UTC')\n",
    "    \n",
    "    # create new dataframe with relevant info for benchmark\n",
    "    df_energy_benchmark = df_energy_current.copy()\n",
    "    df_energy_benchmark[\"month\"] = df_energy_benchmark['timestamp_CET'].dt.month\n",
    "    df_energy_benchmark[\"weekday\"] = df_energy_benchmark['timestamp_CET'].dt.weekday # Monday=0, Sunday=6\n",
    "    df_energy_benchmark[\"weeknum\"] = df_energy_benchmark['timestamp_CET'].dt.isocalendar().week\n",
    "\n",
    "    last_t = 150 # if there are more matches only take the most recent\n",
    "    pred_baseline = np.zeros((3,len(fcast_timestamp_CET),5)) # 3 condition types, 5 quantiles\n",
    "\n",
    "    for i,d in enumerate(fcast_timestamp_CET):\n",
    "            \n",
    "        weekday = d.weekday()\n",
    "        hour = d.hour\n",
    "        weeknum = d.week\n",
    "        \n",
    "        # basic condition that the weekday and hour match\n",
    "        basic_cond = (df_energy_benchmark.weekday == weekday) & (df_energy_benchmark.index.time == d.time())\n",
    "        \n",
    "        # AND the weeknum is within +/- 2 weeks of the target\n",
    "        cond1 = (df_energy_benchmark['weeknum'].between(weeknum-2, weeknum+2)) \n",
    "        # AND the month also matches\n",
    "        cond2 = (df_energy_benchmark.index.month == d.month)\n",
    "        # AND the month is within +/- 1 months of the target\n",
    "        cond3 = (df_energy_benchmark['month'].between(d.month-1, d.month+1))\n",
    "\n",
    "        cond_list = [cond1, cond2, cond3]\n",
    "\n",
    "        for cond_idx, cond in enumerate(cond_list):\n",
    "            cond = basic_cond & cond\n",
    "            match_df = df_energy_benchmark[cond]\n",
    "            # print(f\"condition {cond_idx} ... {len(match_df)} matches found\")\n",
    "            pred_baseline[cond_idx, i, :] = np.quantile(match_df.iloc[-last_t:][\"gesamt\"], q=quantiles) # method='linear'\n",
    "\n",
    "    methods = ['bench_pm_2weeks', 'same_month', 'bench_pm_1month']\n",
    "    for m_idx, method in enumerate(methods):\n",
    "\n",
    "        print(f\"method = {method}\")\n",
    "        # create empty df\n",
    "        df_benchmark = pd.DataFrame(index=fcast_timestamp_UTC, columns=[f\"q {q:.3f}\" for q in quantiles])\n",
    "        df_benchmark.loc[:,:] = pred_baseline[m_idx,:,:]\n",
    "\n",
    "        # make sure all cols are float\n",
    "        df_benchmark = df_benchmark.astype(float)\n",
    "        # add CET col\n",
    "        df_benchmark['timestamp_CET'] = df_benchmark.index.tz_convert('CET')\n",
    "        # reorder cols\n",
    "        df_benchmark = df_benchmark[['timestamp_CET', 'q 0.025', 'q 0.250', 'q 0.500', 'q 0.750', 'q 0.975']]\n",
    "        # save to dict\n",
    "        dict_weekly_fcasts[method] = df_benchmark\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # MSTL\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    mstl_train_horizon = 0.5 # in years\n",
    "\n",
    "    for mstl_train_horizon in [1, 0.5]:\n",
    "        \n",
    "        method = f\"mstl_{mstl_train_horizon}\"\n",
    "        print(f\"method = {method}\")\n",
    "\n",
    "        df_mstl_train = df_energy_current.iloc[-int(mstl_train_horizon * 365 * 24):].copy()\n",
    "        mstl_model = MSTL(season_length=[24, 24 * 7]).fit(df_mstl_train[\"gesamt\"])\n",
    "\n",
    "        n_steps = df_benchmark.shape[0]\n",
    "\n",
    "        y_hat_dict = mstl_model.predict(h=n_steps, level=[50, 95])\n",
    "        y_hat_df = pd.DataFrame(y_hat_dict)\n",
    "        y_hat_df[\"timestamp_CET\"] = pd.date_range(start=t_thursday, periods=len(y_hat_df), freq=\"H\")\n",
    "\n",
    "        # rename columns\n",
    "        y_hat_df = y_hat_df.rename(\n",
    "            columns={\n",
    "                \"mean\": \"q 0.500\",\n",
    "                \"lo-50\": \"q 0.250\",\n",
    "                \"hi-50\": \"q 0.750\",\n",
    "                \"lo-95\": \"q 0.025\",\n",
    "                \"hi-95\": \"q 0.975\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # rearrange cols\n",
    "        y_hat_df = y_hat_df[[\"timestamp_CET\", \"q 0.025\", \"q 0.250\", \"q 0.500\", \"q 0.750\", \"q 0.975\"]]\n",
    "\n",
    "        df_mstl_fcast = y_hat_df\n",
    "        df_mstl_fcast.index = fcast_timestamp_UTC\n",
    "\n",
    "        dict_weekly_fcasts[method] = df_mstl_fcast\n",
    "\n",
    "    # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "    # take smaller dataset for feature engineering\n",
    "    # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "    start   = '2023-01-01'\n",
    "    df_energy_small = df_energy_current.loc[(df_energy_current['timestamp_CET'] >= start)].copy()\n",
    "    print('- '*15)\n",
    "    print(f\"take smaller dataset ... from {start} to {df_energy_small['timestamp_CET'].max()}\")\n",
    "\n",
    "    df_energy_dummy = data_prepro.create_dummy_df(df_energy_small, hour_method='seasonal', holiday_method='separate')\n",
    "    df_energy_fturs = data_prepro.create_features_df(df_energy_small, holiday_method='separate')\n",
    "\n",
    "    X_train_fturs = df_energy_fturs.drop(['gesamt', 'timestamp_CET'], axis=1)\n",
    "    y_train_fturs = df_energy_fturs['gesamt']\n",
    "\n",
    "    X_train_dummy = df_energy_dummy.drop(['gesamt', 'timestamp_CET'], axis=1)\n",
    "    y_train_dummy = df_energy_dummy['gesamt']\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # Quantile Reg\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    method = 'quant_reg'\n",
    "    print(f\"method = {method}\")\n",
    "\n",
    "    # train quantile regression with dummies\n",
    "    all_models_quant_reg = model_train.fit_quant_reg(X_train_dummy, y_train_dummy, quantiles=quantiles)\n",
    "\n",
    "    # create fcast index for next 68 hours\n",
    "    fcast_timestamp_CET = pd.date_range(start=t_thursday, periods=68+1, freq='H')\n",
    "    fcast_timestamp_UTC = fcast_timestamp_CET.tz_convert('UTC')\n",
    "\n",
    "    # create df with fcast timestamps as INPUT for model\n",
    "    df_temp = pd.DataFrame(index=fcast_timestamp_UTC)\n",
    "    df_temp['timestamp_CET'] = fcast_timestamp_CET\n",
    "    df_fcast_dummy = data_prepro.create_dummy_df(df_temp, hour_method='seasonal', holiday_method='separate')\n",
    "\n",
    "    # create empty OUTPUT df with columns = quantiles\n",
    "    df_quant_reg_direct_fcast = pd.DataFrame(index=df_fcast_dummy.index)\n",
    "    df_quant_reg_direct_fcast['timestamp_CET'] = fcast_timestamp_CET\n",
    "\n",
    "    # Prediction for Quantile Regression\n",
    "    for name, model in sorted(all_models_quant_reg.items()):\n",
    "        pred = model.predict(df_fcast_dummy.drop('timestamp_CET', axis=1))\n",
    "        df_quant_reg_direct_fcast[name] = pred\n",
    "\n",
    "    dict_weekly_fcasts[method] = df_quant_reg_direct_fcast\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # Grad Boosting\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    methods = ['grad_boost_ftrs', 'grad_boost_dummy']\n",
    "\n",
    "    for method in methods:\n",
    "\n",
    "        print(f\"method = {method}\")\n",
    "\n",
    "        # create fcast index for next 68 hours\n",
    "        fcast_timestamp_CET = pd.date_range(start=t_thursday, periods=68+1, freq='H')\n",
    "        fcast_timestamp_UTC = fcast_timestamp_CET.tz_convert('UTC')\n",
    "\n",
    "        if method == 'grad_boost_ftrs':\n",
    "            # train gradient boosting with features\n",
    "            all_models_grad_boost = model_train.fit_grad_boost(X_train_fturs, y_train_fturs, quantiles=quantiles)\n",
    "\n",
    "            # create df with fcast timestamps as INPUT for model\n",
    "            df_temp = pd.DataFrame(index=fcast_timestamp_UTC)\n",
    "            df_temp['timestamp_CET'] = fcast_timestamp_CET\n",
    "            df_fcast_dummy = data_prepro.create_features_df(df_temp, holiday_method='separate')\n",
    "            \n",
    "        elif method == 'grad_boost_dummy':\n",
    "            # train gradient boosting with dummies\n",
    "            all_models_grad_boost = model_train.fit_grad_boost(X_train_dummy, y_train_dummy, quantiles=quantiles)\n",
    "\n",
    "            # create df with fcast timestamps as INPUT for model\n",
    "            df_temp = pd.DataFrame(index=fcast_timestamp_UTC)\n",
    "            df_temp['timestamp_CET'] = fcast_timestamp_CET\n",
    "            df_fcast_dummy = data_prepro.create_dummy_df(df_temp, hour_method='seasonal', holiday_method='separate')\n",
    "\n",
    "        # create empty OUTPUT df with columns = quantiles\n",
    "        df_grad_boost_direct_fcast = pd.DataFrame(index=df_fcast_dummy.index)\n",
    "        df_grad_boost_direct_fcast['timestamp_CET'] = fcast_timestamp_CET\n",
    "\n",
    "        # Prediction for Quantile Regression\n",
    "        for name, model in sorted(all_models_grad_boost.items()):\n",
    "            pred = model.predict(df_fcast_dummy.drop('timestamp_CET', axis=1))\n",
    "            df_grad_boost_direct_fcast[name] = pred\n",
    "\n",
    "        dict_weekly_fcasts[method] = df_grad_boost_direct_fcast\n",
    "    \n",
    "    # = = = = = = = = = = = = = \n",
    "    # Save all fcasts & trained models for the week\n",
    "    # = = = = = = = = = = = = = \n",
    "        \n",
    "    dict_all_fcasts[fcast_date] = dict_weekly_fcasts\n",
    "\n",
    "    # = = = = = = = = = = = = = \n",
    "    # Evaluation based on submission timestamps\n",
    "    # = = = = = = = = = = = = = \n",
    "\n",
    "    # get actual values at every submission timestamp\n",
    "    df_energy_eval = df_energy.loc[df_energy['timestamp_CET'].isin(subm_timestamps)].copy()\n",
    "    # display(df_energy_eval)\n",
    "\n",
    "    # Initialize an empty dictionary to store evaluation results\n",
    "    evaluation_results = {}\n",
    "\n",
    "    # Iterate over each model's forecast for the week\n",
    "    for model_name, forecast_df in dict_weekly_fcasts.items():\n",
    "\n",
    "        # Initialize an empty DataFrame to store quantile scores\n",
    "        quantile_scores = pd.DataFrame(index=subm_timestamps, columns=[f\"q {q:.3f}\" for q in quantiles])\n",
    "        # take subset of fcast df at submission timestamps\n",
    "        forecast_df = forecast_df.loc[forecast_df['timestamp_CET'].isin(subm_timestamps)].copy()\n",
    "\n",
    "        # Iterate over each submission timestamp\n",
    "        for q_idx, q in enumerate(quantiles):\n",
    "\n",
    "            qscore = mean_pinball_loss(alpha=q, \n",
    "                                       y_true=df_energy_eval['gesamt'].values, \n",
    "                                       y_pred=forecast_df.iloc[:,q_idx+1].values) # skip timestamp_CET col\n",
    "            \n",
    "            quantile_scores.iloc[:,q_idx] = qscore / 1000\n",
    "        \n",
    "        # Store the quantile scores for the model\n",
    "        evaluation_results[model_name] = quantile_scores\n",
    "\n",
    "    # Calculate mean scores for each quantile over time\n",
    "    mean_scores = {}\n",
    "    for model_name, quantile_scores in evaluation_results.items():\n",
    "        mean_scores[model_name] = quantile_scores.mean()\n",
    "\n",
    "    # calculate mean scores over all quantiles\n",
    "    mean_scores_df = pd.DataFrame(mean_scores)\n",
    "    print('- '*15)\n",
    "    print('scores:')\n",
    "    print(mean_scores_df.mean(axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
