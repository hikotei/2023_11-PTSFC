plot(DAX_returns$ret1, type='l')
plot(DAX_returns$price, type='l')
plot(DAX_returns$date, DAX_returns$price, type='l')
plot(DAX_returns$date, DAX_returns$ret1, type='l')
plot(DAX_returns$date, DAX_returns$price, type='l')
plot(DAX_returns$date, DAX_returns$ret1, type='l')
plot(DAX_returns$date, DAX_returns$ret2, type='l')
plot(DAX_returns$date, DAX_returns$ret1, type='l')
# Function to get rugarch model with specified parameters
get_rugarch_model <- function(p, q, arch_p, arch_q, dist) {
variance_model <- list(model = "sGARCH", garchOrder = c(arch_p, arch_q))
mean_model <- list(armaOrder = c(p, q), include.mean = TRUE)
if (dist == 'std') {
fix_df <- 3
params <- list(shape = fix_df)
model <- ugarchspec(variance.model = variance_model, mean.model = mean_model,
distribution.model = dist, fixed.pars = params)
} else if (dist == 'norm') {
model <- ugarchspec(variance.model = variance_model, mean.model = mean_model,
distribution.model = dist)
}
return(model)
}
hist <- DAX_prices %>%
mutate(ret1_sqrd = compute_return(price, h = 1)^2,
ret1_sqrd_lag1 = lag(ret1_sqrd, 1),
ret1 = compute_return(price, h = 1),
ret1_abs_lag1 = abs(lag(ret1, 1)),
ret2 = compute_return(price, h = 2),
ret2_abs_lag1 = abs(lag(ret2, 1)),
ret3 = compute_return(price, h = 3),
ret4 = compute_return(price, h = 4),
ret5 = compute_return(price, h = 5))
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# Load necessary packages
library(rugarch)
library(tseries)
library(zoo)
library(dplyr)
source("dax_procs.R")
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# get dax data ####
start_date  <- "2015-01-01"
# fcast_date  <- "2022-10-10"
fcast_date  <- Sys.Date()
DAX_prices = get.hist.quote(instrument="^GDAXI",
start=start_date, end=fcast_date,
quote="Adjusted",
provider="yahoo",
compression="d",
retclass="zoo")
# convert zoo to dataframe
DAX_prices <- fortify.zoo(DAX_prices)
names(DAX_prices) <- c("date", "price")
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# data processing ####
# compute cumulative log returns
DAX_returns <- DAX_prices %>%
mutate(ret1_sqrd = compute_return(price, h = 1)^2,
ret1_sqrd_lag1 = lag(ret1_sqrd, 1),
ret1 = compute_return(price, h = 1),
ret1_abs_lag1 = abs(lag(ret1, 1)),
ret2 = compute_return(price, h = 2),
ret2_abs_lag1 = abs(lag(ret2, 1)),
ret3 = compute_return(price, h = 3),
ret4 = compute_return(price, h = 4),
ret5 = compute_return(price, h = 5))
plot(DAX_returns$date, DAX_returns$price, type='l')
plot(DAX_returns$date, DAX_returns$ret1, type='l')
# Function to get rugarch model with specified parameters
get_rugarch_model <- function(p, q, arch_p, arch_q, dist) {
variance_model <- list(model = "sGARCH", garchOrder = c(arch_p, arch_q))
mean_model <- list(armaOrder = c(p, q), include.mean = TRUE)
if (dist == 'std') {
fix_df <- 3
params <- list(shape = fix_df)
model <- ugarchspec(variance.model = variance_model, mean.model = mean_model,
distribution.model = dist, fixed.pars = params)
} else if (dist == 'norm') {
model <- ugarchspec(variance.model = variance_model, mean.model = mean_model,
distribution.model = dist)
}
return(model)
}
# Function to perform GARCH forecasting
r_garch_forecast <- function(y, p, q, arch_p, arch_q, dist = 'std') {
model <- get_rugarch_model(p, q, arch_p, arch_q, dist)
modelfit <- ugarchfit(spec = model, data = y, solver.control = list(tol = 1e-3))
fore <- ugarchforecast(modelfit)
mu_hist <- fitted(modelfit)[, 1]
sigma_hist <- sigma(modelfit)[, 1]
mu <- fitted(fore)[, 1]
sigma <- sigma(fore)[, 1]
return(list(mu_hist = mu_hist, sigma_hist = sigma_hist, mu = mu, sigma = sigma))
}
# Parameters
p <- 5
q <- 3
arch_p <- 2
arch_q <- 3
ignore_first <- 2000
# Example usage
lr1_res <- r_garch_forecast(DAX_returns$ret1[(ignore_first + 1):length(DAX_returns$ret1)], p, q, arch_p, arch_q)
lr2_res <- r_garch_forecast(DAX_returns$ret2[(ignore_first + 1):length(DAX_returns$ret2)], p, q, arch_p, arch_q)
lr3_res <- r_garch_forecast(DAX_returns$ret3[(ignore_first + 1):length(DAX_returns$ret3)], p, q, arch_p, arch_q)
lr4_res <- r_garch_forecast(DAX_returns$ret4[(ignore_first + 1):length(DAX_returns$ret4)], p, q, arch_p, arch_q)
lr5_res <- r_garch_forecast(DAX_returns$ret5[(ignore_first + 1):length(DAX_returns$ret5)], p, q, arch_p, arch_q)
# Extract mean and sigma values
mean_vals <- c(lr1_res$mu, lr2_res$mu, lr3_res$mu, lr4_res$mu, lr5_res$mu)
sigma_vals <- c(lr1_res$sigma, lr2_res$sigma, lr3_res$sigma, lr4_res$sigma, lr5_res$sigma)
# Function to get quantiles from distribution
get_q_from_dist <- function(mean, std, q = c(0.025, 0.25, 0.5, 0.75, 0.975)) {
quantiles <- numeric(length(q))
eps <- 1e-5
for (i in seq_along(mean)) {
quants <- qt(q, df = 3, location = mean[i], scale = std[i] + eps)
quantiles <- cbind(quantiles, quants)
}
return(quantiles[, -1])
}
# Get quantiles
quantiles_val <- get_q_from_dist(mean_vals, sigma_vals)
mean_vals
sigma_vals
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# Load necessary packages
library(rugarch)
library(tseries)
library(zoo)
library(dplyr)
source("dax_procs.R")
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# get dax data ####
start_date  <- "2015-01-01"
# fcast_date  <- "2022-10-10"
fcast_date  <- Sys.Date()
DAX_prices = get.hist.quote(instrument="^GDAXI",
start=start_date, end=fcast_date,
quote="Adjusted",
provider="yahoo",
compression="d",
retclass="zoo")
# convert zoo to dataframe
DAX_prices <- fortify.zoo(DAX_prices)
names(DAX_prices) <- c("date", "price")
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# data processing ####
# compute cumulative log returns
DAX_returns <- DAX_prices %>%
mutate(ret1_sqrd = compute_return(price, h = 1)^2,
ret1_sqrd_lag1 = lag(ret1_sqrd, 1),
ret1 = compute_return(price, h = 1),
ret1_abs_lag1 = abs(lag(ret1, 1)),
ret2 = compute_return(price, h = 2),
ret2_abs_lag1 = abs(lag(ret2, 1)),
ret3 = compute_return(price, h = 3),
ret4 = compute_return(price, h = 4),
ret5 = compute_return(price, h = 5))
plot(DAX_returns$date, DAX_returns$price, type='l')
plot(DAX_returns$date, DAX_returns$ret1, type='l')
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# rugarch ####
# Function to get rugarch model with specified parameters
get_rugarch_model <- function(p, q, arch_p, arch_q, dist) {
variance_model <- list(model = "sGARCH", garchOrder = c(arch_p, arch_q))
mean_model <- list(armaOrder = c(p, q), include.mean = TRUE)
if (dist == 'std') {
fix_df <- 3
params <- list(shape = fix_df)
model <- ugarchspec(variance.model = variance_model, mean.model = mean_model,
distribution.model = dist, fixed.pars = params)
} else if (dist == 'norm') {
model <- ugarchspec(variance.model = variance_model, mean.model = mean_model,
distribution.model = dist)
}
return(model)
}
# Function to perform GARCH forecasting
r_garch_forecast <- function(y, p, q, arch_p, arch_q, dist = 'std') {
model <- get_rugarch_model(p, q, arch_p, arch_q, dist)
modelfit <- ugarchfit(spec = model, data = y, solver.control = list(tol = 1e-3))
fore <- ugarchforecast(modelfit)
mu_hist <- fitted(modelfit)[, 1]
sigma_hist <- sigma(modelfit)[, 1]
mu <- fitted(fore)[, 1]
sigma <- sigma(fore)[, 1]
return(list(mu_hist = mu_hist, sigma_hist = sigma_hist, mu = mu, sigma = sigma))
}
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# model fit & fcast ####
# Parameters
p <- 5
q <- 3
arch_p <- 2
arch_q <- 3
ignore_first <- 1000
# Example usage
lr1_res <- r_garch_forecast(DAX_returns$ret1[(ignore_first + 1):length(DAX_returns$ret1)], p, q, arch_p, arch_q)
lr2_res <- r_garch_forecast(DAX_returns$ret2[(ignore_first + 1):length(DAX_returns$ret2)], p, q, arch_p, arch_q)
lr3_res <- r_garch_forecast(DAX_returns$ret3[(ignore_first + 1):length(DAX_returns$ret3)], p, q, arch_p, arch_q)
lr4_res <- r_garch_forecast(DAX_returns$ret4[(ignore_first + 1):length(DAX_returns$ret4)], p, q, arch_p, arch_q)
lr5_res <- r_garch_forecast(DAX_returns$ret5[(ignore_first + 1):length(DAX_returns$ret5)], p, q, arch_p, arch_q)
# Extract mean and sigma values
mean_vals <- c(lr1_res$mu, lr2_res$mu, lr3_res$mu, lr4_res$mu, lr5_res$mu)
sigma_vals <- c(lr1_res$sigma, lr2_res$sigma, lr3_res$sigma, lr4_res$sigma, lr5_res$sigma)
# Function to get quantiles from distribution
get_q_from_dist <- function(mean, std, q = c(0.025, 0.25, 0.5, 0.75, 0.975)) {
quantiles <- numeric(length(q))
eps <- 1e-5
for (i in seq_along(mean)) {
quants <- qt(q, df = 3, location = mean[i], scale = std[i] + eps)
quantiles <- cbind(quantiles, quants)
}
return(quantiles[, -1])
}
# Get quantiles
quantiles_val <- get_q_from_dist(mean_vals, sigma_vals)
lr1_res
?r_garch_forecast
?ugarchforecast
View(DAX_returns)
?qt
quants <- qt(q, df = 3) * (std[i] + eps) + mean[i]
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# Load necessary packages
library(rugarch)
library(tseries)
library(zoo)
library(dplyr)
source("dax_procs.R")
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# get dax data ####
start_date  <- "2015-01-01"
# fcast_date  <- "2022-10-10"
fcast_date  <- Sys.Date()
DAX_prices = get.hist.quote(instrument="^GDAXI",
start=start_date, end=fcast_date,
quote="Adjusted",
provider="yahoo",
compression="d",
retclass="zoo")
# convert zoo to dataframe
DAX_prices <- fortify.zoo(DAX_prices)
names(DAX_prices) <- c("date", "price")
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# data processing ####
# compute cumulative log returns
DAX_returns <- DAX_prices %>%
mutate(ret1_sqrd = compute_return(price, h = 1)^2,
ret1_sqrd_lag1 = lag(ret1_sqrd, 1),
ret1 = compute_return(price, h = 1),
ret1_abs_lag1 = abs(lag(ret1, 1)),
ret2 = compute_return(price, h = 2),
ret2_abs_lag1 = abs(lag(ret2, 1)),
ret3 = compute_return(price, h = 3),
ret4 = compute_return(price, h = 4),
ret5 = compute_return(price, h = 5))
plot(DAX_returns$date, DAX_returns$price, type='l')
plot(DAX_returns$date, DAX_returns$ret1, type='l')
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# rugarch ####
# Function to get rugarch model with specified parameters
get_rugarch_model <- function(p, q, arch_p, arch_q, dist) {
variance_model <- list(model = "sGARCH", garchOrder = c(arch_p, arch_q))
mean_model <- list(armaOrder = c(p, q), include.mean = TRUE)
if (dist == 'std') {
fix_df <- 3
params <- list(shape = fix_df)
model <- ugarchspec(variance.model = variance_model, mean.model = mean_model,
distribution.model = dist, fixed.pars = params)
} else if (dist == 'norm') {
model <- ugarchspec(variance.model = variance_model, mean.model = mean_model,
distribution.model = dist)
}
return(model)
}
# Function to perform GARCH forecasting
r_garch_forecast <- function(y, p, q, arch_p, arch_q, dist = 'std') {
model <- get_rugarch_model(p, q, arch_p, arch_q, dist)
modelfit <- ugarchfit(spec = model, data = y, solver.control = list(tol = 1e-3))
fore <- ugarchforecast(modelfit)
mu_hist <- fitted(modelfit)[, 1]
sigma_hist <- sigma(modelfit)[, 1]
mu <- fitted(fore)[, 1]
sigma <- sigma(fore)[, 1]
return(list(mu_hist = mu_hist, sigma_hist = sigma_hist, mu = mu, sigma = sigma))
}
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# model fit & fcast ####
# Parameters
p <- 5
q <- 3
arch_p <- 2
arch_q <- 3
ignore_first <- 1000
# Example usage
lr1_res <- r_garch_forecast(DAX_returns$ret1[(ignore_first + 1):length(DAX_returns$ret1)], p, q, arch_p, arch_q)
lr2_res <- r_garch_forecast(DAX_returns$ret2[(ignore_first + 1):length(DAX_returns$ret2)], p, q, arch_p, arch_q)
lr3_res <- r_garch_forecast(DAX_returns$ret3[(ignore_first + 1):length(DAX_returns$ret3)], p, q, arch_p, arch_q)
lr4_res <- r_garch_forecast(DAX_returns$ret4[(ignore_first + 1):length(DAX_returns$ret4)], p, q, arch_p, arch_q)
lr5_res <- r_garch_forecast(DAX_returns$ret5[(ignore_first + 1):length(DAX_returns$ret5)], p, q, arch_p, arch_q)
# Extract mean and sigma values
mean_vals <- c(lr1_res$mu, lr2_res$mu, lr3_res$mu, lr4_res$mu, lr5_res$mu)
sigma_vals <- c(lr1_res$sigma, lr2_res$sigma, lr3_res$sigma, lr4_res$sigma, lr5_res$sigma)
# Function to get quantiles from distribution
get_q_from_dist <- function(mean, std, q = c(0.025, 0.25, 0.5, 0.75, 0.975)) {
quantiles <- numeric(length(q))
eps <- 1e-5
for (i in seq_along(mean)) {
quants <- qt(q, df = 3) * (std[i] + eps) + mean[i]
quantiles <- cbind(quantiles, quants)
}
return(quantiles[, -1])
}
# Get quantiles
quantiles_val <- get_q_from_dist(mean_vals, sigma_vals)
quantiles_val
View(quantiles_val)
#' v3 Note
#' Try ARMA GARCH models
rm(list = ls())
library(dplyr)
library(lubridate)
library(tseries)
library(zoo)
library(quantreg)
set.seed(1103)
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# system directory ####
if (Sys.info()[[1]] == 'Windows') {
comp <- 'surface'
homedir <- "C:/2023_11-PTSFC"
} else {
comp <- 'mac'
homedir <- "/Users/yanting/OneDrive/Desktop/23_24 WS (Master)/VL - PTSFC"
}
setwd(homedir)
chdir('./dax')
tau_arr <- c(.025, .25, .5, .75, .975) # quantile levels
#' v3 Note
#' Try ARMA GARCH models
rm(list = ls())
library(dplyr)
library(lubridate)
library(tseries)
library(zoo)
library(quantreg)
set.seed(1103)
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# system directory ####
if (Sys.info()[[1]] == 'Windows') {
comp <- 'surface'
homedir <- "C:/2023_11-PTSFC"
} else {
comp <- 'mac'
homedir <- "/Users/yanting/OneDrive/Desktop/23_24 WS (Master)/VL - PTSFC"
}
setwd(homedir)
setwd('./dax')
source("dax_procs.R")
setwd('../')
tau_arr <- c(.025, .25, .5, .75, .975) # quantile levels
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# get dax data ####
start_date  <- "2020-01-01"
# fcast_date  <- "2024-01-03"
fcast_date  <- Sys.Date()
DAX_prices = get.hist.quote(instrument="^GDAXI",
start=start_date, end=fcast_date,
quote="Adjusted",
provider="yahoo",
compression="d",
retclass="zoo")
DAX_prices <- fortify.zoo(DAX_prices)
names(DAX_prices) <- c("date", "price")
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# data processing ####
# compute cumulative log returns
DAX_returns <- DAX_prices %>%
mutate(ret1_sqrd = compute_return(price, h = 1)^2,
ret1_sqrd_lag1 = lag(ret1_sqrd, 1),
ret1 = compute_return(price, h = 1),
ret1_abs_lag1 = abs(lag(ret1, 1)),
ret2 = compute_return(price, h = 2),
ret2_abs_lag1 = abs(lag(ret2, 1)),
ret3 = compute_return(price, h = 3),
ret4 = compute_return(price, h = 4),
ret5 = compute_return(price, h = 5))
plot(DAX_returns$price, type='l')
plot(DAX_returns$ret1, type='l')
# - - - - - - - - - - - - - - - - - - - - - - - - - -
# Remove outliers ???
# DAX_returns <- DAX_returns %>%
#     filter(abs(ret1_sqrd_lag1) <= 10)
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# train test split ####
n_total <- nrow(DAX_returns)
n_train <- n_total
# Create the training and test sets
DAX_returns_train <- DAX_returns[1:n_train, ]
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# quant reg models ####
# example quantile regression
# y = cumulative log returns h=1
# x = ret sqrd of yesterday
# all quantile regression models for h = {1,2,3,4,5}
# y = cumulative log returns h=i
# x = ret sqrd of yesterday
rqfit_ret1 <- rq(ret1 ~ ret1_sqrd_lag1 + ret1_abs_lag1 + ret2_abs_lag1,
tau = tau_arr, data = DAX_returns_train)
rqfit_ret2 <- rq(ret2 ~ ret1_sqrd_lag1 + ret1_abs_lag1 + ret2_abs_lag1,
tau = tau_arr, data = DAX_returns_train)
rqfit_ret3 <- rq(ret3 ~ ret1_sqrd_lag1 + ret1_abs_lag1 + ret2_abs_lag1,
tau = tau_arr, data = DAX_returns_train)
rqfit_ret4 <- rq(ret4 ~ ret1_sqrd_lag1 + ret1_abs_lag1 + ret2_abs_lag1,
tau = tau_arr, data = DAX_returns_train)
rqfit_ret5 <- rq(ret5 ~ ret1_sqrd_lag1 + ret1_abs_lag1 + ret2_abs_lag1,
tau = tau_arr, data = DAX_returns_train)
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# QR predictions on test set
DAX_returns_train <- DAX_returns_train %>%
mutate(
pred_ret1 = predict(rqfit_ret1, newdata = ., interval = "confidence"),
pred_ret2 = predict(rqfit_ret2, newdata = ., interval = "confidence"),
pred_ret3 = predict(rqfit_ret3, newdata = ., interval = "confidence"),
pred_ret4 = predict(rqfit_ret4, newdata = ., interval = "confidence"),
pred_ret5 = predict(rqfit_ret5, newdata = ., interval = "confidence")
)
pred_ret <- t(rbind(DAX_returns_train$pred_ret1[n_total-4,],
DAX_returns_train$pred_ret2[n_total-3,],
DAX_returns_train$pred_ret3[n_total-2,],
DAX_returns_train$pred_ret4[n_total-1,],
DAX_returns_train$pred_ret5[n_total,]))
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# fit ARMA GARCH ####
library(rugarch)
spec_garch  <- ugarchspec(variance.model = list(model="sGARCH", garchOrder=c(3,1)),
mean.model = list(armaOrder = c(6, 6)))
garch_model <- ugarchfit(spec_garch, DAX_returns_train[2:n_train,5])
garch_fcast <- ugarchforecast(garch_model, n.ahead=5)
plot(garch_fcast, which=1)
plot(garch_fcast, which=3)
# - - - - - - - - - - - - - - - - - - - - - - - - - -
# calc cumulative log returns
garch_fcast_cumulative <- numeric(5)
prev_ret <- 0
for (idx in 1:5) {
ret <- fitted(garch_fcast)[idx] + prev_ret
garch_fcast_cumulative[idx] <- ret
prev_ret <- prev_ret + fitted(garch_fcast)[idx]
}
# - - - - - - - - - - - - - - - - - - - - - - - - - -
# generate prediction quantiles assuming normal distribution using GARCH sigma's
# initialize matrix (rows are quantile levels, cols are horizons)
pred_garch <- matrix(NA, nrow = length(tau_arr), ncol = 5)
# loop over 5 fcast horizons
for (jj in 1:5){
for (tau_idx in seq_along(tau_arr)) {
sd <- qnorm(tau_arr[tau_idx]) * sigma(garch_fcast)[jj]
pred <- garch_fcast_cumulative[jj] + sd
pred_garch[tau_idx,jj] <- pred
}
}
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# baseline model ####
# compute baseline predictions (rolling window)
# initialize matrix (rows are quantile levels, cols are horizons)
pred_baseline <- matrix(NA, nrow = length(tau_arr), ncol = 5)
n_past_values <- 100
# loop over 5 fcast horizons
for (jj in 1:5){
tmp <- DAX_returns_train[, paste0("ret", jj)] %>%
na.omit %>% # removes any rows
tail(n_past_values) # selects only #n values in tail
# return quantiles at the specified probabilities given
pred_baseline[,jj] <- quantile(tmp, probs = tau_arr)
}
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# plot against baseline ####
pred_mean <- (pred_baseline + pred_ret + pred_garch) / 3
quantile_comparison_plot(list(pred_baseline, pred_ret, pred_garch, pred_mean),
model_names = c("Base", "QR", "GARCH", "comb"))
abline(h = 0, lwd = .5, lty = 2)
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# plausibility check ####
check_ascending <- function(df) {
for (col in names(df)) {
if (!all(diff(df[[col]]) > 0)) {
stop(paste0("Column '", col, "' does not have ascending values."))
}
}
print("All columns have ascending values.")
}
# Call the test function
check_ascending(pred_mean)
# = = = = = = = = = = = = = = = = = = = = = = = = = =
# submission file ####
# (rows are horizons, cols are quantile levels)
pred_df <- data.frame(forecast_date = fcast_date,
target = "DAX", horizon = paste(c(1, 2, 5:7), "day"),
q0.025 = NA, q0.25 = NA, q0.5 = NA, q0.75 = NA,
q0.975 = NA)
pred_df[,4:8] <- t(pred_mean)
fcast_date_ <- gsub("-", "_", fcast_date)
print(paste0("saving to: ", fcast_date_))
newdir <- paste0(homedir, "/Submissions/", fcast_date_)
if (!file.exists(newdir)) { dir.create(newdir) }
setwd(newdir)
flnm <- paste0(fcast_date_, "_DAX.csv")
write.table(pred_df, flnm, sep = ",", row.names = FALSE, col.names = TRUE)
setwd(homedir)
pred_baseline
